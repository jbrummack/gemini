// This file is @generated by prost-build.
/// Schema is used to define the format of input/output data. Represents a select
/// subset of an [OpenAPI 3.0 schema
/// object](<https://spec.openapis.org/oas/v3.0.3#schema-object>). More fields may
/// be added in the future as needed.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Schema {
    /// Optional. The type of the data.
    #[prost(enumeration = "Type", tag = "1")]
    pub r#type: i32,
    /// Optional. The format of the data.
    /// Supported formats:
    /// for NUMBER type: "float", "double"
    /// for INTEGER type: "int32", "int64"
    /// for STRING type: "email", "byte", etc
    #[prost(string, tag = "7")]
    pub format: ::prost::alloc::string::String,
    /// Optional. The title of the Schema.
    #[prost(string, tag = "24")]
    pub title: ::prost::alloc::string::String,
    /// Optional. The description of the data.
    #[prost(string, tag = "8")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Indicates if the value may be null.
    #[prost(bool, tag = "6")]
    pub nullable: bool,
    /// Optional. Default value of the data.
    #[prost(message, optional, tag = "23")]
    pub default: ::core::option::Option<super::super::super::protobuf::Value>,
    /// Optional. SCHEMA FIELDS FOR TYPE ARRAY
    /// Schema of the elements of Type.ARRAY.
    #[prost(message, optional, boxed, tag = "2")]
    pub items: ::core::option::Option<::prost::alloc::boxed::Box<Schema>>,
    /// Optional. Minimum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "21")]
    pub min_items: i64,
    /// Optional. Maximum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "22")]
    pub max_items: i64,
    /// Optional. Possible values of the element of primitive type with enum
    /// format. Examples:
    ///
    /// 1. We can define direction as :
    ///    {type:STRING, format:enum, enum:\["EAST", NORTH", "SOUTH", "WEST"\]}
    /// 1. We can define apartment number as :
    ///    {type:INTEGER, format:enum, enum:\["101", "201", "301"\]}
    #[prost(string, repeated, tag = "9")]
    pub r#enum: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. SCHEMA FIELDS FOR TYPE OBJECT
    /// Properties of Type.OBJECT.
    #[prost(map = "string, message", tag = "3")]
    pub properties: ::std::collections::HashMap<::prost::alloc::string::String, Schema>,
    /// Optional. The order of the properties.
    /// Not a standard field in open api spec. Only used to support the order of
    /// the properties.
    #[prost(string, repeated, tag = "25")]
    pub property_ordering: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Required properties of Type.OBJECT.
    #[prost(string, repeated, tag = "5")]
    pub required: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Minimum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "14")]
    pub min_properties: i64,
    /// Optional. Maximum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "15")]
    pub max_properties: i64,
    /// Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER
    /// Minimum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, tag = "16")]
    pub minimum: f64,
    /// Optional. Maximum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, tag = "17")]
    pub maximum: f64,
    /// Optional. SCHEMA FIELDS FOR TYPE STRING
    /// Minimum length of the Type.STRING
    #[prost(int64, tag = "18")]
    pub min_length: i64,
    /// Optional. Maximum length of the Type.STRING
    #[prost(int64, tag = "19")]
    pub max_length: i64,
    /// Optional. Pattern of the Type.STRING to restrict a string to a regular
    /// expression.
    #[prost(string, tag = "20")]
    pub pattern: ::prost::alloc::string::String,
    /// Optional. Example of the object. Will only populated when the object is the
    /// root.
    #[prost(message, optional, tag = "4")]
    pub example: ::core::option::Option<super::super::super::protobuf::Value>,
    /// Optional. The value should be validated against any (one or more) of the
    /// subschemas in the list.
    #[prost(message, repeated, tag = "11")]
    pub any_of: ::prost::alloc::vec::Vec<Schema>,
    /// Optional. Can either be a boolean or an object; controls the presence of
    /// additional properties.
    #[prost(message, optional, tag = "26")]
    pub additional_properties: ::core::option::Option<
        super::super::super::protobuf::Value,
    >,
    /// Optional. Allows indirect references between schema nodes. The value should
    /// be a valid reference to a child of the root `defs`.
    ///
    /// For example, the following schema defines a reference to a schema node
    /// named "Pet":
    ///
    /// type: object
    /// properties:
    /// pet:
    /// ref: #/defs/Pet
    /// defs:
    /// Pet:
    /// type: object
    /// properties:
    /// name:
    /// type: string
    ///
    /// The value of the "pet" property is a reference to the schema node
    /// named "Pet".
    /// See details in
    /// <https://json-schema.org/understanding-json-schema/structuring>
    #[prost(string, tag = "27")]
    pub r#ref: ::prost::alloc::string::String,
    /// Optional. A map of definitions for use by `ref`
    /// Only allowed at the root of the schema.
    #[prost(map = "string, message", tag = "28")]
    pub defs: ::std::collections::HashMap<::prost::alloc::string::String, Schema>,
}
/// Type contains the list of OpenAPI data types as defined by
/// <https://swagger.io/docs/specification/data-models/data-types/>
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Type {
    /// Not specified, should not be used.
    Unspecified = 0,
    /// OpenAPI string type
    String = 1,
    /// OpenAPI number type
    Number = 2,
    /// OpenAPI integer type
    Integer = 3,
    /// OpenAPI boolean type
    Boolean = 4,
    /// OpenAPI array type
    Array = 5,
    /// OpenAPI object type
    Object = 6,
}
impl Type {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TYPE_UNSPECIFIED",
            Self::String => "STRING",
            Self::Number => "NUMBER",
            Self::Integer => "INTEGER",
            Self::Boolean => "BOOLEAN",
            Self::Array => "ARRAY",
            Self::Object => "OBJECT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "STRING" => Some(Self::String),
            "NUMBER" => Some(Self::Number),
            "INTEGER" => Some(Self::Integer),
            "BOOLEAN" => Some(Self::Boolean),
            "ARRAY" => Some(Self::Array),
            "OBJECT" => Some(Self::Object),
            _ => None,
        }
    }
}
/// Tool details that the model may use to generate response.
///
/// A `Tool` is a piece of code that enables the system to interact with
/// external systems to perform an action, or set of actions, outside of
/// knowledge and scope of the model. A Tool object should contain exactly
/// one type of Tool (e.g FunctionDeclaration, Retrieval or
/// GoogleSearchRetrieval).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tool {
    /// Optional. Function tool type.
    /// One or more function declarations to be passed to the model along with the
    /// current user query. Model may decide to call a subset of these functions
    /// by populating \[FunctionCall\]\[google.cloud.aiplatform.v1.Part.function_call\]
    /// in the response. User should provide a
    /// \[FunctionResponse\]\[google.cloud.aiplatform.v1.Part.function_response\] for
    /// each function call in the next turn. Based on the function responses, Model
    /// will generate the final response back to the user. Maximum 128 function
    /// declarations can be provided.
    #[prost(message, repeated, tag = "1")]
    pub function_declarations: ::prost::alloc::vec::Vec<FunctionDeclaration>,
    /// Optional. Retrieval tool type.
    /// System will always execute the provided retrieval tool(s) to get external
    /// knowledge to answer the prompt. Retrieval results are presented to the
    /// model for generation.
    #[prost(message, optional, tag = "2")]
    pub retrieval: ::core::option::Option<Retrieval>,
    /// Optional. GoogleSearch tool type.
    /// Tool to support Google Search in Model. Powered by Google.
    #[prost(message, optional, tag = "7")]
    pub google_search: ::core::option::Option<tool::GoogleSearch>,
    /// Optional. GoogleSearchRetrieval tool type.
    /// Specialized retrieval tool that is powered by Google search.
    #[prost(message, optional, tag = "3")]
    pub google_search_retrieval: ::core::option::Option<GoogleSearchRetrieval>,
    /// Optional. GoogleMaps tool type.
    /// Tool to support Google Maps in Model.
    #[prost(message, optional, tag = "5")]
    pub google_maps: ::core::option::Option<GoogleMaps>,
    /// Optional. Tool to support searching public web data, powered by Vertex AI
    /// Search and Sec4 compliance.
    #[prost(message, optional, tag = "6")]
    pub enterprise_web_search: ::core::option::Option<EnterpriseWebSearch>,
    /// Optional. CodeExecution tool type.
    /// Enables the model to execute code as part of generation.
    #[prost(message, optional, tag = "4")]
    pub code_execution: ::core::option::Option<tool::CodeExecution>,
    /// Optional. Tool to support URL context retrieval.
    #[prost(message, optional, tag = "10")]
    pub url_context: ::core::option::Option<UrlContext>,
    /// Optional. Tool to support the model interacting directly with the computer.
    /// If enabled, it automatically populates computer-use specific Function
    /// Declarations.
    #[prost(message, optional, tag = "11")]
    pub computer_use: ::core::option::Option<tool::ComputerUse>,
}
/// Nested message and enum types in `Tool`.
pub mod tool {
    /// GoogleSearch tool type.
    /// Tool to support Google Search in Model. Powered by Google.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct GoogleSearch {
        /// Optional. List of domains to be excluded from the search results.
        /// The default limit is 2000 domains.
        /// Example: \["amazon.com", "facebook.com"\].
        #[prost(string, repeated, tag = "3")]
        pub exclude_domains: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
        /// Optional. Sites with confidence level chosen & above this value will be
        /// blocked from the search results.
        #[prost(enumeration = "PhishBlockThreshold", optional, tag = "4")]
        pub blocking_confidence: ::core::option::Option<i32>,
    }
    /// Tool that executes code generated by the model, and automatically returns
    /// the result to the model.
    ///
    /// See also \[ExecutableCode\]and \[CodeExecutionResult\] which are input and
    /// output to this tool.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct CodeExecution {}
    /// Tool to support computer use.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ComputerUse {
        /// Required. The environment being operated.
        #[prost(enumeration = "computer_use::Environment", tag = "1")]
        pub environment: i32,
        /// Optional. By default, [predefined
        /// functions](<https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use#supported-actions>)
        /// are included in the final model call. Some of them can be explicitly
        /// excluded from being automatically included. This can serve two purposes:
        ///
        /// 1. Using a more restricted / different action space.
        /// 1. Improving the definitions / instructions of predefined functions.
        #[prost(string, repeated, tag = "2")]
        pub excluded_predefined_functions: ::prost::alloc::vec::Vec<
            ::prost::alloc::string::String,
        >,
    }
    /// Nested message and enum types in `ComputerUse`.
    pub mod computer_use {
        /// Represents the environment being operated, such as a web browser.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum Environment {
            /// Defaults to browser.
            Unspecified = 0,
            /// Operates in a web browser.
            Browser = 1,
        }
        impl Environment {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "ENVIRONMENT_UNSPECIFIED",
                    Self::Browser => "ENVIRONMENT_BROWSER",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "ENVIRONMENT_UNSPECIFIED" => Some(Self::Unspecified),
                    "ENVIRONMENT_BROWSER" => Some(Self::Browser),
                    _ => None,
                }
            }
        }
    }
    /// These are available confidence level user can set to block malicious urls
    /// with chosen confidence and above. For understanding different confidence of
    /// webrisk, please refer to
    /// <https://cloud.google.com/web-risk/docs/reference/rpc/google.cloud.webrisk.v1eap1#confidencelevel>
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum PhishBlockThreshold {
        /// Defaults to unspecified.
        Unspecified = 0,
        /// Blocks Low and above confidence URL that is risky.
        BlockLowAndAbove = 30,
        /// Blocks Medium and above confidence URL that is risky.
        BlockMediumAndAbove = 40,
        /// Blocks High and above confidence URL that is risky.
        BlockHighAndAbove = 50,
        /// Blocks Higher and above confidence URL that is risky.
        BlockHigherAndAbove = 55,
        /// Blocks Very high and above confidence URL that is risky.
        BlockVeryHighAndAbove = 60,
        /// Blocks Extremely high confidence URL that is risky.
        BlockOnlyExtremelyHigh = 100,
    }
    impl PhishBlockThreshold {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "PHISH_BLOCK_THRESHOLD_UNSPECIFIED",
                Self::BlockLowAndAbove => "BLOCK_LOW_AND_ABOVE",
                Self::BlockMediumAndAbove => "BLOCK_MEDIUM_AND_ABOVE",
                Self::BlockHighAndAbove => "BLOCK_HIGH_AND_ABOVE",
                Self::BlockHigherAndAbove => "BLOCK_HIGHER_AND_ABOVE",
                Self::BlockVeryHighAndAbove => "BLOCK_VERY_HIGH_AND_ABOVE",
                Self::BlockOnlyExtremelyHigh => "BLOCK_ONLY_EXTREMELY_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PHISH_BLOCK_THRESHOLD_UNSPECIFIED" => Some(Self::Unspecified),
                "BLOCK_LOW_AND_ABOVE" => Some(Self::BlockLowAndAbove),
                "BLOCK_MEDIUM_AND_ABOVE" => Some(Self::BlockMediumAndAbove),
                "BLOCK_HIGH_AND_ABOVE" => Some(Self::BlockHighAndAbove),
                "BLOCK_HIGHER_AND_ABOVE" => Some(Self::BlockHigherAndAbove),
                "BLOCK_VERY_HIGH_AND_ABOVE" => Some(Self::BlockVeryHighAndAbove),
                "BLOCK_ONLY_EXTREMELY_HIGH" => Some(Self::BlockOnlyExtremelyHigh),
                _ => None,
            }
        }
    }
}
/// Tool to support URL context.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct UrlContext {}
/// Structured representation of a function declaration as defined by the
/// [OpenAPI 3.0 specification](<https://spec.openapis.org/oas/v3.0.3>). Included
/// in this declaration are the function name, description, parameters and
/// response type. This FunctionDeclaration is a representation of a block of
/// code that can be used as a `Tool` by the model and executed by the client.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionDeclaration {
    /// Required. The name of the function to call.
    /// Must start with a letter or an underscore.
    /// Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a
    /// maximum length of 64.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. Description and purpose of the function.
    /// Model uses it to decide how and whether to call the function.
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Describes the parameters to this function in JSON Schema Object
    /// format. Reflects the Open API 3.03 Parameter Object. string Key: the name
    /// of the parameter. Parameter names are case sensitive. Schema Value: the
    /// Schema defining the type used for the parameter. For function with no
    /// parameters, this can be left unset. Parameter names must start with a
    /// letter or an underscore and must only contain chars a-z, A-Z, 0-9, or
    /// underscores with a maximum length of 64. Example with 1 required and 1
    /// optional parameter: type: OBJECT properties:
    /// param1:
    /// type: STRING
    /// param2:
    /// type: INTEGER
    /// required:
    ///
    /// * param1
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Schema>,
    /// Optional. Describes the parameters to the function in JSON Schema format.
    /// The schema must describe an object where the properties are the parameters
    /// to the function. For example:
    ///
    /// ```text,
    /// {
    ///   "type": "object",
    ///   "properties": {
    ///     "name": { "type": "string" },
    ///     "age": { "type": "integer" }
    ///   },
    ///   "additionalProperties": false,
    ///   "required": \["name", "age"\],
    ///   "propertyOrdering": \["name", "age"\]
    /// }
    /// ```
    ///
    /// This field is mutually exclusive with `parameters`.
    #[prost(message, optional, tag = "5")]
    pub parameters_json_schema: ::core::option::Option<
        super::super::super::protobuf::Value,
    >,
    /// Optional. Describes the output from this function in JSON Schema format.
    /// Reflects the Open API 3.03 Response Object. The Schema defines the type
    /// used for the response value of the function.
    #[prost(message, optional, tag = "4")]
    pub response: ::core::option::Option<Schema>,
    /// Optional. Describes the output from this function in JSON Schema format.
    /// The value specified by the schema is the response value of the function.
    ///
    /// This field is mutually exclusive with `response`.
    #[prost(message, optional, tag = "6")]
    pub response_json_schema: ::core::option::Option<
        super::super::super::protobuf::Value,
    >,
}
/// A predicted \[FunctionCall\] returned from the model that contains a string
/// representing the \[FunctionDeclaration.name\] and a structured JSON object
/// containing the parameters and their values.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionCall {
    /// Optional. The name of the function to call.
    /// Matches \[FunctionDeclaration.name\].
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. The function parameters and values in JSON object format.
    /// See \[FunctionDeclaration.parameters\] for parameter details.
    #[prost(message, optional, tag = "2")]
    pub args: ::core::option::Option<super::super::super::protobuf::Struct>,
    /// Optional. The partial argument value of the function call.
    /// If provided, represents the arguments/fields that are streamed
    /// incrementally.
    #[prost(message, repeated, tag = "4")]
    pub partial_args: ::prost::alloc::vec::Vec<PartialArg>,
    /// Optional. Whether this is the last part of the FunctionCall.
    /// If true, another partial message for the current FunctionCall is expected
    /// to follow.
    #[prost(bool, tag = "5")]
    pub will_continue: bool,
}
/// Partial argument value of the function call.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PartialArg {
    /// Required. A JSON Path (RFC 9535) to the argument being streamed.
    /// <https://datatracker.ietf.org/doc/html/rfc9535.> e.g. "$.foo.bar\[0\].data".
    #[prost(string, tag = "1")]
    pub json_path: ::prost::alloc::string::String,
    /// Optional. Whether this is not the last part of the same json_path.
    /// If true, another PartialArg message for the current json_path is expected
    /// to follow.
    #[prost(bool, tag = "6")]
    pub will_continue: bool,
    /// The delta of field value being streamed.
    #[prost(oneof = "partial_arg::Delta", tags = "2, 3, 4, 5")]
    pub delta: ::core::option::Option<partial_arg::Delta>,
}
/// Nested message and enum types in `PartialArg`.
pub mod partial_arg {
    /// The delta of field value being streamed.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Delta {
        /// Optional. Represents a null value.
        #[prost(
            enumeration = "super::super::super::super::protobuf::NullValue",
            tag = "2"
        )]
        NullValue(i32),
        /// Optional. Represents a double value.
        #[prost(double, tag = "3")]
        NumberValue(f64),
        /// Optional. Represents a string value.
        #[prost(string, tag = "4")]
        StringValue(::prost::alloc::string::String),
        /// Optional. Represents a boolean value.
        #[prost(bool, tag = "5")]
        BoolValue(bool),
    }
}
/// A datatype containing media that is part of a `FunctionResponse` message.
///
/// A `FunctionResponsePart` consists of data which has an associated datatype. A
/// `FunctionResponsePart` can only contain one of the accepted types in
/// `FunctionResponsePart.data`.
///
/// A `FunctionResponsePart` must have a fixed IANA MIME type identifying the
/// type and subtype of the media if the `inline_data` field is filled with raw
/// bytes.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FunctionResponsePart {
    /// The data of the function response part.
    #[prost(oneof = "function_response_part::Data", tags = "1, 2")]
    pub data: ::core::option::Option<function_response_part::Data>,
}
/// Nested message and enum types in `FunctionResponsePart`.
pub mod function_response_part {
    /// The data of the function response part.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Data {
        /// Inline media bytes.
        #[prost(message, tag = "1")]
        InlineData(super::FunctionResponseBlob),
        /// URI based data.
        #[prost(message, tag = "2")]
        FileData(super::FunctionResponseFileData),
    }
}
/// Raw media bytes for function response.
///
/// Text should not be sent as raw bytes, use the 'text' field.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FunctionResponseBlob {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. Raw bytes.
    #[prost(bytes = "vec", tag = "2")]
    pub data: ::prost::alloc::vec::Vec<u8>,
    /// Optional. Display name of the blob.
    ///
    /// Used to provide a label or filename to distinguish blobs.
    ///
    /// This field is only returned in PromptMessage for prompt management.
    /// It is currently used in the Gemini GenerateContent calls only when server
    /// side tools (code_execution, google_search, and url_context) are enabled.
    #[prost(string, tag = "4")]
    pub display_name: ::prost::alloc::string::String,
}
/// URI based data for function response.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FunctionResponseFileData {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. URI.
    #[prost(string, tag = "2")]
    pub file_uri: ::prost::alloc::string::String,
    /// Optional. Display name of the file data.
    ///
    /// Used to provide a label or filename to distinguish file datas.
    ///
    /// This field is only returned in PromptMessage for prompt management.
    /// It is currently used in the Gemini GenerateContent calls only when server
    /// side tools (code_execution, google_search, and url_context) are enabled.
    #[prost(string, tag = "3")]
    pub display_name: ::prost::alloc::string::String,
}
/// The result output from a \[FunctionCall\] that contains a string representing
/// the \[FunctionDeclaration.name\] and a structured JSON object containing any
/// output from the function is used as context to the model. This should contain
/// the result of a \[FunctionCall\] made based on model prediction.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionResponse {
    /// Required. The name of the function to call.
    /// Matches \[FunctionDeclaration.name\] and \[FunctionCall.name\].
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The function response in JSON object format.
    /// Use "output" key to specify function output and "error" key to specify
    /// error details (if any). If "output" and "error" keys are not specified,
    /// then whole "response" is treated as function output.
    #[prost(message, optional, tag = "2")]
    pub response: ::core::option::Option<super::super::super::protobuf::Struct>,
    /// Optional. Ordered `Parts` that constitute a function response. Parts may
    /// have different IANA MIME types.
    #[prost(message, repeated, tag = "4")]
    pub parts: ::prost::alloc::vec::Vec<FunctionResponsePart>,
}
/// Code generated by the model that is meant to be executed, and the result
/// returned to the model.
///
/// Generated when using the \[FunctionDeclaration\] tool and
/// \[FunctionCallingConfig\] mode is set to \[Mode.CODE\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ExecutableCode {
    /// Required. Programming language of the `code`.
    #[prost(enumeration = "executable_code::Language", tag = "1")]
    pub language: i32,
    /// Required. The code to be executed.
    #[prost(string, tag = "2")]
    pub code: ::prost::alloc::string::String,
}
/// Nested message and enum types in `ExecutableCode`.
pub mod executable_code {
    /// Supported programming languages for the generated code.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Language {
        /// Unspecified language. This value should not be used.
        Unspecified = 0,
        /// Python >= 3.10, with numpy and simpy available.
        Python = 1,
    }
    impl Language {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "LANGUAGE_UNSPECIFIED",
                Self::Python => "PYTHON",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "LANGUAGE_UNSPECIFIED" => Some(Self::Unspecified),
                "PYTHON" => Some(Self::Python),
                _ => None,
            }
        }
    }
}
/// Result of executing the \[ExecutableCode\].
///
/// Always follows a `part` containing the \[ExecutableCode\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CodeExecutionResult {
    /// Required. Outcome of the code execution.
    #[prost(enumeration = "code_execution_result::Outcome", tag = "1")]
    pub outcome: i32,
    /// Optional. Contains stdout when code execution is successful, stderr or
    /// other description otherwise.
    #[prost(string, tag = "2")]
    pub output: ::prost::alloc::string::String,
}
/// Nested message and enum types in `CodeExecutionResult`.
pub mod code_execution_result {
    /// Enumeration of possible outcomes of the code execution.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Outcome {
        /// Unspecified status. This value should not be used.
        Unspecified = 0,
        /// Code execution completed successfully.
        Ok = 1,
        /// Code execution finished but with a failure. `stderr` should contain the
        /// reason.
        Failed = 2,
        /// Code execution ran for too long, and was cancelled. There may or may not
        /// be a partial output present.
        DeadlineExceeded = 3,
    }
    impl Outcome {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "OUTCOME_UNSPECIFIED",
                Self::Ok => "OUTCOME_OK",
                Self::Failed => "OUTCOME_FAILED",
                Self::DeadlineExceeded => "OUTCOME_DEADLINE_EXCEEDED",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "OUTCOME_UNSPECIFIED" => Some(Self::Unspecified),
                "OUTCOME_OK" => Some(Self::Ok),
                "OUTCOME_FAILED" => Some(Self::Failed),
                "OUTCOME_DEADLINE_EXCEEDED" => Some(Self::DeadlineExceeded),
                _ => None,
            }
        }
    }
}
/// Defines a retrieval tool that model can call to access external knowledge.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Retrieval {
    /// Optional. Deprecated. This option is no longer supported.
    #[deprecated]
    #[prost(bool, tag = "3")]
    pub disable_attribution: bool,
    /// The source of the retrieval.
    #[prost(oneof = "retrieval::Source", tags = "2, 4")]
    pub source: ::core::option::Option<retrieval::Source>,
}
/// Nested message and enum types in `Retrieval`.
pub mod retrieval {
    /// The source of the retrieval.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Source {
        /// Set to use data source powered by Vertex AI Search.
        #[prost(message, tag = "2")]
        VertexAiSearch(super::VertexAiSearch),
        /// Set to use data source powered by Vertex RAG store.
        /// User data is uploaded via the VertexRagDataService.
        #[prost(message, tag = "4")]
        VertexRagStore(super::VertexRagStore),
    }
}
/// Retrieve from Vertex RAG Store for grounding.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VertexRagStore {
    /// Optional. The representation of the rag source. It can be used to specify
    /// corpus only or ragfiles. Currently only support one corpus or multiple
    /// files from one corpus. In the future we may open up multiple corpora
    /// support.
    #[prost(message, repeated, tag = "4")]
    pub rag_resources: ::prost::alloc::vec::Vec<vertex_rag_store::RagResource>,
    /// Optional. Number of top k results to return from the selected corpora.
    #[deprecated]
    #[prost(int32, optional, tag = "2")]
    pub similarity_top_k: ::core::option::Option<i32>,
    /// Optional. Only return results with vector distance smaller than the
    /// threshold.
    #[deprecated]
    #[prost(double, optional, tag = "3")]
    pub vector_distance_threshold: ::core::option::Option<f64>,
    /// Optional. The retrieval config for the Rag query.
    #[prost(message, optional, tag = "6")]
    pub rag_retrieval_config: ::core::option::Option<RagRetrievalConfig>,
}
/// Nested message and enum types in `VertexRagStore`.
pub mod vertex_rag_store {
    /// The definition of the Rag resource.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct RagResource {
        /// Optional. RagCorpora resource name.
        /// Format:
        /// `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`
        #[prost(string, tag = "1")]
        pub rag_corpus: ::prost::alloc::string::String,
        /// Optional. rag_file_id. The files should be in the same rag_corpus set in
        /// rag_corpus field.
        #[prost(string, repeated, tag = "2")]
        pub rag_file_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    }
}
/// Retrieve from Vertex AI Search datastore or engine for grounding.
/// datastore and engine are mutually exclusive.
/// See <https://cloud.google.com/products/agent-builder>
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VertexAiSearch {
    /// Optional. Fully-qualified Vertex AI Search data store resource ID.
    /// Format:
    /// `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
    #[prost(string, tag = "1")]
    pub datastore: ::prost::alloc::string::String,
    /// Optional. Fully-qualified Vertex AI Search engine resource ID.
    /// Format:
    /// `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`
    #[prost(string, tag = "2")]
    pub engine: ::prost::alloc::string::String,
    /// Optional. Number of search results to return per query.
    /// The default value is 10.
    /// The maximumm allowed value is 10.
    #[prost(int32, tag = "3")]
    pub max_results: i32,
    /// Optional. Filter strings to be passed to the search API.
    #[prost(string, tag = "4")]
    pub filter: ::prost::alloc::string::String,
    /// Specifications that define the specific DataStores to be searched, along
    /// with configurations for those data stores. This is only considered for
    /// Engines with multiple data stores.
    /// It should only be set if engine is used.
    #[prost(message, repeated, tag = "5")]
    pub data_store_specs: ::prost::alloc::vec::Vec<vertex_ai_search::DataStoreSpec>,
}
/// Nested message and enum types in `VertexAISearch`.
pub mod vertex_ai_search {
    /// Define data stores within engine to filter on in a search call and
    /// configurations for those data stores. For more information, see
    /// <https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec>
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct DataStoreSpec {
        /// Full resource name of DataStore, such as
        /// Format:
        /// `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
        #[prost(string, tag = "1")]
        pub data_store: ::prost::alloc::string::String,
        /// Optional. Filter specification to filter documents in the data store
        /// specified by data_store field. For more information on filtering, see
        /// [Filtering](<https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata>)
        #[prost(string, tag = "2")]
        pub filter: ::prost::alloc::string::String,
    }
}
/// Tool to retrieve public web data for grounding, powered by Google.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct GoogleSearchRetrieval {
    /// Specifies the dynamic retrieval configuration for the given source.
    #[prost(message, optional, tag = "2")]
    pub dynamic_retrieval_config: ::core::option::Option<DynamicRetrievalConfig>,
}
/// Tool to retrieve public maps data for grounding, powered by Google.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GoogleMaps {
    /// If true, include the widget context token in the response.
    #[prost(bool, tag = "1")]
    pub enable_widget: bool,
}
/// Tool to search public web data, powered by Vertex AI Search and Sec4
/// compliance.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct EnterpriseWebSearch {
    /// Optional. List of domains to be excluded from the search results.
    /// The default limit is 2000 domains.
    #[prost(string, repeated, tag = "1")]
    pub exclude_domains: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Sites with confidence level chosen & above this value will be
    /// blocked from the search results.
    #[prost(enumeration = "tool::PhishBlockThreshold", optional, tag = "2")]
    pub blocking_confidence: ::core::option::Option<i32>,
}
/// Describes the options to customize dynamic retrieval.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct DynamicRetrievalConfig {
    /// The mode of the predictor to be used in dynamic retrieval.
    #[prost(enumeration = "dynamic_retrieval_config::Mode", tag = "1")]
    pub mode: i32,
    /// Optional. The threshold to be used in dynamic retrieval.
    /// If not set, a system default value is used.
    #[prost(float, optional, tag = "2")]
    pub dynamic_threshold: ::core::option::Option<f32>,
}
/// Nested message and enum types in `DynamicRetrievalConfig`.
pub mod dynamic_retrieval_config {
    /// The mode of the predictor to be used in dynamic retrieval.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Mode {
        /// Always trigger retrieval.
        Unspecified = 0,
        /// Run retrieval only when system decides it is necessary.
        Dynamic = 1,
    }
    impl Mode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODE_UNSPECIFIED",
                Self::Dynamic => "MODE_DYNAMIC",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODE_UNSPECIFIED" => Some(Self::Unspecified),
                "MODE_DYNAMIC" => Some(Self::Dynamic),
                _ => None,
            }
        }
    }
}
/// Tool config. This config is shared for all tools provided in the request.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ToolConfig {
    /// Optional. Function calling config.
    #[prost(message, optional, tag = "1")]
    pub function_calling_config: ::core::option::Option<FunctionCallingConfig>,
    /// Optional. Retrieval config.
    #[prost(message, optional, tag = "2")]
    pub retrieval_config: ::core::option::Option<RetrievalConfig>,
}
/// Function calling config.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FunctionCallingConfig {
    /// Optional. Function calling mode.
    #[prost(enumeration = "function_calling_config::Mode", tag = "1")]
    pub mode: i32,
    /// Optional. Function names to call. Only set when the Mode is ANY. Function
    /// names should match \[FunctionDeclaration.name\]. With mode set to ANY, model
    /// will predict a function call from the set of function names provided.
    #[prost(string, repeated, tag = "2")]
    pub allowed_function_names: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. When set to true, arguments of a single function call will be
    /// streamed out in multiple parts/contents/responses. Partial parameter
    /// results will be returned in the \[FunctionCall.partial_args\] field.
    #[prost(bool, tag = "4")]
    pub stream_function_call_arguments: bool,
}
/// Nested message and enum types in `FunctionCallingConfig`.
pub mod function_calling_config {
    /// Function calling mode.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Mode {
        /// Unspecified function calling mode. This value should not be used.
        Unspecified = 0,
        /// Default model behavior, model decides to predict either function calls
        /// or natural language response.
        Auto = 1,
        /// Model is constrained to always predicting function calls only.
        /// If "allowed_function_names" are set, the predicted function calls will be
        /// limited to any one of "allowed_function_names", else the predicted
        /// function calls will be any one of the provided "function_declarations".
        Any = 2,
        /// Model will not predict any function calls. Model behavior is same as when
        /// not passing any function declarations.
        None = 3,
    }
    impl Mode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODE_UNSPECIFIED",
                Self::Auto => "AUTO",
                Self::Any => "ANY",
                Self::None => "NONE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODE_UNSPECIFIED" => Some(Self::Unspecified),
                "AUTO" => Some(Self::Auto),
                "ANY" => Some(Self::Any),
                "NONE" => Some(Self::None),
                _ => None,
            }
        }
    }
}
/// Retrieval config.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RetrievalConfig {
    /// The location of the user.
    #[prost(message, optional, tag = "1")]
    pub lat_lng: ::core::option::Option<super::super::super::r#type::LatLng>,
    /// The language code of the user.
    #[prost(string, optional, tag = "2")]
    pub language_code: ::core::option::Option<::prost::alloc::string::String>,
}
/// Specifies the context retrieval config.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RagRetrievalConfig {
    /// Optional. The number of contexts to retrieve.
    #[prost(int32, tag = "1")]
    pub top_k: i32,
    /// Optional. Config for filters.
    #[prost(message, optional, tag = "3")]
    pub filter: ::core::option::Option<rag_retrieval_config::Filter>,
    /// Optional. Config for ranking and reranking.
    #[prost(message, optional, tag = "4")]
    pub ranking: ::core::option::Option<rag_retrieval_config::Ranking>,
}
/// Nested message and enum types in `RagRetrievalConfig`.
pub mod rag_retrieval_config {
    /// Config for filters.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Filter {
        /// Optional. String for metadata filtering.
        #[prost(string, tag = "2")]
        pub metadata_filter: ::prost::alloc::string::String,
        /// Filter contexts retrieved from the vector DB based on either vector
        /// distance or vector similarity.
        #[prost(oneof = "filter::VectorDbThreshold", tags = "3, 4")]
        pub vector_db_threshold: ::core::option::Option<filter::VectorDbThreshold>,
    }
    /// Nested message and enum types in `Filter`.
    pub mod filter {
        /// Filter contexts retrieved from the vector DB based on either vector
        /// distance or vector similarity.
        #[derive(Clone, Copy, PartialEq, ::prost::Oneof)]
        pub enum VectorDbThreshold {
            /// Optional. Only returns contexts with vector distance smaller than the
            /// threshold.
            #[prost(double, tag = "3")]
            VectorDistanceThreshold(f64),
            /// Optional. Only returns contexts with vector similarity larger than the
            /// threshold.
            #[prost(double, tag = "4")]
            VectorSimilarityThreshold(f64),
        }
    }
    /// Config for ranking and reranking.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Ranking {
        /// Config options for ranking. Currently only Rank Service is supported.
        #[prost(oneof = "ranking::RankingConfig", tags = "1, 3")]
        pub ranking_config: ::core::option::Option<ranking::RankingConfig>,
    }
    /// Nested message and enum types in `Ranking`.
    pub mod ranking {
        /// Config for Rank Service.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct RankService {
            /// Optional. The model name of the rank service.
            /// Format: `semantic-ranker-512@latest`
            #[prost(string, optional, tag = "1")]
            pub model_name: ::core::option::Option<::prost::alloc::string::String>,
        }
        /// Config for LlmRanker.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct LlmRanker {
            /// Optional. The model name used for ranking.
            /// Format: `gemini-1.5-pro`
            #[prost(string, optional, tag = "1")]
            pub model_name: ::core::option::Option<::prost::alloc::string::String>,
        }
        /// Config options for ranking. Currently only Rank Service is supported.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum RankingConfig {
            /// Optional. Config for Rank Service.
            #[prost(message, tag = "1")]
            RankService(RankService),
            /// Optional. Config for LlmRanker.
            #[prost(message, tag = "3")]
            LlmRanker(LlmRanker),
        }
    }
}
/// The generic reusable api auth config.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ApiAuth {
    /// The auth config.
    #[prost(oneof = "api_auth::AuthConfig", tags = "1")]
    pub auth_config: ::core::option::Option<api_auth::AuthConfig>,
}
/// Nested message and enum types in `ApiAuth`.
pub mod api_auth {
    /// The API secret.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ApiKeyConfig {
        /// Required. The SecretManager secret version resource name storing API key.
        /// e.g. projects/{project}/secrets/{secret}/versions/{version}
        #[prost(string, tag = "1")]
        pub api_key_secret_version: ::prost::alloc::string::String,
    }
    /// The auth config.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum AuthConfig {
        /// The API secret.
        #[prost(message, tag = "1")]
        ApiKeyConfig(ApiKeyConfig),
    }
}
/// Represents a customer-managed encryption key spec that can be applied to
/// a top-level resource.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct EncryptionSpec {
    /// Required. The Cloud KMS resource identifier of the customer managed
    /// encryption key used to protect a resource. Has the form:
    /// `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`.
    /// The key needs to be in the same region as where the compute resource is
    /// created.
    #[prost(string, tag = "1")]
    pub kms_key_name: ::prost::alloc::string::String,
}
/// The storage details for Avro input content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct AvroSource {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_source: ::core::option::Option<GcsSource>,
}
/// The storage details for CSV input content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CsvSource {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_source: ::core::option::Option<GcsSource>,
}
/// The Google Cloud Storage location for the input content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GcsSource {
    /// Required. Google Cloud Storage URI(-s) to the input file(s). May contain
    /// wildcards. For more information on wildcards, see
    /// <https://cloud.google.com/storage/docs/wildcards.>
    #[prost(string, repeated, tag = "1")]
    pub uris: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// The Google Cloud Storage location where the output is to be written to.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GcsDestination {
    /// Required. Google Cloud Storage URI to output directory. If the uri doesn't
    /// end with
    /// '/', a '/' will be automatically appended. The directory is created if it
    /// doesn't exist.
    #[prost(string, tag = "1")]
    pub output_uri_prefix: ::prost::alloc::string::String,
}
/// The BigQuery location for the input content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct BigQuerySource {
    /// Required. BigQuery URI to a table, up to 2000 characters long.
    /// Accepted forms:
    ///
    /// * BigQuery path. For example: `bq://projectId.bqDatasetId.bqTableId`.
    #[prost(string, tag = "1")]
    pub input_uri: ::prost::alloc::string::String,
}
/// The BigQuery location for the output content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct BigQueryDestination {
    /// Required. BigQuery URI to a project or table, up to 2000 characters long.
    ///
    /// When only the project is specified, the Dataset and Table is created.
    /// When the full table reference is specified, the Dataset must exist and
    /// table must not exist.
    ///
    /// Accepted forms:
    ///
    /// * BigQuery path. For example:
    ///   `bq://projectId` or `bq://projectId.bqDatasetId` or
    ///   `bq://projectId.bqDatasetId.bqTableId`.
    #[prost(string, tag = "1")]
    pub output_uri: ::prost::alloc::string::String,
}
/// The Vertex Multimodal Dataset for the input content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VertexMultimodalDatasetSource {
    /// Required. The resource name of the Vertex Dataset.
    /// Format: `projects/{project}/locations/{location}/datasets/{dataset}`
    #[prost(string, tag = "1")]
    pub dataset_name: ::prost::alloc::string::String,
}
/// The details for a Vertex Multimodal Dataset output.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VertexMultimodalDatasetDestination {
    /// Optional. The destination of the underlying BigQuery table that will be
    /// created for the output Multimodal Dataset. If not specified, the BigQuery
    /// table will be created in a default BigQuery dataset.
    #[prost(message, optional, tag = "1")]
    pub bigquery_destination: ::core::option::Option<BigQueryDestination>,
    /// Optional. Display name of the output dataset.
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
}
/// The storage details for CSV output content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CsvDestination {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_destination: ::core::option::Option<GcsDestination>,
}
/// The storage details for TFRecord output content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TfRecordDestination {
    /// Required. Google Cloud Storage location.
    #[prost(message, optional, tag = "1")]
    pub gcs_destination: ::core::option::Option<GcsDestination>,
}
/// The Container Registry location for the container image.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ContainerRegistryDestination {
    /// Required. Container Registry URI of a container image.
    /// Only Google Container Registry and Artifact Registry are supported now.
    /// Accepted forms:
    ///
    /// * Google Container Registry path. For example:
    ///   `gcr.io/projectId/imageName:tag`.
    ///
    /// * Artifact Registry path. For example:
    ///   `us-central1-docker.pkg.dev/projectId/repoName/imageName:tag`.
    ///
    /// If a tag is not specified, "latest" will be used as the default tag.
    #[prost(string, tag = "1")]
    pub output_uri: ::prost::alloc::string::String,
}
/// The Google Drive location for the input content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GoogleDriveSource {
    /// Required. Google Drive resource IDs.
    #[prost(message, repeated, tag = "1")]
    pub resource_ids: ::prost::alloc::vec::Vec<google_drive_source::ResourceId>,
}
/// Nested message and enum types in `GoogleDriveSource`.
pub mod google_drive_source {
    /// The type and ID of the Google Drive resource.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ResourceId {
        /// Required. The type of the Google Drive resource.
        #[prost(enumeration = "resource_id::ResourceType", tag = "1")]
        pub resource_type: i32,
        /// Required. The ID of the Google Drive resource.
        #[prost(string, tag = "2")]
        pub resource_id: ::prost::alloc::string::String,
    }
    /// Nested message and enum types in `ResourceId`.
    pub mod resource_id {
        /// The type of the Google Drive resource.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum ResourceType {
            /// Unspecified resource type.
            Unspecified = 0,
            /// File resource type.
            File = 1,
            /// Folder resource type.
            Folder = 2,
        }
        impl ResourceType {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "RESOURCE_TYPE_UNSPECIFIED",
                    Self::File => "RESOURCE_TYPE_FILE",
                    Self::Folder => "RESOURCE_TYPE_FOLDER",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "RESOURCE_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                    "RESOURCE_TYPE_FILE" => Some(Self::File),
                    "RESOURCE_TYPE_FOLDER" => Some(Self::Folder),
                    _ => None,
                }
            }
        }
    }
}
/// The input content is encapsulated and uploaded in the request.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DirectUploadSource {}
/// The Slack source for the ImportRagFilesRequest.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SlackSource {
    /// Required. The Slack channels.
    #[prost(message, repeated, tag = "1")]
    pub channels: ::prost::alloc::vec::Vec<slack_source::SlackChannels>,
}
/// Nested message and enum types in `SlackSource`.
pub mod slack_source {
    /// SlackChannels contains the Slack channels and corresponding access token.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct SlackChannels {
        /// Required. The Slack channel IDs.
        #[prost(message, repeated, tag = "1")]
        pub channels: ::prost::alloc::vec::Vec<slack_channels::SlackChannel>,
        /// Required. The SecretManager secret version resource name (e.g.
        /// projects/{project}/secrets/{secret}/versions/{version}) storing the
        /// Slack channel access token that has access to the slack channel IDs.
        /// See: <https://api.slack.com/tutorials/tracks/getting-a-token.>
        #[prost(message, optional, tag = "3")]
        pub api_key_config: ::core::option::Option<super::api_auth::ApiKeyConfig>,
    }
    /// Nested message and enum types in `SlackChannels`.
    pub mod slack_channels {
        /// SlackChannel contains the Slack channel ID and the time range to import.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct SlackChannel {
            /// Required. The Slack channel ID.
            #[prost(string, tag = "1")]
            pub channel_id: ::prost::alloc::string::String,
            /// Optional. The starting timestamp for messages to import.
            #[prost(message, optional, tag = "2")]
            pub start_time: ::core::option::Option<
                super::super::super::super::super::protobuf::Timestamp,
            >,
            /// Optional. The ending timestamp for messages to import.
            #[prost(message, optional, tag = "3")]
            pub end_time: ::core::option::Option<
                super::super::super::super::super::protobuf::Timestamp,
            >,
        }
    }
}
/// The Jira source for the ImportRagFilesRequest.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct JiraSource {
    /// Required. The Jira queries.
    #[prost(message, repeated, tag = "1")]
    pub jira_queries: ::prost::alloc::vec::Vec<jira_source::JiraQueries>,
}
/// Nested message and enum types in `JiraSource`.
pub mod jira_source {
    /// JiraQueries contains the Jira queries and corresponding authentication.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct JiraQueries {
        /// A list of Jira projects to import in their entirety.
        #[prost(string, repeated, tag = "3")]
        pub projects: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
        /// A list of custom Jira queries to import. For information about JQL (Jira
        /// Query Language), see
        /// <https://support.atlassian.com/jira-service-management-cloud/docs/use-advanced-search-with-jira-query-language-jql/>
        #[prost(string, repeated, tag = "4")]
        pub custom_queries: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
        /// Required. The Jira email address.
        #[prost(string, tag = "5")]
        pub email: ::prost::alloc::string::String,
        /// Required. The Jira server URI.
        #[prost(string, tag = "6")]
        pub server_uri: ::prost::alloc::string::String,
        /// Required. The SecretManager secret version resource name (e.g.
        /// projects/{project}/secrets/{secret}/versions/{version}) storing the
        /// Jira API key. See [Manage API tokens for your Atlassian
        /// account](<https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/>).
        #[prost(message, optional, tag = "7")]
        pub api_key_config: ::core::option::Option<super::api_auth::ApiKeyConfig>,
    }
}
/// The SharePointSources to pass to ImportRagFiles.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SharePointSources {
    /// The SharePoint sources.
    #[prost(message, repeated, tag = "1")]
    pub share_point_sources: ::prost::alloc::vec::Vec<
        share_point_sources::SharePointSource,
    >,
}
/// Nested message and enum types in `SharePointSources`.
pub mod share_point_sources {
    /// An individual SharePointSource.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct SharePointSource {
        /// The Application ID for the app registered in Microsoft Azure Portal.
        /// The application must also be configured with MS Graph permissions
        /// "Files.ReadAll", "Sites.ReadAll" and BrowserSiteLists.Read.All.
        #[prost(string, tag = "1")]
        pub client_id: ::prost::alloc::string::String,
        /// The application secret for the app registered in Azure.
        #[prost(message, optional, tag = "2")]
        pub client_secret: ::core::option::Option<super::api_auth::ApiKeyConfig>,
        /// Unique identifier of the Azure Active Directory Instance.
        #[prost(string, tag = "3")]
        pub tenant_id: ::prost::alloc::string::String,
        /// The name of the SharePoint site to download from. This can be the site
        /// name or the site id.
        #[prost(string, tag = "4")]
        pub sharepoint_site_name: ::prost::alloc::string::String,
        /// Output only. The SharePoint file id. Output only.
        #[prost(string, tag = "9")]
        pub file_id: ::prost::alloc::string::String,
        /// The SharePoint folder source. If not provided, uses "root".
        #[prost(oneof = "share_point_source::FolderSource", tags = "5, 6")]
        pub folder_source: ::core::option::Option<share_point_source::FolderSource>,
        /// The SharePoint drive source.
        #[prost(oneof = "share_point_source::DriveSource", tags = "7, 8")]
        pub drive_source: ::core::option::Option<share_point_source::DriveSource>,
    }
    /// Nested message and enum types in `SharePointSource`.
    pub mod share_point_source {
        /// The SharePoint folder source. If not provided, uses "root".
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum FolderSource {
            /// The path of the SharePoint folder to download from.
            #[prost(string, tag = "5")]
            SharepointFolderPath(::prost::alloc::string::String),
            /// The ID of the SharePoint folder to download from.
            #[prost(string, tag = "6")]
            SharepointFolderId(::prost::alloc::string::String),
        }
        /// The SharePoint drive source.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum DriveSource {
            /// The name of the drive to download from.
            #[prost(string, tag = "7")]
            DriveName(::prost::alloc::string::String),
            /// The ID of the drive to download from.
            #[prost(string, tag = "8")]
            DriveId(::prost::alloc::string::String),
        }
    }
}
/// Config for the embedding model to use for RAG.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagEmbeddingModelConfig {
    /// The model config to use.
    #[prost(oneof = "rag_embedding_model_config::ModelConfig", tags = "1")]
    pub model_config: ::core::option::Option<rag_embedding_model_config::ModelConfig>,
}
/// Nested message and enum types in `RagEmbeddingModelConfig`.
pub mod rag_embedding_model_config {
    /// Config representing a model hosted on Vertex Prediction Endpoint.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct VertexPredictionEndpoint {
        /// Required. The endpoint resource name.
        /// Format:
        /// `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`
        /// or
        /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
        #[prost(string, tag = "1")]
        pub endpoint: ::prost::alloc::string::String,
        /// Output only. The resource name of the model that is deployed on the
        /// endpoint. Present only when the endpoint is not a publisher model.
        /// Pattern:
        /// `projects/{project}/locations/{location}/models/{model}`
        #[prost(string, tag = "2")]
        pub model: ::prost::alloc::string::String,
        /// Output only. Version ID of the model that is deployed on the endpoint.
        /// Present only when the endpoint is not a publisher model.
        #[prost(string, tag = "3")]
        pub model_version_id: ::prost::alloc::string::String,
    }
    /// The model config to use.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum ModelConfig {
        /// The Vertex AI Prediction Endpoint that either refers to a publisher model
        /// or an endpoint that is hosting a 1P fine-tuned text embedding model.
        /// Endpoints hosting non-1P fine-tuned text embedding models are
        /// currently not supported.
        /// This is used for dense vector search.
        #[prost(message, tag = "1")]
        VertexPredictionEndpoint(VertexPredictionEndpoint),
    }
}
/// Config for the Vector DB to use for RAG.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagVectorDbConfig {
    /// Authentication config for the chosen Vector DB.
    #[prost(message, optional, tag = "5")]
    pub api_auth: ::core::option::Option<ApiAuth>,
    /// Optional. Immutable. The embedding model config of the Vector DB.
    #[prost(message, optional, tag = "7")]
    pub rag_embedding_model_config: ::core::option::Option<RagEmbeddingModelConfig>,
    /// The config for the Vector DB.
    #[prost(oneof = "rag_vector_db_config::VectorDb", tags = "1, 3, 6")]
    pub vector_db: ::core::option::Option<rag_vector_db_config::VectorDb>,
}
/// Nested message and enum types in `RagVectorDbConfig`.
pub mod rag_vector_db_config {
    /// The config for the default RAG-managed Vector DB.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct RagManagedDb {
        /// Choice of retrieval strategy.
        #[prost(oneof = "rag_managed_db::RetrievalStrategy", tags = "1, 2")]
        pub retrieval_strategy: ::core::option::Option<
            rag_managed_db::RetrievalStrategy,
        >,
    }
    /// Nested message and enum types in `RagManagedDb`.
    pub mod rag_managed_db {
        /// Config for KNN search.
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct Knn {}
        /// Config for ANN search.
        ///
        /// RagManagedDb uses a tree-based structure to partition data and
        /// facilitate faster searches. As a tradeoff, it requires longer indexing
        /// time and manual triggering of index rebuild via the ImportRagFiles and
        /// UpdateRagCorpus API.
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct Ann {
            /// The depth of the tree-based structure. Only depth values of 2 and 3 are
            /// supported.
            ///
            /// Recommended value is 2 if you have if you have O(10K) files in the
            /// RagCorpus and set this to 3 if more than that.
            ///
            /// Default value is 2.
            #[prost(int32, tag = "1")]
            pub tree_depth: i32,
            /// Number of leaf nodes in the tree-based structure. Each leaf node
            /// contains groups of closely related vectors along with their
            /// corresponding centroid.
            ///
            /// Recommended value is 10 * sqrt(num of RagFiles in your RagCorpus).
            ///
            /// Default value is 500.
            #[prost(int32, tag = "2")]
            pub leaf_count: i32,
        }
        /// Choice of retrieval strategy.
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum RetrievalStrategy {
            /// Performs a KNN search on RagCorpus.
            /// Default choice if not specified.
            #[prost(message, tag = "1")]
            Knn(Knn),
            /// Performs an ANN search on RagCorpus. Use this if you have a lot of
            /// files (> 10K) in your RagCorpus and want to reduce the search latency.
            #[prost(message, tag = "2")]
            Ann(Ann),
        }
    }
    /// The config for the Pinecone.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Pinecone {
        /// Pinecone index name.
        /// This value cannot be changed after it's set.
        #[prost(string, tag = "1")]
        pub index_name: ::prost::alloc::string::String,
    }
    /// The config for the Vertex Vector Search.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct VertexVectorSearch {
        /// The resource name of the Index Endpoint.
        /// Format:
        /// `projects/{project}/locations/{location}/indexEndpoints/{index_endpoint}`
        #[prost(string, tag = "1")]
        pub index_endpoint: ::prost::alloc::string::String,
        /// The resource name of the Index.
        /// Format:
        /// `projects/{project}/locations/{location}/indexes/{index}`
        #[prost(string, tag = "2")]
        pub index: ::prost::alloc::string::String,
    }
    /// The config for the Vector DB.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum VectorDb {
        /// The config for the RAG-managed Vector DB.
        #[prost(message, tag = "1")]
        RagManagedDb(RagManagedDb),
        /// The config for the Pinecone.
        #[prost(message, tag = "3")]
        Pinecone(Pinecone),
        /// The config for the Vertex Vector Search.
        #[prost(message, tag = "6")]
        VertexVectorSearch(VertexVectorSearch),
    }
}
/// RagFile status.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FileStatus {
    /// Output only. RagFile state.
    #[prost(enumeration = "file_status::State", tag = "1")]
    pub state: i32,
    /// Output only. Only when the `state` field is ERROR.
    #[prost(string, tag = "2")]
    pub error_status: ::prost::alloc::string::String,
}
/// Nested message and enum types in `FileStatus`.
pub mod file_status {
    /// RagFile state.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum State {
        /// RagFile state is unspecified.
        Unspecified = 0,
        /// RagFile resource has been created and indexed successfully.
        Active = 1,
        /// RagFile resource is in a problematic state.
        /// See `error_message` field for details.
        Error = 2,
    }
    impl State {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "STATE_UNSPECIFIED",
                Self::Active => "ACTIVE",
                Self::Error => "ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "STATE_UNSPECIFIED" => Some(Self::Unspecified),
                "ACTIVE" => Some(Self::Active),
                "ERROR" => Some(Self::Error),
                _ => None,
            }
        }
    }
}
/// Config for the Vertex AI Search.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VertexAiSearchConfig {
    /// Vertex AI Search Serving Config resource full name. For example,
    /// `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/servingConfigs/{serving_config}`
    /// or
    /// `projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/servingConfigs/{serving_config}`.
    #[prost(string, tag = "1")]
    pub serving_config: ::prost::alloc::string::String,
}
/// RagCorpus status.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CorpusStatus {
    /// Output only. RagCorpus life state.
    #[prost(enumeration = "corpus_status::State", tag = "1")]
    pub state: i32,
    /// Output only. Only when the `state` field is ERROR.
    #[prost(string, tag = "2")]
    pub error_status: ::prost::alloc::string::String,
}
/// Nested message and enum types in `CorpusStatus`.
pub mod corpus_status {
    /// RagCorpus life state.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum State {
        /// This state is not supposed to happen.
        Unknown = 0,
        /// RagCorpus resource entry is initialized, but hasn't done validation.
        Initialized = 1,
        /// RagCorpus is provisioned successfully and is ready to serve.
        Active = 2,
        /// RagCorpus is in a problematic situation.
        /// See `error_message` field for details.
        Error = 3,
    }
    impl State {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unknown => "UNKNOWN",
                Self::Initialized => "INITIALIZED",
                Self::Active => "ACTIVE",
                Self::Error => "ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "UNKNOWN" => Some(Self::Unknown),
                "INITIALIZED" => Some(Self::Initialized),
                "ACTIVE" => Some(Self::Active),
                "ERROR" => Some(Self::Error),
                _ => None,
            }
        }
    }
}
/// A RagCorpus is a RagFile container and a project can have multiple
/// RagCorpora.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagCorpus {
    /// Output only. The resource name of the RagCorpus.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The display name of the RagCorpus.
    /// The name can be up to 128 characters long and can consist of any UTF-8
    /// characters.
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
    /// Optional. The description of the RagCorpus.
    #[prost(string, tag = "3")]
    pub description: ::prost::alloc::string::String,
    /// Output only. Timestamp when this RagCorpus was created.
    #[prost(message, optional, tag = "4")]
    pub create_time: ::core::option::Option<super::super::super::protobuf::Timestamp>,
    /// Output only. Timestamp when this RagCorpus was last updated.
    #[prost(message, optional, tag = "5")]
    pub update_time: ::core::option::Option<super::super::super::protobuf::Timestamp>,
    /// Output only. RagCorpus state.
    #[prost(message, optional, tag = "8")]
    pub corpus_status: ::core::option::Option<CorpusStatus>,
    /// Optional. Immutable. The CMEK key name used to encrypt at-rest data related
    /// to this Corpus. Only applicable to RagManagedDb option for Vector DB. This
    /// field can only be set at corpus creation time, and cannot be updated or
    /// deleted.
    #[prost(message, optional, tag = "12")]
    pub encryption_spec: ::core::option::Option<EncryptionSpec>,
    /// The backend config of the RagCorpus.
    /// It can be data store and/or retrieval engine.
    #[prost(oneof = "rag_corpus::BackendConfig", tags = "9, 10")]
    pub backend_config: ::core::option::Option<rag_corpus::BackendConfig>,
}
/// Nested message and enum types in `RagCorpus`.
pub mod rag_corpus {
    /// The backend config of the RagCorpus.
    /// It can be data store and/or retrieval engine.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum BackendConfig {
        /// Optional. Immutable. The config for the Vector DBs.
        #[prost(message, tag = "9")]
        VectorDbConfig(super::RagVectorDbConfig),
        /// Optional. Immutable. The config for the Vertex AI Search.
        #[prost(message, tag = "10")]
        VertexAiSearchConfig(super::VertexAiSearchConfig),
    }
}
/// A RagFile contains user data for chunking, embedding and indexing.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RagFile {
    /// Output only. The resource name of the RagFile.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The display name of the RagFile.
    /// The name can be up to 128 characters long and can consist of any UTF-8
    /// characters.
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
    /// Optional. The description of the RagFile.
    #[prost(string, tag = "3")]
    pub description: ::prost::alloc::string::String,
    /// Output only. Timestamp when this RagFile was created.
    #[prost(message, optional, tag = "6")]
    pub create_time: ::core::option::Option<super::super::super::protobuf::Timestamp>,
    /// Output only. Timestamp when this RagFile was last updated.
    #[prost(message, optional, tag = "7")]
    pub update_time: ::core::option::Option<super::super::super::protobuf::Timestamp>,
    /// Output only. State of the RagFile.
    #[prost(message, optional, tag = "13")]
    pub file_status: ::core::option::Option<FileStatus>,
    /// The origin location of the RagFile if it is imported from Google Cloud
    /// Storage or Google Drive.
    #[prost(oneof = "rag_file::RagFileSource", tags = "8, 9, 10, 11, 12, 14")]
    pub rag_file_source: ::core::option::Option<rag_file::RagFileSource>,
}
/// Nested message and enum types in `RagFile`.
pub mod rag_file {
    /// The origin location of the RagFile if it is imported from Google Cloud
    /// Storage or Google Drive.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum RagFileSource {
        /// Output only. Google Cloud Storage location of the RagFile.
        /// It does not support wildcards in the Cloud Storage uri for now.
        #[prost(message, tag = "8")]
        GcsSource(super::GcsSource),
        /// Output only. Google Drive location. Supports importing individual files
        /// as well as Google Drive folders.
        #[prost(message, tag = "9")]
        GoogleDriveSource(super::GoogleDriveSource),
        /// Output only. The RagFile is encapsulated and uploaded in the
        /// UploadRagFile request.
        #[prost(message, tag = "10")]
        DirectUploadSource(super::DirectUploadSource),
        /// The RagFile is imported from a Slack channel.
        #[prost(message, tag = "11")]
        SlackSource(super::SlackSource),
        /// The RagFile is imported from a Jira query.
        #[prost(message, tag = "12")]
        JiraSource(super::JiraSource),
        /// The RagFile is imported from a SharePoint source.
        #[prost(message, tag = "14")]
        SharePointSources(super::SharePointSources),
    }
}
/// A RagChunk includes the content of a chunk of a RagFile, and associated
/// metadata.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagChunk {
    /// The content of the chunk.
    #[prost(string, tag = "1")]
    pub text: ::prost::alloc::string::String,
    /// If populated, represents where the chunk starts and ends in the document.
    #[prost(message, optional, tag = "2")]
    pub page_span: ::core::option::Option<rag_chunk::PageSpan>,
}
/// Nested message and enum types in `RagChunk`.
pub mod rag_chunk {
    /// Represents where the chunk starts and ends in the document.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct PageSpan {
        /// Page where chunk starts in the document. Inclusive. 1-indexed.
        #[prost(int32, tag = "1")]
        pub first_page: i32,
        /// Page where chunk ends in the document. Inclusive. 1-indexed.
        #[prost(int32, tag = "2")]
        pub last_page: i32,
    }
}
/// Specifies the size and overlap of chunks for RagFiles.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagFileChunkingConfig {
    /// Specifies the chunking config for RagFiles.
    #[prost(oneof = "rag_file_chunking_config::ChunkingConfig", tags = "3")]
    pub chunking_config: ::core::option::Option<
        rag_file_chunking_config::ChunkingConfig,
    >,
}
/// Nested message and enum types in `RagFileChunkingConfig`.
pub mod rag_file_chunking_config {
    /// Specifies the fixed length chunking config.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct FixedLengthChunking {
        /// The size of the chunks.
        #[prost(int32, tag = "1")]
        pub chunk_size: i32,
        /// The overlap between chunks.
        #[prost(int32, tag = "2")]
        pub chunk_overlap: i32,
    }
    /// Specifies the chunking config for RagFiles.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum ChunkingConfig {
        /// Specifies the fixed length chunking config.
        #[prost(message, tag = "3")]
        FixedLengthChunking(FixedLengthChunking),
    }
}
/// Specifies the transformation config for RagFiles.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagFileTransformationConfig {
    /// Specifies the chunking config for RagFiles.
    #[prost(message, optional, tag = "1")]
    pub rag_file_chunking_config: ::core::option::Option<RagFileChunkingConfig>,
}
/// Specifies the parsing config for RagFiles.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagFileParsingConfig {
    /// The parser to use for RagFiles.
    #[prost(oneof = "rag_file_parsing_config::Parser", tags = "4, 5")]
    pub parser: ::core::option::Option<rag_file_parsing_config::Parser>,
}
/// Nested message and enum types in `RagFileParsingConfig`.
pub mod rag_file_parsing_config {
    /// Document AI Layout Parser config.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct LayoutParser {
        /// The full resource name of a Document AI processor or processor version.
        /// The processor must have type `LAYOUT_PARSER_PROCESSOR`. If specified, the
        /// `additional_config.parse_as_scanned_pdf` field must be false.
        /// Format:
        ///
        /// * `projects/{project_id}/locations/{location}/processors/{processor_id}`
        /// * `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`
        #[prost(string, tag = "1")]
        pub processor_name: ::prost::alloc::string::String,
        /// The maximum number of requests the job is allowed to make to the Document
        /// AI processor per minute. Consult
        /// <https://cloud.google.com/document-ai/quotas> and the Quota page for your
        /// project to set an appropriate value here. If unspecified, a default value
        /// of 120 QPM would be used.
        #[prost(int32, tag = "2")]
        pub max_parsing_requests_per_min: i32,
    }
    /// Specifies the advanced parsing for RagFiles.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct LlmParser {
        /// The name of a LLM model used for parsing.
        /// Format:
        ///
        /// * `projects/{project_id}/locations/{location}/publishers/{publisher}/models/{model}`
        #[prost(string, tag = "1")]
        pub model_name: ::prost::alloc::string::String,
        /// The maximum number of requests the job is allowed to make to the
        /// LLM model per minute. Consult
        /// <https://cloud.google.com/vertex-ai/generative-ai/docs/quotas>
        /// and your document size to set an appropriate value here. If unspecified,
        /// a default value of 5000 QPM would be used.
        #[prost(int32, tag = "2")]
        pub max_parsing_requests_per_min: i32,
        /// The prompt to use for parsing. If not specified, a default prompt will
        /// be used.
        #[prost(string, tag = "3")]
        pub custom_parsing_prompt: ::prost::alloc::string::String,
    }
    /// The parser to use for RagFiles.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Parser {
        /// The Layout Parser to use for RagFiles.
        #[prost(message, tag = "4")]
        LayoutParser(LayoutParser),
        /// The LLM Parser to use for RagFiles.
        #[prost(message, tag = "5")]
        LlmParser(LlmParser),
    }
}
/// Config for uploading RagFile.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct UploadRagFileConfig {
    /// Specifies the transformation config for RagFiles.
    #[prost(message, optional, tag = "3")]
    pub rag_file_transformation_config: ::core::option::Option<
        RagFileTransformationConfig,
    >,
}
/// Config for importing RagFiles.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ImportRagFilesConfig {
    /// Specifies the transformation config for RagFiles.
    #[prost(message, optional, tag = "16")]
    pub rag_file_transformation_config: ::core::option::Option<
        RagFileTransformationConfig,
    >,
    /// Optional. Specifies the parsing config for RagFiles.
    /// RAG will use the default parser if this field is not set.
    #[prost(message, optional, tag = "8")]
    pub rag_file_parsing_config: ::core::option::Option<RagFileParsingConfig>,
    /// Optional. The max number of queries per minute that this job is allowed to
    /// make to the embedding model specified on the corpus. This value is specific
    /// to this job and not shared across other import jobs. Consult the Quotas
    /// page on the project to set an appropriate value here.
    /// If unspecified, a default value of 1,000 QPM would be used.
    #[prost(int32, tag = "5")]
    pub max_embedding_requests_per_min: i32,
    /// Rebuilds the ANN index to optimize for recall on the imported data.
    /// Only applicable for RagCorpora running on RagManagedDb with
    /// `retrieval_strategy` set to `ANN`. The rebuild will be performed using the
    /// existing ANN config set on the RagCorpus. To change the ANN config, please
    /// use the UpdateRagCorpus API.
    ///
    /// Default is false, i.e., index is not rebuilt.
    #[prost(bool, tag = "19")]
    pub rebuild_ann_index: bool,
    /// The source of the import.
    #[prost(oneof = "import_rag_files_config::ImportSource", tags = "2, 3, 6, 7, 13")]
    pub import_source: ::core::option::Option<import_rag_files_config::ImportSource>,
    /// Optional. If provided, all partial failures are written to the sink.
    /// Deprecated. Prefer to use the `import_result_sink`.
    #[prost(oneof = "import_rag_files_config::PartialFailureSink", tags = "11, 12")]
    pub partial_failure_sink: ::core::option::Option<
        import_rag_files_config::PartialFailureSink,
    >,
    /// Optional. If provided, all successfully imported files and all partial
    /// failures are written to the sink.
    #[prost(oneof = "import_rag_files_config::ImportResultSink", tags = "14, 15")]
    pub import_result_sink: ::core::option::Option<
        import_rag_files_config::ImportResultSink,
    >,
}
/// Nested message and enum types in `ImportRagFilesConfig`.
pub mod import_rag_files_config {
    /// The source of the import.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum ImportSource {
        /// Google Cloud Storage location. Supports importing individual files as
        /// well as entire Google Cloud Storage directories. Sample formats:
        ///
        /// * `gs://bucket_name/my_directory/object_name/my_file.txt`
        /// * `gs://bucket_name/my_directory`
        #[prost(message, tag = "2")]
        GcsSource(super::GcsSource),
        /// Google Drive location. Supports importing individual files as
        /// well as Google Drive folders.
        #[prost(message, tag = "3")]
        GoogleDriveSource(super::GoogleDriveSource),
        /// Slack channels with their corresponding access tokens.
        #[prost(message, tag = "6")]
        SlackSource(super::SlackSource),
        /// Jira queries with their corresponding authentication.
        #[prost(message, tag = "7")]
        JiraSource(super::JiraSource),
        /// SharePoint sources.
        #[prost(message, tag = "13")]
        SharePointSources(super::SharePointSources),
    }
    /// Optional. If provided, all partial failures are written to the sink.
    /// Deprecated. Prefer to use the `import_result_sink`.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum PartialFailureSink {
        /// The Cloud Storage path to write partial failures to.
        /// Deprecated. Prefer to use `import_result_gcs_sink`.
        #[deprecated]
        #[prost(message, tag = "11")]
        PartialFailureGcsSink(super::GcsDestination),
        /// The BigQuery destination to write partial failures to. It should be a
        /// bigquery table resource name (e.g.
        /// "bq://projectId.bqDatasetId.bqTableId"). The dataset must exist. If the
        /// table does not exist, it will be created with the expected schema. If the
        /// table exists, the schema will be validated and data will be added to this
        /// existing table.
        /// Deprecated. Prefer to use `import_result_bq_sink`.
        #[deprecated]
        #[prost(message, tag = "12")]
        PartialFailureBigquerySink(super::BigQueryDestination),
    }
    /// Optional. If provided, all successfully imported files and all partial
    /// failures are written to the sink.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum ImportResultSink {
        /// The Cloud Storage path to write import result to.
        #[prost(message, tag = "14")]
        ImportResultGcsSink(super::GcsDestination),
        /// The BigQuery destination to write import result to. It should be a
        /// bigquery table resource name (e.g.
        /// "bq://projectId.bqDatasetId.bqTableId"). The dataset must exist. If the
        /// table does not exist, it will be created with the expected schema. If the
        /// table exists, the schema will be validated and data will be added to this
        /// existing table.
        #[prost(message, tag = "15")]
        ImportResultBigquerySink(super::BigQueryDestination),
    }
}
/// Configuration message for RagManagedDb used by RagEngine.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagManagedDbConfig {
    /// The tier of the RagManagedDb.
    #[prost(oneof = "rag_managed_db_config::Tier", tags = "4, 2, 3")]
    pub tier: ::core::option::Option<rag_managed_db_config::Tier>,
}
/// Nested message and enum types in `RagManagedDbConfig`.
pub mod rag_managed_db_config {
    /// Scaled tier offers production grade performance along with
    /// autoscaling functionality. It is suitable for customers with large
    /// amounts of data or performance sensitive workloads.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Scaled {}
    /// Basic tier is a cost-effective and low compute tier suitable for
    /// the following cases:
    ///
    /// * Experimenting with RagManagedDb.
    /// * Small data size.
    /// * Latency insensitive workload.
    /// * Only using RAG Engine with external vector DBs.
    ///
    /// NOTE: This is the default tier if not explicitly chosen.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Basic {}
    /// Disables the RAG Engine service and deletes all your data held
    /// within this service. This will halt the billing of the service.
    ///
    /// NOTE: Once deleted the data cannot be recovered. To start using
    /// RAG Engine again, you will need to update the tier by calling the
    /// UpdateRagEngineConfig API.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Unprovisioned {}
    /// The tier of the RagManagedDb.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Tier {
        /// Sets the RagManagedDb to the Scaled tier.
        #[prost(message, tag = "4")]
        Scaled(Scaled),
        /// Sets the RagManagedDb to the Basic tier.
        #[prost(message, tag = "2")]
        Basic(Basic),
        /// Sets the RagManagedDb to the Unprovisioned tier.
        #[prost(message, tag = "3")]
        Unprovisioned(Unprovisioned),
    }
}
/// Config for RagEngine.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RagEngineConfig {
    /// Identifier. The name of the RagEngineConfig.
    /// Format:
    /// `projects/{project}/locations/{location}/ragEngineConfig`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The config of the RagManagedDb used by RagEngine.
    #[prost(message, optional, tag = "2")]
    pub rag_managed_db_config: ::core::option::Option<RagManagedDbConfig>,
}
/// The base structured datatype containing multi-part content of a message.
///
/// A `Content` includes a `role` field designating the producer of the `Content`
/// and a `parts` field containing multi-part data that contains the content of
/// the message turn.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Content {
    /// Optional. The producer of the content. Must be either 'user' or 'model'.
    ///
    /// Useful to set for multi-turn conversations, otherwise can be left blank
    /// or unset.
    #[prost(string, tag = "1")]
    pub role: ::prost::alloc::string::String,
    /// Required. Ordered `Parts` that constitute a single message. Parts may have
    /// different IANA MIME types.
    #[prost(message, repeated, tag = "2")]
    pub parts: ::prost::alloc::vec::Vec<Part>,
}
/// A datatype containing media that is part of a multi-part `Content` message.
///
/// A `Part` consists of data which has an associated datatype. A `Part` can only
/// contain one of the accepted types in `Part.data`.
///
/// A `Part` must have a fixed IANA MIME type identifying the type and subtype
/// of the media if `inline_data` or `file_data` field is filled with raw bytes.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Part {
    /// Indicates if the part is thought from the model.
    #[prost(bool, tag = "10")]
    pub thought: bool,
    /// An opaque signature for the thought so it can be reused in subsequent
    /// requests.
    #[prost(bytes = "vec", tag = "11")]
    pub thought_signature: ::prost::alloc::vec::Vec<u8>,
    /// per part media resolution.
    /// Media resolution for the input media.
    #[prost(message, optional, tag = "12")]
    pub media_resolution: ::core::option::Option<part::MediaResolution>,
    #[prost(oneof = "part::Data", tags = "1, 2, 3, 5, 6, 8, 9")]
    pub data: ::core::option::Option<part::Data>,
    #[prost(oneof = "part::Metadata", tags = "4")]
    pub metadata: ::core::option::Option<part::Metadata>,
}
/// Nested message and enum types in `Part`.
pub mod part {
    /// per part media resolution.
    /// Media resolution for the input media.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct MediaResolution {
        #[prost(oneof = "media_resolution::Value", tags = "1")]
        pub value: ::core::option::Option<media_resolution::Value>,
    }
    /// Nested message and enum types in `MediaResolution`.
    pub mod media_resolution {
        /// The media resolution level.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum Level {
            /// Media resolution has not been set.
            MediaResolutionUnspecified = 0,
            /// Media resolution set to low.
            MediaResolutionLow = 1,
            /// Media resolution set to medium.
            MediaResolutionMedium = 2,
            /// Media resolution set to high.
            MediaResolutionHigh = 3,
            /// Media resolution set to ultra high. This is for image only.
            MediaResolutionUltraHigh = 4,
        }
        impl Level {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::MediaResolutionUnspecified => "MEDIA_RESOLUTION_UNSPECIFIED",
                    Self::MediaResolutionLow => "MEDIA_RESOLUTION_LOW",
                    Self::MediaResolutionMedium => "MEDIA_RESOLUTION_MEDIUM",
                    Self::MediaResolutionHigh => "MEDIA_RESOLUTION_HIGH",
                    Self::MediaResolutionUltraHigh => "MEDIA_RESOLUTION_ULTRA_HIGH",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "MEDIA_RESOLUTION_UNSPECIFIED" => {
                        Some(Self::MediaResolutionUnspecified)
                    }
                    "MEDIA_RESOLUTION_LOW" => Some(Self::MediaResolutionLow),
                    "MEDIA_RESOLUTION_MEDIUM" => Some(Self::MediaResolutionMedium),
                    "MEDIA_RESOLUTION_HIGH" => Some(Self::MediaResolutionHigh),
                    "MEDIA_RESOLUTION_ULTRA_HIGH" => Some(Self::MediaResolutionUltraHigh),
                    _ => None,
                }
            }
        }
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum Value {
            /// The tokenization quality used for given media.
            #[prost(enumeration = "Level", tag = "1")]
            Level(i32),
        }
    }
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Data {
        /// Optional. Text part (can be code).
        #[prost(string, tag = "1")]
        Text(::prost::alloc::string::String),
        /// Optional. Inlined bytes data.
        #[prost(message, tag = "2")]
        InlineData(super::Blob),
        /// Optional. URI based data.
        #[prost(message, tag = "3")]
        FileData(super::FileData),
        /// Optional. A predicted \[FunctionCall\] returned from the model that
        /// contains a string representing the \[FunctionDeclaration.name\] with the
        /// parameters and their values.
        #[prost(message, tag = "5")]
        FunctionCall(super::FunctionCall),
        /// Optional. The result output of a \[FunctionCall\] that contains a string
        /// representing the \[FunctionDeclaration.name\] and a structured JSON object
        /// containing any output from the function call. It is used as context to
        /// the model.
        #[prost(message, tag = "6")]
        FunctionResponse(super::FunctionResponse),
        /// Optional. Code generated by the model that is meant to be executed.
        #[prost(message, tag = "8")]
        ExecutableCode(super::ExecutableCode),
        /// Optional. Result of executing the \[ExecutableCode\].
        #[prost(message, tag = "9")]
        CodeExecutionResult(super::CodeExecutionResult),
    }
    #[derive(Clone, Copy, PartialEq, ::prost::Oneof)]
    pub enum Metadata {
        /// Optional. Video metadata. The metadata should only be specified while the
        /// video data is presented in inline_data or file_data.
        #[prost(message, tag = "4")]
        VideoMetadata(super::VideoMetadata),
    }
}
/// Content blob.
///
/// It's preferred to send as \[text\]\[google.cloud.aiplatform.v1.Part.text\]
/// directly rather than raw bytes.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Blob {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. Raw bytes.
    #[prost(bytes = "vec", tag = "2")]
    pub data: ::prost::alloc::vec::Vec<u8>,
}
/// URI based data.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FileData {
    /// Required. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. URI.
    #[prost(string, tag = "2")]
    pub file_uri: ::prost::alloc::string::String,
}
/// Metadata describes the input video content.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct VideoMetadata {
    /// Optional. The start offset of the video.
    #[prost(message, optional, tag = "1")]
    pub start_offset: ::core::option::Option<super::super::super::protobuf::Duration>,
    /// Optional. The end offset of the video.
    #[prost(message, optional, tag = "2")]
    pub end_offset: ::core::option::Option<super::super::super::protobuf::Duration>,
    /// Optional. The frame rate of the video sent to the model. If not specified,
    /// the default value is 1.0. The valid range is (0.0, 24.0\].
    #[prost(double, tag = "3")]
    pub fps: f64,
}
/// Configuration for a prebuilt voice.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct PrebuiltVoiceConfig {
    /// The name of the prebuilt voice to use.
    #[prost(string, optional, tag = "1")]
    pub voice_name: ::core::option::Option<::prost::alloc::string::String>,
}
/// The configuration for the replicated voice to use.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ReplicatedVoiceConfig {
    /// Optional. The mimetype of the voice sample. The only currently supported
    /// value is `audio/wav`. This represents 16-bit signed little-endian wav data,
    /// with a 24kHz sampling rate. `mime_type` will default to `audio/wav` if not
    /// set.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Optional. The sample of the custom voice.
    #[prost(bytes = "vec", tag = "2")]
    pub voice_sample_audio: ::prost::alloc::vec::Vec<u8>,
}
/// Configuration for a voice.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct VoiceConfig {
    /// The configuration for the speaker to use.
    #[prost(oneof = "voice_config::VoiceConfig", tags = "1, 3")]
    pub voice_config: ::core::option::Option<voice_config::VoiceConfig>,
}
/// Nested message and enum types in `VoiceConfig`.
pub mod voice_config {
    /// The configuration for the speaker to use.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum VoiceConfig {
        /// The configuration for a prebuilt voice.
        #[prost(message, tag = "1")]
        PrebuiltVoiceConfig(super::PrebuiltVoiceConfig),
        /// Optional. The configuration for a replicated voice. This enables users to
        /// replicate a voice from an audio sample.
        #[prost(message, tag = "3")]
        ReplicatedVoiceConfig(super::ReplicatedVoiceConfig),
    }
}
/// Configuration for a single speaker in a multi-speaker setup.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SpeakerVoiceConfig {
    /// Required. The name of the speaker. This should be the same as the speaker
    /// name used in the prompt.
    #[prost(string, tag = "1")]
    pub speaker: ::prost::alloc::string::String,
    /// Required. The configuration for the voice of this speaker.
    #[prost(message, optional, tag = "2")]
    pub voice_config: ::core::option::Option<VoiceConfig>,
}
/// Configuration for a multi-speaker text-to-speech request.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct MultiSpeakerVoiceConfig {
    /// Required. A list of configurations for the voices of the speakers. Exactly
    /// two speaker voice configurations must be provided.
    #[prost(message, repeated, tag = "2")]
    pub speaker_voice_configs: ::prost::alloc::vec::Vec<SpeakerVoiceConfig>,
}
/// Configuration for speech generation.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SpeechConfig {
    /// The configuration for the voice to use.
    #[prost(message, optional, tag = "1")]
    pub voice_config: ::core::option::Option<VoiceConfig>,
    /// Optional. The language code (ISO 639-1) for the speech synthesis.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
    /// The configuration for a multi-speaker text-to-speech request.
    /// This field is mutually exclusive with `voice_config`.
    #[prost(message, optional, tag = "3")]
    pub multi_speaker_voice_config: ::core::option::Option<MultiSpeakerVoiceConfig>,
}
/// Config for image generation features.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ImageConfig {
    /// Optional. The image output format for generated images.
    #[prost(message, optional, tag = "1")]
    pub image_output_options: ::core::option::Option<image_config::ImageOutputOptions>,
    /// Optional. The desired aspect ratio for the generated images. The following
    /// aspect ratios are supported:
    ///
    /// "1:1"
    /// "2:3", "3:2"
    /// "3:4", "4:3"
    /// "4:5", "5:4"
    /// "9:16", "16:9"
    /// "21:9"
    #[prost(string, optional, tag = "2")]
    pub aspect_ratio: ::core::option::Option<::prost::alloc::string::String>,
    /// Optional. Controls whether the model can generate people.
    #[prost(enumeration = "image_config::PersonGeneration", optional, tag = "3")]
    pub person_generation: ::core::option::Option<i32>,
    /// Optional. Specifies the size of generated images. Supported values are
    /// `1K`, `2K`, `4K`. If not specified, the model will use default value `1K`.
    #[prost(string, optional, tag = "4")]
    pub image_size: ::core::option::Option<::prost::alloc::string::String>,
}
/// Nested message and enum types in `ImageConfig`.
pub mod image_config {
    /// The image output format for generated images.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ImageOutputOptions {
        /// Optional. The image format that the output should be saved as.
        #[prost(string, optional, tag = "1")]
        pub mime_type: ::core::option::Option<::prost::alloc::string::String>,
        /// Optional. The compression quality of the output image.
        #[prost(int32, optional, tag = "2")]
        pub compression_quality: ::core::option::Option<i32>,
    }
    /// Enum for controlling the generation of people in images.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum PersonGeneration {
        /// The default behavior is unspecified. The model will decide whether to
        /// generate images of people.
        Unspecified = 0,
        /// Allows the model to generate images of people, including adults and
        /// children.
        AllowAll = 1,
        /// Allows the model to generate images of adults, but not children.
        AllowAdult = 2,
        /// Prevents the model from generating images of people.
        AllowNone = 3,
    }
    impl PersonGeneration {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "PERSON_GENERATION_UNSPECIFIED",
                Self::AllowAll => "ALLOW_ALL",
                Self::AllowAdult => "ALLOW_ADULT",
                Self::AllowNone => "ALLOW_NONE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PERSON_GENERATION_UNSPECIFIED" => Some(Self::Unspecified),
                "ALLOW_ALL" => Some(Self::AllowAll),
                "ALLOW_ADULT" => Some(Self::AllowAdult),
                "ALLOW_NONE" => Some(Self::AllowNone),
                _ => None,
            }
        }
    }
}
/// Generation config.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerationConfig {
    /// Optional. Controls the randomness of predictions.
    #[prost(float, optional, tag = "1")]
    pub temperature: ::core::option::Option<f32>,
    /// Optional. If specified, nucleus sampling will be used.
    #[prost(float, optional, tag = "2")]
    pub top_p: ::core::option::Option<f32>,
    /// Optional. If specified, top-k sampling will be used.
    #[prost(float, optional, tag = "3")]
    pub top_k: ::core::option::Option<f32>,
    /// Optional. Number of candidates to generate.
    #[prost(int32, optional, tag = "4")]
    pub candidate_count: ::core::option::Option<i32>,
    /// Optional. The maximum number of output tokens to generate per message.
    #[prost(int32, optional, tag = "5")]
    pub max_output_tokens: ::core::option::Option<i32>,
    /// Optional. Stop sequences.
    #[prost(string, repeated, tag = "6")]
    pub stop_sequences: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. If true, export the logprobs results in response.
    #[prost(bool, optional, tag = "18")]
    pub response_logprobs: ::core::option::Option<bool>,
    /// Optional. Logit probabilities.
    #[prost(int32, optional, tag = "7")]
    pub logprobs: ::core::option::Option<i32>,
    /// Optional. Positive penalties.
    #[prost(float, optional, tag = "8")]
    pub presence_penalty: ::core::option::Option<f32>,
    /// Optional. Frequency penalties.
    #[prost(float, optional, tag = "9")]
    pub frequency_penalty: ::core::option::Option<f32>,
    /// Optional. Seed.
    #[prost(int32, optional, tag = "12")]
    pub seed: ::core::option::Option<i32>,
    /// Optional. Output response mimetype of the generated candidate text.
    /// Supported mimetype:
    ///
    /// * `text/plain`: (default) Text output.
    /// * `application/json`: JSON response in the candidates.
    ///   The model needs to be prompted to output the appropriate response type,
    ///   otherwise the behavior is undefined.
    ///   This is a preview feature.
    #[prost(string, tag = "13")]
    pub response_mime_type: ::prost::alloc::string::String,
    /// Optional. The `Schema` object allows the definition of input and output
    /// data types. These types can be objects, but also primitives and arrays.
    /// Represents a select subset of an [OpenAPI 3.0 schema
    /// object](<https://spec.openapis.org/oas/v3.0.3#schema>).
    /// If set, a compatible response_mime_type must also be set.
    /// Compatible mimetypes:
    /// `application/json`: Schema for JSON response.
    #[prost(message, optional, tag = "16")]
    pub response_schema: ::core::option::Option<Schema>,
    /// Optional. Output schema of the generated response. This is an alternative
    /// to `response_schema` that accepts [JSON Schema](<https://json-schema.org/>).
    ///
    /// If set, `response_schema` must be omitted, but `response_mime_type` is
    /// required.
    ///
    /// While the full JSON Schema may be sent, not all features are supported.
    /// Specifically, only the following properties are supported:
    ///
    /// * `$id`
    /// * `$defs`
    /// * `$ref`
    /// * `$anchor`
    /// * `type`
    /// * `format`
    /// * `title`
    /// * `description`
    /// * `enum` (for strings and numbers)
    /// * `items`
    /// * `prefixItems`
    /// * `minItems`
    /// * `maxItems`
    /// * `minimum`
    /// * `maximum`
    /// * `anyOf`
    /// * `oneOf` (interpreted the same as `anyOf`)
    /// * `properties`
    /// * `additionalProperties`
    /// * `required`
    ///
    /// The non-standard `propertyOrdering` property may also be set.
    ///
    /// Cyclic references are unrolled to a limited degree and, as such, may only
    /// be used within non-required properties. (Nullable properties are not
    /// sufficient.) If `$ref` is set on a sub-schema, no other properties, except
    /// for than those starting as a `$`, may be set.
    #[prost(message, optional, tag = "28")]
    pub response_json_schema: ::core::option::Option<
        super::super::super::protobuf::Value,
    >,
    /// Optional. Routing configuration.
    #[prost(message, optional, tag = "17")]
    pub routing_config: ::core::option::Option<generation_config::RoutingConfig>,
    /// Optional. If enabled, audio timestamps will be included in the request to
    /// the model. This can be useful for synchronizing audio with other modalities
    /// in the response.
    #[prost(bool, optional, tag = "20")]
    pub audio_timestamp: ::core::option::Option<bool>,
    /// Optional. The modalities of the response. The model will generate a
    /// response that includes all the specified modalities. For example, if this
    /// is set to `\[TEXT, IMAGE\]`, the response will include both text and an
    /// image.
    #[prost(
        enumeration = "generation_config::Modality",
        repeated,
        packed = "false",
        tag = "21"
    )]
    pub response_modalities: ::prost::alloc::vec::Vec<i32>,
    /// Optional. The token resolution at which input media content is sampled.
    /// This is used to control the trade-off between the quality of the response
    /// and the number of tokens used to represent the media. A higher resolution
    /// allows the model to perceive more detail, which can lead to a more nuanced
    /// response, but it will also use more tokens. This does not affect the
    /// image dimensions sent to the model.
    #[prost(enumeration = "generation_config::MediaResolution", optional, tag = "22")]
    pub media_resolution: ::core::option::Option<i32>,
    /// Optional. The speech generation config.
    #[prost(message, optional, tag = "23")]
    pub speech_config: ::core::option::Option<SpeechConfig>,
    /// Optional. Config for thinking features.
    /// An error will be returned if this field is set for models that don't
    /// support thinking.
    #[prost(message, optional, tag = "25")]
    pub thinking_config: ::core::option::Option<generation_config::ThinkingConfig>,
    /// Optional. Config for image generation features.
    #[prost(message, optional, tag = "30")]
    pub image_config: ::core::option::Option<ImageConfig>,
}
/// Nested message and enum types in `GenerationConfig`.
pub mod generation_config {
    /// The configuration for routing the request to a specific model.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct RoutingConfig {
        /// Routing mode.
        #[prost(oneof = "routing_config::RoutingConfig", tags = "1, 2")]
        pub routing_config: ::core::option::Option<routing_config::RoutingConfig>,
    }
    /// Nested message and enum types in `RoutingConfig`.
    pub mod routing_config {
        /// When automated routing is specified, the routing will be determined by
        /// the pretrained routing model and customer provided model routing
        /// preference.
        #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct AutoRoutingMode {
            /// The model routing preference.
            #[prost(
                enumeration = "auto_routing_mode::ModelRoutingPreference",
                optional,
                tag = "1"
            )]
            pub model_routing_preference: ::core::option::Option<i32>,
        }
        /// Nested message and enum types in `AutoRoutingMode`.
        pub mod auto_routing_mode {
            /// The model routing preference.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum ModelRoutingPreference {
                /// Unspecified model routing preference.
                Unknown = 0,
                /// Prefer higher quality over low cost.
                PrioritizeQuality = 1,
                /// Balanced model routing preference.
                Balanced = 2,
                /// Prefer lower cost over higher quality.
                PrioritizeCost = 3,
            }
            impl ModelRoutingPreference {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Self::Unknown => "UNKNOWN",
                        Self::PrioritizeQuality => "PRIORITIZE_QUALITY",
                        Self::Balanced => "BALANCED",
                        Self::PrioritizeCost => "PRIORITIZE_COST",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "UNKNOWN" => Some(Self::Unknown),
                        "PRIORITIZE_QUALITY" => Some(Self::PrioritizeQuality),
                        "BALANCED" => Some(Self::Balanced),
                        "PRIORITIZE_COST" => Some(Self::PrioritizeCost),
                        _ => None,
                    }
                }
            }
        }
        /// When manual routing is set, the specified model will be used directly.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
        pub struct ManualRoutingMode {
            /// The model name to use. Only the public LLM models are accepted. e.g.
            /// 'gemini-1.5-pro-001'.
            #[prost(string, optional, tag = "1")]
            pub model_name: ::core::option::Option<::prost::alloc::string::String>,
        }
        /// Routing mode.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum RoutingConfig {
            /// Automated routing.
            #[prost(message, tag = "1")]
            AutoMode(AutoRoutingMode),
            /// Manual routing.
            #[prost(message, tag = "2")]
            ManualMode(ManualRoutingMode),
        }
    }
    /// Config for thinking features.
    #[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ThinkingConfig {
        /// Indicates whether to include thoughts in the response.
        /// If true, thoughts are returned only when available.
        #[prost(bool, optional, tag = "1")]
        pub include_thoughts: ::core::option::Option<bool>,
        /// Optional. Indicates the thinking budget in tokens.
        /// This is only applied when enable_thinking is true.
        #[prost(int32, optional, tag = "3")]
        pub thinking_budget: ::core::option::Option<i32>,
        /// Optional. The number of thoughts tokens that the model should generate.
        #[prost(enumeration = "thinking_config::ThinkingLevel", optional, tag = "4")]
        pub thinking_level: ::core::option::Option<i32>,
    }
    /// Nested message and enum types in `ThinkingConfig`.
    pub mod thinking_config {
        /// The thinking level for the model.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum ThinkingLevel {
            /// Unspecified thinking level.
            Unspecified = 0,
            /// Low thinking level.
            Low = 1,
            /// Medium thinking level.
            Medium = 2,
            /// High thinking level.
            High = 3,
            /// MINIMAL thinking level.
            Minimal = 4,
        }
        impl ThinkingLevel {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "THINKING_LEVEL_UNSPECIFIED",
                    Self::Low => "LOW",
                    Self::Medium => "MEDIUM",
                    Self::High => "HIGH",
                    Self::Minimal => "MINIMAL",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "THINKING_LEVEL_UNSPECIFIED" => Some(Self::Unspecified),
                    "LOW" => Some(Self::Low),
                    "MEDIUM" => Some(Self::Medium),
                    "HIGH" => Some(Self::High),
                    "MINIMAL" => Some(Self::Minimal),
                    _ => None,
                }
            }
        }
    }
    /// The modalities of the response.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Modality {
        /// Unspecified modality. Will be processed as text.
        Unspecified = 0,
        /// Text modality.
        Text = 1,
        /// Image modality.
        Image = 2,
        /// Audio modality.
        Audio = 3,
    }
    impl Modality {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODALITY_UNSPECIFIED",
                Self::Text => "TEXT",
                Self::Image => "IMAGE",
                Self::Audio => "AUDIO",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
                "TEXT" => Some(Self::Text),
                "IMAGE" => Some(Self::Image),
                "AUDIO" => Some(Self::Audio),
                _ => None,
            }
        }
    }
    /// Media resolution for the input media.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum MediaResolution {
        /// Media resolution has not been set.
        Unspecified = 0,
        /// Media resolution set to low (64 tokens).
        Low = 1,
        /// Media resolution set to medium (256 tokens).
        Medium = 2,
        /// Media resolution set to high (zoomed reframing with 256 tokens).
        High = 3,
    }
    impl MediaResolution {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MEDIA_RESOLUTION_UNSPECIFIED",
                Self::Low => "MEDIA_RESOLUTION_LOW",
                Self::Medium => "MEDIA_RESOLUTION_MEDIUM",
                Self::High => "MEDIA_RESOLUTION_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MEDIA_RESOLUTION_UNSPECIFIED" => Some(Self::Unspecified),
                "MEDIA_RESOLUTION_LOW" => Some(Self::Low),
                "MEDIA_RESOLUTION_MEDIUM" => Some(Self::Medium),
                "MEDIA_RESOLUTION_HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// Safety settings.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SafetySetting {
    /// Required. Harm category.
    #[prost(enumeration = "HarmCategory", tag = "1")]
    pub category: i32,
    /// Required. The harm block threshold.
    #[prost(enumeration = "safety_setting::HarmBlockThreshold", tag = "2")]
    pub threshold: i32,
    /// Optional. Specify if the threshold is used for probability or severity
    /// score. If not specified, the threshold is used for probability score.
    #[prost(enumeration = "safety_setting::HarmBlockMethod", tag = "4")]
    pub method: i32,
}
/// Nested message and enum types in `SafetySetting`.
pub mod safety_setting {
    /// Probability based thresholds levels for blocking.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmBlockThreshold {
        /// Unspecified harm block threshold.
        Unspecified = 0,
        /// Block low threshold and above (i.e. block more).
        BlockLowAndAbove = 1,
        /// Block medium threshold and above.
        BlockMediumAndAbove = 2,
        /// Block only high threshold (i.e. block less).
        BlockOnlyHigh = 3,
        /// Block none.
        BlockNone = 4,
        /// Turn off the safety filter.
        Off = 5,
    }
    impl HarmBlockThreshold {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                Self::BlockLowAndAbove => "BLOCK_LOW_AND_ABOVE",
                Self::BlockMediumAndAbove => "BLOCK_MEDIUM_AND_ABOVE",
                Self::BlockOnlyHigh => "BLOCK_ONLY_HIGH",
                Self::BlockNone => "BLOCK_NONE",
                Self::Off => "OFF",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_BLOCK_THRESHOLD_UNSPECIFIED" => Some(Self::Unspecified),
                "BLOCK_LOW_AND_ABOVE" => Some(Self::BlockLowAndAbove),
                "BLOCK_MEDIUM_AND_ABOVE" => Some(Self::BlockMediumAndAbove),
                "BLOCK_ONLY_HIGH" => Some(Self::BlockOnlyHigh),
                "BLOCK_NONE" => Some(Self::BlockNone),
                "OFF" => Some(Self::Off),
                _ => None,
            }
        }
    }
    /// Probability vs severity.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmBlockMethod {
        /// The harm block method is unspecified.
        Unspecified = 0,
        /// The harm block method uses both probability and severity scores.
        Severity = 1,
        /// The harm block method uses the probability score.
        Probability = 2,
    }
    impl HarmBlockMethod {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_BLOCK_METHOD_UNSPECIFIED",
                Self::Severity => "SEVERITY",
                Self::Probability => "PROBABILITY",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_BLOCK_METHOD_UNSPECIFIED" => Some(Self::Unspecified),
                "SEVERITY" => Some(Self::Severity),
                "PROBABILITY" => Some(Self::Probability),
                _ => None,
            }
        }
    }
}
/// Safety rating corresponding to the generated content.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct SafetyRating {
    /// Output only. Harm category.
    #[prost(enumeration = "HarmCategory", tag = "1")]
    pub category: i32,
    /// Output only. Harm probability levels in the content.
    #[prost(enumeration = "safety_rating::HarmProbability", tag = "2")]
    pub probability: i32,
    /// Output only. Harm probability score.
    #[prost(float, tag = "5")]
    pub probability_score: f32,
    /// Output only. Harm severity levels in the content.
    #[prost(enumeration = "safety_rating::HarmSeverity", tag = "6")]
    pub severity: i32,
    /// Output only. Harm severity score.
    #[prost(float, tag = "7")]
    pub severity_score: f32,
    /// Output only. Indicates whether the content was filtered out because of this
    /// rating.
    #[prost(bool, tag = "3")]
    pub blocked: bool,
}
/// Nested message and enum types in `SafetyRating`.
pub mod safety_rating {
    /// Harm probability levels in the content.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmProbability {
        /// Harm probability unspecified.
        Unspecified = 0,
        /// Negligible level of harm.
        Negligible = 1,
        /// Low level of harm.
        Low = 2,
        /// Medium level of harm.
        Medium = 3,
        /// High level of harm.
        High = 4,
    }
    impl HarmProbability {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_PROBABILITY_UNSPECIFIED",
                Self::Negligible => "NEGLIGIBLE",
                Self::Low => "LOW",
                Self::Medium => "MEDIUM",
                Self::High => "HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_PROBABILITY_UNSPECIFIED" => Some(Self::Unspecified),
                "NEGLIGIBLE" => Some(Self::Negligible),
                "LOW" => Some(Self::Low),
                "MEDIUM" => Some(Self::Medium),
                "HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
    /// Harm severity levels.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum HarmSeverity {
        /// Harm severity unspecified.
        Unspecified = 0,
        /// Negligible level of harm severity.
        Negligible = 1,
        /// Low level of harm severity.
        Low = 2,
        /// Medium level of harm severity.
        Medium = 3,
        /// High level of harm severity.
        High = 4,
    }
    impl HarmSeverity {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_SEVERITY_UNSPECIFIED",
                Self::Negligible => "HARM_SEVERITY_NEGLIGIBLE",
                Self::Low => "HARM_SEVERITY_LOW",
                Self::Medium => "HARM_SEVERITY_MEDIUM",
                Self::High => "HARM_SEVERITY_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_SEVERITY_UNSPECIFIED" => Some(Self::Unspecified),
                "HARM_SEVERITY_NEGLIGIBLE" => Some(Self::Negligible),
                "HARM_SEVERITY_LOW" => Some(Self::Low),
                "HARM_SEVERITY_MEDIUM" => Some(Self::Medium),
                "HARM_SEVERITY_HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// A collection of source attributions for a piece of content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CitationMetadata {
    /// Output only. List of citations.
    #[prost(message, repeated, tag = "1")]
    pub citations: ::prost::alloc::vec::Vec<Citation>,
}
/// Source attributions for content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Citation {
    /// Output only. Start index into the content.
    #[prost(int32, tag = "1")]
    pub start_index: i32,
    /// Output only. End index into the content.
    #[prost(int32, tag = "2")]
    pub end_index: i32,
    /// Output only. Url reference of the attribution.
    #[prost(string, tag = "3")]
    pub uri: ::prost::alloc::string::String,
    /// Output only. Title of the attribution.
    #[prost(string, tag = "4")]
    pub title: ::prost::alloc::string::String,
    /// Output only. License of the attribution.
    #[prost(string, tag = "5")]
    pub license: ::prost::alloc::string::String,
    /// Output only. Publication date of the attribution.
    #[prost(message, optional, tag = "6")]
    pub publication_date: ::core::option::Option<super::super::super::r#type::Date>,
}
/// A response candidate generated from the model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Candidate {
    /// Output only. Index of the candidate.
    #[prost(int32, tag = "1")]
    pub index: i32,
    /// Output only. Content parts of the candidate.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
    /// Output only. Confidence score of the candidate.
    #[prost(double, tag = "8")]
    pub score: f64,
    /// Output only. Average log probability score of the candidate.
    #[prost(double, tag = "9")]
    pub avg_logprobs: f64,
    /// Output only. Log-likelihood scores for the response tokens and top tokens
    #[prost(message, optional, tag = "10")]
    pub logprobs_result: ::core::option::Option<LogprobsResult>,
    /// Output only. The reason why the model stopped generating tokens.
    /// If empty, the model has not stopped generating the tokens.
    #[prost(enumeration = "candidate::FinishReason", tag = "3")]
    pub finish_reason: i32,
    /// Output only. List of ratings for the safety of a response candidate.
    ///
    /// There is at most one rating per category.
    #[prost(message, repeated, tag = "4")]
    pub safety_ratings: ::prost::alloc::vec::Vec<SafetyRating>,
    /// Output only. Describes the reason the mode stopped generating tokens in
    /// more detail. This is only filled when `finish_reason` is set.
    #[prost(string, optional, tag = "5")]
    pub finish_message: ::core::option::Option<::prost::alloc::string::String>,
    /// Output only. Source attribution of the generated content.
    #[prost(message, optional, tag = "6")]
    pub citation_metadata: ::core::option::Option<CitationMetadata>,
    /// Output only. Metadata specifies sources used to ground generated content.
    #[prost(message, optional, tag = "7")]
    pub grounding_metadata: ::core::option::Option<GroundingMetadata>,
    /// Output only. Metadata related to url context retrieval tool.
    #[prost(message, optional, tag = "11")]
    pub url_context_metadata: ::core::option::Option<UrlContextMetadata>,
}
/// Nested message and enum types in `Candidate`.
pub mod candidate {
    /// The reason why the model stopped generating tokens.
    /// If empty, the model has not stopped generating the tokens.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum FinishReason {
        /// The finish reason is unspecified.
        Unspecified = 0,
        /// Token generation reached a natural stopping point or a configured stop
        /// sequence.
        Stop = 1,
        /// Token generation reached the configured maximum output tokens.
        MaxTokens = 2,
        /// Token generation stopped because the content potentially contains safety
        /// violations. NOTE: When streaming,
        /// \[content\]\[google.cloud.aiplatform.v1.Candidate.content\] is empty if
        /// content filters blocks the output.
        Safety = 3,
        /// Token generation stopped because the content potentially contains
        /// copyright violations.
        Recitation = 4,
        /// All other reasons that stopped the token generation.
        Other = 5,
        /// Token generation stopped because the content contains forbidden terms.
        Blocklist = 6,
        /// Token generation stopped for potentially containing prohibited content.
        ProhibitedContent = 7,
        /// Token generation stopped because the content potentially contains
        /// Sensitive Personally Identifiable Information (SPII).
        Spii = 8,
        /// The function call generated by the model is invalid.
        MalformedFunctionCall = 9,
        /// The model response was blocked by Model Armor.
        ModelArmor = 10,
    }
    impl FinishReason {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "FINISH_REASON_UNSPECIFIED",
                Self::Stop => "STOP",
                Self::MaxTokens => "MAX_TOKENS",
                Self::Safety => "SAFETY",
                Self::Recitation => "RECITATION",
                Self::Other => "OTHER",
                Self::Blocklist => "BLOCKLIST",
                Self::ProhibitedContent => "PROHIBITED_CONTENT",
                Self::Spii => "SPII",
                Self::MalformedFunctionCall => "MALFORMED_FUNCTION_CALL",
                Self::ModelArmor => "MODEL_ARMOR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "FINISH_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                "STOP" => Some(Self::Stop),
                "MAX_TOKENS" => Some(Self::MaxTokens),
                "SAFETY" => Some(Self::Safety),
                "RECITATION" => Some(Self::Recitation),
                "OTHER" => Some(Self::Other),
                "BLOCKLIST" => Some(Self::Blocklist),
                "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                "SPII" => Some(Self::Spii),
                "MALFORMED_FUNCTION_CALL" => Some(Self::MalformedFunctionCall),
                "MODEL_ARMOR" => Some(Self::ModelArmor),
                _ => None,
            }
        }
    }
}
/// Metadata related to url context retrieval tool.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UrlContextMetadata {
    /// Output only. List of url context.
    #[prost(message, repeated, tag = "1")]
    pub url_metadata: ::prost::alloc::vec::Vec<UrlMetadata>,
}
/// Context of the a single url retrieval.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct UrlMetadata {
    /// Retrieved url by the tool.
    #[prost(string, tag = "1")]
    pub retrieved_url: ::prost::alloc::string::String,
    /// Status of the url retrieval.
    #[prost(enumeration = "url_metadata::UrlRetrievalStatus", tag = "2")]
    pub url_retrieval_status: i32,
}
/// Nested message and enum types in `UrlMetadata`.
pub mod url_metadata {
    /// Status of the url retrieval.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum UrlRetrievalStatus {
        /// Default value. This value is unused.
        Unspecified = 0,
        /// Url retrieval is successful.
        Success = 1,
        /// Url retrieval is failed due to error.
        Error = 2,
    }
    impl UrlRetrievalStatus {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "URL_RETRIEVAL_STATUS_UNSPECIFIED",
                Self::Success => "URL_RETRIEVAL_STATUS_SUCCESS",
                Self::Error => "URL_RETRIEVAL_STATUS_ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "URL_RETRIEVAL_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
                "URL_RETRIEVAL_STATUS_SUCCESS" => Some(Self::Success),
                "URL_RETRIEVAL_STATUS_ERROR" => Some(Self::Error),
                _ => None,
            }
        }
    }
}
/// Logprobs Result
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LogprobsResult {
    /// Length = total number of decoding steps.
    #[prost(message, repeated, tag = "1")]
    pub top_candidates: ::prost::alloc::vec::Vec<logprobs_result::TopCandidates>,
    /// Length = total number of decoding steps.
    /// The chosen candidates may or may not be in top_candidates.
    #[prost(message, repeated, tag = "2")]
    pub chosen_candidates: ::prost::alloc::vec::Vec<logprobs_result::Candidate>,
}
/// Nested message and enum types in `LogprobsResult`.
pub mod logprobs_result {
    /// Candidate for the logprobs token and score.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Candidate {
        /// The candidates token string value.
        #[prost(string, optional, tag = "1")]
        pub token: ::core::option::Option<::prost::alloc::string::String>,
        /// The candidates token id value.
        #[prost(int32, optional, tag = "3")]
        pub token_id: ::core::option::Option<i32>,
        /// The candidate's log probability.
        #[prost(float, optional, tag = "2")]
        pub log_probability: ::core::option::Option<f32>,
    }
    /// Candidates with top log probabilities at each decoding step.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct TopCandidates {
        /// Sorted by log probability in descending order.
        #[prost(message, repeated, tag = "1")]
        pub candidates: ::prost::alloc::vec::Vec<Candidate>,
    }
}
/// Segment of the content.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Segment {
    /// Output only. The index of a Part object within its parent Content object.
    #[prost(int32, tag = "1")]
    pub part_index: i32,
    /// Output only. Start index in the given Part, measured in bytes. Offset from
    /// the start of the Part, inclusive, starting at zero.
    #[prost(int32, tag = "2")]
    pub start_index: i32,
    /// Output only. End index in the given Part, measured in bytes. Offset from
    /// the start of the Part, exclusive, starting at zero.
    #[prost(int32, tag = "3")]
    pub end_index: i32,
    /// Output only. The text corresponding to the segment from the response.
    #[prost(string, tag = "4")]
    pub text: ::prost::alloc::string::String,
}
/// Grounding chunk.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingChunk {
    /// Chunk type.
    #[prost(oneof = "grounding_chunk::ChunkType", tags = "1, 2, 3")]
    pub chunk_type: ::core::option::Option<grounding_chunk::ChunkType>,
}
/// Nested message and enum types in `GroundingChunk`.
pub mod grounding_chunk {
    /// Chunk from the web.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct Web {
        /// URI reference of the chunk.
        #[prost(string, optional, tag = "1")]
        pub uri: ::core::option::Option<::prost::alloc::string::String>,
        /// Title of the chunk.
        #[prost(string, optional, tag = "2")]
        pub title: ::core::option::Option<::prost::alloc::string::String>,
    }
    /// Chunk from context retrieved by the retrieval tools.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct RetrievedContext {
        /// URI reference of the attribution.
        #[prost(string, optional, tag = "1")]
        pub uri: ::core::option::Option<::prost::alloc::string::String>,
        /// Title of the attribution.
        #[prost(string, optional, tag = "2")]
        pub title: ::core::option::Option<::prost::alloc::string::String>,
        /// Text of the attribution.
        #[prost(string, optional, tag = "3")]
        pub text: ::core::option::Option<::prost::alloc::string::String>,
        /// Output only. The full document name for the referenced Vertex AI Search
        /// document.
        #[prost(string, optional, tag = "6")]
        pub document_name: ::core::option::Option<::prost::alloc::string::String>,
        /// Tool-specific details about the retrieved context.
        #[prost(oneof = "retrieved_context::ContextDetails", tags = "4")]
        pub context_details: ::core::option::Option<retrieved_context::ContextDetails>,
    }
    /// Nested message and enum types in `RetrievedContext`.
    pub mod retrieved_context {
        /// Tool-specific details about the retrieved context.
        #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
        pub enum ContextDetails {
            /// Additional context for the RAG retrieval result. This is only populated
            /// when using the RAG retrieval tool.
            #[prost(message, tag = "4")]
            RagChunk(super::super::RagChunk),
        }
    }
    /// Chunk from Google Maps.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Maps {
        /// URI reference of the chunk.
        #[prost(string, optional, tag = "1")]
        pub uri: ::core::option::Option<::prost::alloc::string::String>,
        /// Title of the chunk.
        #[prost(string, optional, tag = "2")]
        pub title: ::core::option::Option<::prost::alloc::string::String>,
        /// Text of the chunk.
        #[prost(string, optional, tag = "3")]
        pub text: ::core::option::Option<::prost::alloc::string::String>,
        /// This Place's resource name, in `places/{place_id}` format.  Can be used
        /// to look up the Place.
        #[prost(string, optional, tag = "4")]
        pub place_id: ::core::option::Option<::prost::alloc::string::String>,
        /// Sources used to generate the place answer.
        /// This includes review snippets and photos that were used to generate the
        /// answer, as well as uris to flag content.
        #[prost(message, optional, tag = "5")]
        pub place_answer_sources: ::core::option::Option<maps::PlaceAnswerSources>,
    }
    /// Nested message and enum types in `Maps`.
    pub mod maps {
        #[derive(Clone, PartialEq, ::prost::Message)]
        pub struct PlaceAnswerSources {
            /// Snippets of reviews that are used to generate the answer.
            #[prost(message, repeated, tag = "1")]
            pub review_snippets: ::prost::alloc::vec::Vec<
                place_answer_sources::ReviewSnippet,
            >,
        }
        /// Nested message and enum types in `PlaceAnswerSources`.
        pub mod place_answer_sources {
            /// Encapsulates a review snippet.
            #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
            pub struct ReviewSnippet {
                /// Id of the review referencing the place.
                #[prost(string, tag = "1")]
                pub review_id: ::prost::alloc::string::String,
                /// A link to show the review on Google Maps.
                #[prost(string, tag = "2")]
                pub google_maps_uri: ::prost::alloc::string::String,
                /// Title of the review.
                #[prost(string, tag = "3")]
                pub title: ::prost::alloc::string::String,
            }
        }
    }
    /// Chunk type.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum ChunkType {
        /// Grounding chunk from the web.
        #[prost(message, tag = "1")]
        Web(Web),
        /// Grounding chunk from context retrieved by the retrieval tools.
        #[prost(message, tag = "2")]
        RetrievedContext(RetrievedContext),
        /// Grounding chunk from Google Maps.
        #[prost(message, tag = "3")]
        Maps(Maps),
    }
}
/// Grounding support.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingSupport {
    /// Segment of the content this support belongs to.
    #[prost(message, optional, tag = "1")]
    pub segment: ::core::option::Option<Segment>,
    /// A list of indices (into 'grounding_chunk') specifying the
    /// citations associated with the claim. For instance \[1,3,4\] means
    /// that grounding_chunk\[1\], grounding_chunk\[3\],
    /// grounding_chunk\[4\] are the retrieved content attributed to the claim.
    #[prost(int32, repeated, tag = "2")]
    pub grounding_chunk_indices: ::prost::alloc::vec::Vec<i32>,
    /// Confidence score of the support references. Ranges from 0 to 1. 1 is the
    /// most confident. This list must have the same size as the
    /// grounding_chunk_indices.
    #[prost(float, repeated, tag = "3")]
    pub confidence_scores: ::prost::alloc::vec::Vec<f32>,
}
/// Metadata returned to client when grounding is enabled.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingMetadata {
    /// Optional. Web search queries for the following-up web search.
    #[prost(string, repeated, tag = "1")]
    pub web_search_queries: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Google search entry for the following-up web searches.
    #[prost(message, optional, tag = "4")]
    pub search_entry_point: ::core::option::Option<SearchEntryPoint>,
    /// List of supporting references retrieved from specified grounding source.
    #[prost(message, repeated, tag = "5")]
    pub grounding_chunks: ::prost::alloc::vec::Vec<GroundingChunk>,
    /// Optional. List of grounding support.
    #[prost(message, repeated, tag = "6")]
    pub grounding_supports: ::prost::alloc::vec::Vec<GroundingSupport>,
    /// Optional. Output only. Retrieval metadata.
    #[prost(message, optional, tag = "7")]
    pub retrieval_metadata: ::core::option::Option<RetrievalMetadata>,
    /// Optional. Output only. Resource name of the Google Maps widget context
    /// token to be used with the PlacesContextElement widget to render contextual
    /// data. This is populated only for Google Maps grounding.
    #[prost(string, optional, tag = "8")]
    pub google_maps_widget_context_token: ::core::option::Option<
        ::prost::alloc::string::String,
    >,
    /// List of source flagging uris. This is currently populated only for Google
    /// Maps grounding.
    #[prost(message, repeated, tag = "9")]
    pub source_flagging_uris: ::prost::alloc::vec::Vec<
        grounding_metadata::SourceFlaggingUri,
    >,
}
/// Nested message and enum types in `GroundingMetadata`.
pub mod grounding_metadata {
    /// Source content flagging uri for a place or review. This is currently
    /// populated only for Google Maps grounding.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct SourceFlaggingUri {
        /// Id of the place or review.
        #[prost(string, tag = "1")]
        pub source_id: ::prost::alloc::string::String,
        /// A link where users can flag a problem with the source (place or review).
        /// (-- The link is generated by Google and it does not contain
        /// information from the user query. It may contain information of the
        /// content it is flagging, which can be used to identify places. --)
        #[prost(string, tag = "2")]
        pub flag_content_uri: ::prost::alloc::string::String,
    }
}
/// Google search entry point.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SearchEntryPoint {
    /// Optional. Web content snippet that can be embedded in a web page or an app
    /// webview.
    #[prost(string, tag = "1")]
    pub rendered_content: ::prost::alloc::string::String,
    /// Optional. Base64 encoded JSON representing array of \<search term, search
    /// url> tuple.
    #[prost(bytes = "vec", tag = "2")]
    pub sdk_blob: ::prost::alloc::vec::Vec<u8>,
}
/// Metadata related to retrieval in the grounding flow.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct RetrievalMetadata {
    /// Optional. Score indicating how likely information from Google Search could
    /// help answer the prompt. The score is in the range `\[0, 1\]`, where 0 is the
    /// least likely and 1 is the most likely. This score is only populated when
    /// Google Search grounding and dynamic retrieval is enabled. It will be
    /// compared to the threshold to determine whether to trigger Google Search.
    #[prost(float, tag = "2")]
    pub google_search_dynamic_retrieval_score: f32,
}
/// Configuration for Model Armor integrations of prompt and responses.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ModelArmorConfig {
    /// Optional. The name of the Model Armor template to use for prompt
    /// sanitization.
    #[prost(string, tag = "1")]
    pub prompt_template_name: ::prost::alloc::string::String,
    /// Optional. The name of the Model Armor template to use for response
    /// sanitization.
    #[prost(string, tag = "2")]
    pub response_template_name: ::prost::alloc::string::String,
}
/// Represents token counting info for a single modality.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ModalityTokenCount {
    /// The modality associated with this token count.
    #[prost(enumeration = "Modality", tag = "1")]
    pub modality: i32,
    /// Number of tokens.
    #[prost(int32, tag = "2")]
    pub token_count: i32,
}
/// Harm categories that will block the content.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum HarmCategory {
    /// The harm category is unspecified.
    Unspecified = 0,
    /// The harm category is hate speech.
    HateSpeech = 1,
    /// The harm category is dangerous content.
    DangerousContent = 2,
    /// The harm category is harassment.
    Harassment = 3,
    /// The harm category is sexually explicit content.
    SexuallyExplicit = 4,
    /// Deprecated: Election filter is not longer supported.
    /// The harm category is civic integrity.
    #[deprecated]
    CivicIntegrity = 5,
    /// The harm category is for jailbreak prompts.
    Jailbreak = 6,
}
impl HarmCategory {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "HARM_CATEGORY_UNSPECIFIED",
            Self::HateSpeech => "HARM_CATEGORY_HATE_SPEECH",
            Self::DangerousContent => "HARM_CATEGORY_DANGEROUS_CONTENT",
            Self::Harassment => "HARM_CATEGORY_HARASSMENT",
            Self::SexuallyExplicit => "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            #[allow(deprecated)]
            Self::CivicIntegrity => "HARM_CATEGORY_CIVIC_INTEGRITY",
            Self::Jailbreak => "HARM_CATEGORY_JAILBREAK",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "HARM_CATEGORY_UNSPECIFIED" => Some(Self::Unspecified),
            "HARM_CATEGORY_HATE_SPEECH" => Some(Self::HateSpeech),
            "HARM_CATEGORY_DANGEROUS_CONTENT" => Some(Self::DangerousContent),
            "HARM_CATEGORY_HARASSMENT" => Some(Self::Harassment),
            "HARM_CATEGORY_SEXUALLY_EXPLICIT" => Some(Self::SexuallyExplicit),
            "HARM_CATEGORY_CIVIC_INTEGRITY" => {
                Some(#[allow(deprecated)] Self::CivicIntegrity)
            }
            "HARM_CATEGORY_JAILBREAK" => Some(Self::Jailbreak),
            _ => None,
        }
    }
}
/// Content Part modality
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Modality {
    /// Unspecified modality.
    Unspecified = 0,
    /// Plain text.
    Text = 1,
    /// Image.
    Image = 2,
    /// Video.
    Video = 3,
    /// Audio.
    Audio = 4,
    /// Document, e.g. PDF.
    Document = 5,
}
impl Modality {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "MODALITY_UNSPECIFIED",
            Self::Text => "TEXT",
            Self::Image => "IMAGE",
            Self::Video => "VIDEO",
            Self::Audio => "AUDIO",
            Self::Document => "DOCUMENT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
            "TEXT" => Some(Self::Text),
            "IMAGE" => Some(Self::Image),
            "VIDEO" => Some(Self::Video),
            "AUDIO" => Some(Self::Audio),
            "DOCUMENT" => Some(Self::Document),
            _ => None,
        }
    }
}
/// Metadata describing the Model's input and output for explanation.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationMetadata {
    /// Required. Map from feature names to feature input metadata. Keys are the
    /// name of the features. Values are the specification of the feature.
    ///
    /// An empty InputMetadata is valid. It describes a text feature which has the
    /// name specified as the key in
    /// \[ExplanationMetadata.inputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.inputs\].
    /// The baseline of the empty feature is chosen by Vertex AI.
    ///
    /// For Vertex AI-provided Tensorflow images, the key can be any friendly
    /// name of the feature. Once specified,
    /// \[featureAttributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\]
    /// are keyed by this key (if not grouped with another feature).
    ///
    /// For custom images, the key must match with the key in
    /// \[instance\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\].
    #[prost(map = "string, message", tag = "1")]
    pub inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata::InputMetadata,
    >,
    /// Required. Map from output names to output metadata.
    ///
    /// For Vertex AI-provided Tensorflow images, keys can be any user defined
    /// string that consists of any UTF-8 characters.
    ///
    /// For custom images, keys are the name of the output field in the prediction
    /// to be explained.
    ///
    /// Currently only one key is allowed.
    #[prost(map = "string, message", tag = "2")]
    pub outputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata::OutputMetadata,
    >,
    /// Points to a YAML file stored on Google Cloud Storage describing the format
    /// of the \[feature
    /// attributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\].
    /// The schema is defined as an OpenAPI 3.0.2 [Schema
    /// Object](<https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject>).
    /// AutoML tabular Models always have this field populated by Vertex AI.
    /// Note: The URI given on output may be different, including the URI scheme,
    /// than the one given on input. The output URI will point to a location where
    /// the user only has a read access.
    #[prost(string, tag = "3")]
    pub feature_attributions_schema_uri: ::prost::alloc::string::String,
    /// Name of the source to generate embeddings for example based explanations.
    #[prost(string, tag = "5")]
    pub latent_space_source: ::prost::alloc::string::String,
}
/// Nested message and enum types in `ExplanationMetadata`.
pub mod explanation_metadata {
    /// Metadata of the input of a feature.
    ///
    /// Fields other than
    /// \[InputMetadata.input_baselines\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.input_baselines\]
    /// are applicable only for Models that are using Vertex AI-provided images for
    /// Tensorflow.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct InputMetadata {
        /// Baseline inputs for this feature.
        ///
        /// If no baseline is specified, Vertex AI chooses the baseline for this
        /// feature. If multiple baselines are specified, Vertex AI returns the
        /// average attributions across them in
        /// \[Attribution.feature_attributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\].
        ///
        /// For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape
        /// of each baseline must match the shape of the input tensor. If a scalar is
        /// provided, we broadcast to the same shape as the input tensor.
        ///
        /// For custom images, the element of the baselines must be in the same
        /// format as the feature's input in the
        /// \[instance\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\]\[\]. The
        /// schema of any single instance may be specified via Endpoint's
        /// DeployedModels' \[Model's\]\[google.cloud.aiplatform.v1.DeployedModel.model\]
        /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
        /// \[instance_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri\].
        #[prost(message, repeated, tag = "1")]
        pub input_baselines: ::prost::alloc::vec::Vec<
            super::super::super::super::protobuf::Value,
        >,
        /// Name of the input tensor for this feature. Required and is only
        /// applicable to Vertex AI-provided images for Tensorflow.
        #[prost(string, tag = "2")]
        pub input_tensor_name: ::prost::alloc::string::String,
        /// Defines how the feature is encoded into the input tensor. Defaults to
        /// IDENTITY.
        #[prost(enumeration = "input_metadata::Encoding", tag = "3")]
        pub encoding: i32,
        /// Modality of the feature. Valid values are: numeric, image. Defaults to
        /// numeric.
        #[prost(string, tag = "4")]
        pub modality: ::prost::alloc::string::String,
        /// The domain details of the input feature value. Like min/max, original
        /// mean or standard deviation if normalized.
        #[prost(message, optional, tag = "5")]
        pub feature_value_domain: ::core::option::Option<
            input_metadata::FeatureValueDomain,
        >,
        /// Specifies the index of the values of the input tensor.
        /// Required when the input tensor is a sparse representation. Refer to
        /// Tensorflow documentation for more details:
        /// <https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.>
        #[prost(string, tag = "6")]
        pub indices_tensor_name: ::prost::alloc::string::String,
        /// Specifies the shape of the values of the input if the input is a sparse
        /// representation. Refer to Tensorflow documentation for more details:
        /// <https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.>
        #[prost(string, tag = "7")]
        pub dense_shape_tensor_name: ::prost::alloc::string::String,
        /// A list of feature names for each index in the input tensor.
        /// Required when the input
        /// \[InputMetadata.encoding\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoding\]
        /// is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
        #[prost(string, repeated, tag = "8")]
        pub index_feature_mapping: ::prost::alloc::vec::Vec<
            ::prost::alloc::string::String,
        >,
        /// Encoded tensor is a transformation of the input tensor. Must be provided
        /// if choosing
        /// \[Integrated Gradients
        /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution\]
        /// or \[XRAI
        /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution\]
        /// and the input tensor is not differentiable.
        ///
        /// An encoded tensor is generated if the input tensor is encoded by a lookup
        /// table.
        #[prost(string, tag = "9")]
        pub encoded_tensor_name: ::prost::alloc::string::String,
        /// A list of baselines for the encoded tensor.
        ///
        /// The shape of each baseline should match the shape of the encoded tensor.
        /// If a scalar is provided, Vertex AI broadcasts to the same shape as the
        /// encoded tensor.
        #[prost(message, repeated, tag = "10")]
        pub encoded_baselines: ::prost::alloc::vec::Vec<
            super::super::super::super::protobuf::Value,
        >,
        /// Visualization configurations for image explanation.
        #[prost(message, optional, tag = "11")]
        pub visualization: ::core::option::Option<input_metadata::Visualization>,
        /// Name of the group that the input belongs to. Features with the same group
        /// name will be treated as one feature when computing attributions. Features
        /// grouped together can have different shapes in value. If provided, there
        /// will be one single attribution generated in
        /// \[Attribution.feature_attributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\],
        /// keyed by the group name.
        #[prost(string, tag = "12")]
        pub group_name: ::prost::alloc::string::String,
    }
    /// Nested message and enum types in `InputMetadata`.
    pub mod input_metadata {
        /// Domain details of the input feature value. Provides numeric information
        /// about the feature, such as its range (min, max). If the feature has been
        /// pre-processed, for example with z-scoring, then it provides information
        /// about how to recover the original feature. For example, if the input
        /// feature is an image and it has been pre-processed to obtain 0-mean and
        /// stddev = 1 values, then original_mean, and original_stddev refer to the
        /// mean and stddev of the original feature (e.g. image tensor) from which
        /// input feature (with mean = 0 and stddev = 1) was obtained.
        #[derive(Clone, Copy, PartialEq, ::prost::Message)]
        pub struct FeatureValueDomain {
            /// The minimum permissible value for this feature.
            #[prost(float, tag = "1")]
            pub min_value: f32,
            /// The maximum permissible value for this feature.
            #[prost(float, tag = "2")]
            pub max_value: f32,
            /// If this input feature has been normalized to a mean value of 0,
            /// the original_mean specifies the mean value of the domain prior to
            /// normalization.
            #[prost(float, tag = "3")]
            pub original_mean: f32,
            /// If this input feature has been normalized to a standard deviation of
            /// 1.0, the original_stddev specifies the standard deviation of the domain
            /// prior to normalization.
            #[prost(float, tag = "4")]
            pub original_stddev: f32,
        }
        /// Visualization configurations for image explanation.
        #[derive(Clone, Copy, PartialEq, ::prost::Message)]
        pub struct Visualization {
            /// Type of the image visualization. Only applicable to
            /// \[Integrated Gradients
            /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution\].
            /// OUTLINES shows regions of attribution, while PIXELS shows per-pixel
            /// attribution. Defaults to OUTLINES.
            #[prost(enumeration = "visualization::Type", tag = "1")]
            pub r#type: i32,
            /// Whether to only highlight pixels with positive contributions, negative
            /// or both. Defaults to POSITIVE.
            #[prost(enumeration = "visualization::Polarity", tag = "2")]
            pub polarity: i32,
            /// The color scheme used for the highlighted areas.
            ///
            /// Defaults to PINK_GREEN for
            /// \[Integrated Gradients
            /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution\],
            /// which shows positive attributions in green and negative in pink.
            ///
            /// Defaults to VIRIDIS for
            /// \[XRAI
            /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution\],
            /// which highlights the most influential regions in yellow and the least
            /// influential in blue.
            #[prost(enumeration = "visualization::ColorMap", tag = "3")]
            pub color_map: i32,
            /// Excludes attributions above the specified percentile from the
            /// highlighted areas. Using the clip_percent_upperbound and
            /// clip_percent_lowerbound together can be useful for filtering out noise
            /// and making it easier to see areas of strong attribution. Defaults to
            /// 99.9.
            #[prost(float, tag = "4")]
            pub clip_percent_upperbound: f32,
            /// Excludes attributions below the specified percentile, from the
            /// highlighted areas. Defaults to 62.
            #[prost(float, tag = "5")]
            pub clip_percent_lowerbound: f32,
            /// How the original image is displayed in the visualization.
            /// Adjusting the overlay can help increase visual clarity if the original
            /// image makes it difficult to view the visualization. Defaults to NONE.
            #[prost(enumeration = "visualization::OverlayType", tag = "6")]
            pub overlay_type: i32,
        }
        /// Nested message and enum types in `Visualization`.
        pub mod visualization {
            /// Type of the image visualization. Only applicable to
            /// \[Integrated Gradients
            /// attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution\].
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum Type {
                /// Should not be used.
                Unspecified = 0,
                /// Shows which pixel contributed to the image prediction.
                Pixels = 1,
                /// Shows which region contributed to the image prediction by outlining
                /// the region.
                Outlines = 2,
            }
            impl Type {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Self::Unspecified => "TYPE_UNSPECIFIED",
                        Self::Pixels => "PIXELS",
                        Self::Outlines => "OUTLINES",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                        "PIXELS" => Some(Self::Pixels),
                        "OUTLINES" => Some(Self::Outlines),
                        _ => None,
                    }
                }
            }
            /// Whether to only highlight pixels with positive contributions, negative
            /// or both. Defaults to POSITIVE.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum Polarity {
                /// Default value. This is the same as POSITIVE.
                Unspecified = 0,
                /// Highlights the pixels/outlines that were most influential to the
                /// model's prediction.
                Positive = 1,
                /// Setting polarity to negative highlights areas that does not lead to
                /// the models's current prediction.
                Negative = 2,
                /// Shows both positive and negative attributions.
                Both = 3,
            }
            impl Polarity {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Self::Unspecified => "POLARITY_UNSPECIFIED",
                        Self::Positive => "POSITIVE",
                        Self::Negative => "NEGATIVE",
                        Self::Both => "BOTH",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "POLARITY_UNSPECIFIED" => Some(Self::Unspecified),
                        "POSITIVE" => Some(Self::Positive),
                        "NEGATIVE" => Some(Self::Negative),
                        "BOTH" => Some(Self::Both),
                        _ => None,
                    }
                }
            }
            /// The color scheme used for highlighting areas.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum ColorMap {
                /// Should not be used.
                Unspecified = 0,
                /// Positive: green. Negative: pink.
                PinkGreen = 1,
                /// Viridis color map: A perceptually uniform color mapping which is
                /// easier to see by those with colorblindness and progresses from yellow
                /// to green to blue. Positive: yellow. Negative: blue.
                Viridis = 2,
                /// Positive: red. Negative: red.
                Red = 3,
                /// Positive: green. Negative: green.
                Green = 4,
                /// Positive: green. Negative: red.
                RedGreen = 6,
                /// PiYG palette.
                PinkWhiteGreen = 5,
            }
            impl ColorMap {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Self::Unspecified => "COLOR_MAP_UNSPECIFIED",
                        Self::PinkGreen => "PINK_GREEN",
                        Self::Viridis => "VIRIDIS",
                        Self::Red => "RED",
                        Self::Green => "GREEN",
                        Self::RedGreen => "RED_GREEN",
                        Self::PinkWhiteGreen => "PINK_WHITE_GREEN",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "COLOR_MAP_UNSPECIFIED" => Some(Self::Unspecified),
                        "PINK_GREEN" => Some(Self::PinkGreen),
                        "VIRIDIS" => Some(Self::Viridis),
                        "RED" => Some(Self::Red),
                        "GREEN" => Some(Self::Green),
                        "RED_GREEN" => Some(Self::RedGreen),
                        "PINK_WHITE_GREEN" => Some(Self::PinkWhiteGreen),
                        _ => None,
                    }
                }
            }
            /// How the original image is displayed in the visualization.
            #[derive(
                Clone,
                Copy,
                Debug,
                PartialEq,
                Eq,
                Hash,
                PartialOrd,
                Ord,
                ::prost::Enumeration
            )]
            #[repr(i32)]
            pub enum OverlayType {
                /// Default value. This is the same as NONE.
                Unspecified = 0,
                /// No overlay.
                None = 1,
                /// The attributions are shown on top of the original image.
                Original = 2,
                /// The attributions are shown on top of grayscaled version of the
                /// original image.
                Grayscale = 3,
                /// The attributions are used as a mask to reveal predictive parts of
                /// the image and hide the un-predictive parts.
                MaskBlack = 4,
            }
            impl OverlayType {
                /// String value of the enum field names used in the ProtoBuf definition.
                ///
                /// The values are not transformed in any way and thus are considered stable
                /// (if the ProtoBuf definition does not change) and safe for programmatic use.
                pub fn as_str_name(&self) -> &'static str {
                    match self {
                        Self::Unspecified => "OVERLAY_TYPE_UNSPECIFIED",
                        Self::None => "NONE",
                        Self::Original => "ORIGINAL",
                        Self::Grayscale => "GRAYSCALE",
                        Self::MaskBlack => "MASK_BLACK",
                    }
                }
                /// Creates an enum from field names used in the ProtoBuf definition.
                pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                    match value {
                        "OVERLAY_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                        "NONE" => Some(Self::None),
                        "ORIGINAL" => Some(Self::Original),
                        "GRAYSCALE" => Some(Self::Grayscale),
                        "MASK_BLACK" => Some(Self::MaskBlack),
                        _ => None,
                    }
                }
            }
        }
        /// Defines how a feature is encoded. Defaults to IDENTITY.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum Encoding {
            /// Default value. This is the same as IDENTITY.
            Unspecified = 0,
            /// The tensor represents one feature.
            Identity = 1,
            /// The tensor represents a bag of features where each index maps to
            /// a feature.
            /// \[InputMetadata.index_feature_mapping\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping\]
            /// must be provided for this encoding. For example:
            ///
            /// ```text,
            /// input = \[27, 6.0, 150\]
            /// index_feature_mapping = \["age", "height", "weight"\]
            /// ```
            BagOfFeatures = 2,
            /// The tensor represents a bag of features where each index maps to a
            /// feature. Zero values in the tensor indicates feature being
            /// non-existent.
            /// \[InputMetadata.index_feature_mapping\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping\]
            /// must be provided for this encoding. For example:
            ///
            /// ```text,
            /// input = \[2, 0, 5, 0, 1\]
            /// index_feature_mapping = \["a", "b", "c", "d", "e"\]
            /// ```
            BagOfFeaturesSparse = 3,
            /// The tensor is a list of binaries representing whether a feature exists
            /// or not (1 indicates existence).
            /// \[InputMetadata.index_feature_mapping\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.index_feature_mapping\]
            /// must be provided for this encoding. For example:
            ///
            /// ```text,
            /// input = \[1, 0, 1, 0, 1\]
            /// index_feature_mapping = \["a", "b", "c", "d", "e"\]
            /// ```
            Indicator = 4,
            /// The tensor is encoded into a 1-dimensional array represented by an
            /// encoded tensor.
            /// \[InputMetadata.encoded_tensor_name\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoded_tensor_name\]
            /// must be provided for this encoding. For example:
            ///
            /// ```text,
            /// input = \["This", "is", "a", "test", "."\]
            /// encoded = \[0.1, 0.2, 0.3, 0.4, 0.5\]
            /// ```
            CombinedEmbedding = 5,
            /// Select this encoding when the input tensor is encoded into a
            /// 2-dimensional array represented by an encoded tensor.
            /// \[InputMetadata.encoded_tensor_name\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoded_tensor_name\]
            /// must be provided for this encoding. The first dimension of the encoded
            /// tensor's shape is the same as the input tensor's shape. For example:
            ///
            /// ```text,
            /// input = \["This", "is", "a", "test", "."\]
            /// encoded = \[[0.1, 0.2, 0.3, 0.4, 0.5\],
            ///            \[0.2, 0.1, 0.4, 0.3, 0.5\],
            ///            \[0.5, 0.1, 0.3, 0.5, 0.4\],
            ///            \[0.5, 0.3, 0.1, 0.2, 0.4\],
            ///            \[0.4, 0.3, 0.2, 0.5, 0.1]\]
            /// ```
            ConcatEmbedding = 6,
        }
        impl Encoding {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "ENCODING_UNSPECIFIED",
                    Self::Identity => "IDENTITY",
                    Self::BagOfFeatures => "BAG_OF_FEATURES",
                    Self::BagOfFeaturesSparse => "BAG_OF_FEATURES_SPARSE",
                    Self::Indicator => "INDICATOR",
                    Self::CombinedEmbedding => "COMBINED_EMBEDDING",
                    Self::ConcatEmbedding => "CONCAT_EMBEDDING",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "ENCODING_UNSPECIFIED" => Some(Self::Unspecified),
                    "IDENTITY" => Some(Self::Identity),
                    "BAG_OF_FEATURES" => Some(Self::BagOfFeatures),
                    "BAG_OF_FEATURES_SPARSE" => Some(Self::BagOfFeaturesSparse),
                    "INDICATOR" => Some(Self::Indicator),
                    "COMBINED_EMBEDDING" => Some(Self::CombinedEmbedding),
                    "CONCAT_EMBEDDING" => Some(Self::ConcatEmbedding),
                    _ => None,
                }
            }
        }
    }
    /// Metadata of the prediction output to be explained.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct OutputMetadata {
        /// Name of the output tensor. Required and is only applicable to Vertex
        /// AI provided images for Tensorflow.
        #[prost(string, tag = "3")]
        pub output_tensor_name: ::prost::alloc::string::String,
        /// Defines how to map
        /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
        /// to
        /// \[Attribution.output_display_name\]\[google.cloud.aiplatform.v1.Attribution.output_display_name\].
        ///
        /// If neither of the fields are specified,
        /// \[Attribution.output_display_name\]\[google.cloud.aiplatform.v1.Attribution.output_display_name\]
        /// will not be populated.
        #[prost(oneof = "output_metadata::DisplayNameMapping", tags = "1, 2")]
        pub display_name_mapping: ::core::option::Option<
            output_metadata::DisplayNameMapping,
        >,
    }
    /// Nested message and enum types in `OutputMetadata`.
    pub mod output_metadata {
        /// Defines how to map
        /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
        /// to
        /// \[Attribution.output_display_name\]\[google.cloud.aiplatform.v1.Attribution.output_display_name\].
        ///
        /// If neither of the fields are specified,
        /// \[Attribution.output_display_name\]\[google.cloud.aiplatform.v1.Attribution.output_display_name\]
        /// will not be populated.
        #[derive(Clone, PartialEq, ::prost::Oneof)]
        pub enum DisplayNameMapping {
            /// Static mapping between the index and display name.
            ///
            /// Use this if the outputs are a deterministic n-dimensional array, e.g. a
            /// list of scores of all the classes in a pre-defined order for a
            /// multi-classification Model. It's not feasible if the outputs are
            /// non-deterministic, e.g. the Model produces top-k classes or sort the
            /// outputs by their values.
            ///
            /// The shape of the value must be an n-dimensional array of strings. The
            /// number of dimensions must match that of the outputs to be explained.
            /// The
            /// \[Attribution.output_display_name\]\[google.cloud.aiplatform.v1.Attribution.output_display_name\]
            /// is populated by locating in the mapping with
            /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\].
            #[prost(message, tag = "1")]
            IndexDisplayNameMapping(super::super::super::super::super::protobuf::Value),
            /// Specify a field name in the prediction to look for the display name.
            ///
            /// Use this if the prediction contains the display names for the outputs.
            ///
            /// The display names in the prediction must have the same shape of the
            /// outputs, so that it can be located by
            /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
            /// for a specific output.
            #[prost(string, tag = "2")]
            DisplayNameMappingKey(::prost::alloc::string::String),
        }
    }
}
/// Explanation of a prediction (provided in
/// \[PredictResponse.predictions\]\[google.cloud.aiplatform.v1.PredictResponse.predictions\])
/// produced by the Model on a given
/// \[instance\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Explanation {
    /// Output only. Feature attributions grouped by predicted outputs.
    ///
    /// For Models that predict only one output, such as regression Models that
    /// predict only one score, there is only one attibution that explains the
    /// predicted output. For Models that predict multiple outputs, such as
    /// multiclass Models that predict multiple classes, each element explains one
    /// specific item.
    /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
    /// can be used to identify which output this attribution is explaining.
    ///
    /// By default, we provide Shapley values for the predicted class. However,
    /// you can configure the explanation request to generate Shapley values for
    /// any other classes too. For example, if a model predicts a probability of
    /// `0.4` for approving a loan application, the model's decision is to reject
    /// the application since `p(reject) = 0.6 > p(approve) = 0.4`, and the default
    /// Shapley values would be computed for rejection decision and not approval,
    /// even though the latter might be the positive class.
    ///
    /// If users set
    /// \[ExplanationParameters.top_k\]\[google.cloud.aiplatform.v1.ExplanationParameters.top_k\],
    /// the attributions are sorted by
    /// \[instance_output_value\]\[google.cloud.aiplatform.v1.Attribution.instance_output_value\]
    /// in descending order. If
    /// \[ExplanationParameters.output_indices\]\[google.cloud.aiplatform.v1.ExplanationParameters.output_indices\]
    /// is specified, the attributions are stored by
    /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
    /// in the same order as they appear in the output_indices.
    #[prost(message, repeated, tag = "1")]
    pub attributions: ::prost::alloc::vec::Vec<Attribution>,
    /// Output only. List of the nearest neighbors for example-based explanations.
    ///
    /// For models deployed with the examples explanations feature enabled, the
    /// attributions field is empty and instead the neighbors field is populated.
    #[prost(message, repeated, tag = "2")]
    pub neighbors: ::prost::alloc::vec::Vec<Neighbor>,
}
/// Aggregated explanation metrics for a Model over a set of instances.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ModelExplanation {
    /// Output only. Aggregated attributions explaining the Model's prediction
    /// outputs over the set of instances. The attributions are grouped by outputs.
    ///
    /// For Models that predict only one output, such as regression Models that
    /// predict only one score, there is only one attibution that explains the
    /// predicted output. For Models that predict multiple outputs, such as
    /// multiclass Models that predict multiple classes, each element explains one
    /// specific item.
    /// \[Attribution.output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
    /// can be used to identify which output this attribution is explaining.
    ///
    /// The
    /// \[baselineOutputValue\]\[google.cloud.aiplatform.v1.Attribution.baseline_output_value\],
    /// \[instanceOutputValue\]\[google.cloud.aiplatform.v1.Attribution.instance_output_value\]
    /// and
    /// \[featureAttributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\]
    /// fields are averaged over the test data.
    ///
    /// NOTE: Currently AutoML tabular classification Models produce only one
    /// attribution, which averages attributions over all the classes it predicts.
    /// \[Attribution.approximation_error\]\[google.cloud.aiplatform.v1.Attribution.approximation_error\]
    /// is not populated.
    #[prost(message, repeated, tag = "1")]
    pub mean_attributions: ::prost::alloc::vec::Vec<Attribution>,
}
/// Attribution that explains a particular prediction output.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Attribution {
    /// Output only. Model predicted output if the input instance is constructed
    /// from the baselines of all the features defined in
    /// \[ExplanationMetadata.inputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.inputs\].
    /// The field name of the output is determined by the key in
    /// \[ExplanationMetadata.outputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.outputs\].
    ///
    /// If the Model's predicted output has multiple dimensions (rank > 1), this is
    /// the value in the output located by
    /// \[output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\].
    ///
    /// If there are multiple baselines, their output values are averaged.
    #[prost(double, tag = "1")]
    pub baseline_output_value: f64,
    /// Output only. Model predicted output on the corresponding \[explanation
    /// instance\]\[ExplainRequest.instances\]. The field name of the output is
    /// determined by the key in
    /// \[ExplanationMetadata.outputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.outputs\].
    ///
    /// If the Model predicted output has multiple dimensions, this is the value in
    /// the output located by
    /// \[output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\].
    #[prost(double, tag = "2")]
    pub instance_output_value: f64,
    /// Output only. Attributions of each explained feature. Features are extracted
    /// from the \[prediction
    /// instances\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\] according
    /// to \[explanation metadata for
    /// inputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.inputs\].
    ///
    /// The value is a struct, whose keys are the name of the feature. The values
    /// are how much the feature in the
    /// \[instance\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\] contributed
    /// to the predicted result.
    ///
    /// The format of the value is determined by the feature's input format:
    ///
    /// * If the feature is a scalar value, the attribution value is a
    ///   \[floating number\]\[google.protobuf.Value.number_value\].
    ///
    /// * If the feature is an array of scalar values, the attribution value is
    ///   an \[array\]\[google.protobuf.Value.list_value\].
    ///
    /// * If the feature is a struct, the attribution value is a
    ///   \[struct\]\[google.protobuf.Value.struct_value\]. The keys in the
    ///   attribution value struct are the same as the keys in the feature
    ///   struct. The formats of the values in the attribution struct are
    ///   determined by the formats of the values in the feature struct.
    ///
    /// The
    /// \[ExplanationMetadata.feature_attributions_schema_uri\]\[google.cloud.aiplatform.v1.ExplanationMetadata.feature_attributions_schema_uri\]
    /// field, pointed to by the
    /// \[ExplanationSpec\]\[google.cloud.aiplatform.v1.ExplanationSpec\] field of the
    /// \[Endpoint.deployed_models\]\[google.cloud.aiplatform.v1.Endpoint.deployed_models\]
    /// object, points to the schema file that describes the features and their
    /// attribution values (if it is populated).
    #[prost(message, optional, tag = "3")]
    pub feature_attributions: ::core::option::Option<
        super::super::super::protobuf::Value,
    >,
    /// Output only. The index that locates the explained prediction output.
    ///
    /// If the prediction output is a scalar value, output_index is not populated.
    /// If the prediction output has multiple dimensions, the length of the
    /// output_index list is the same as the number of dimensions of the output.
    /// The i-th element in output_index is the element index of the i-th dimension
    /// of the output vector. Indices start from 0.
    #[prost(int32, repeated, packed = "false", tag = "4")]
    pub output_index: ::prost::alloc::vec::Vec<i32>,
    /// Output only. The display name of the output identified by
    /// \[output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]. For
    /// example, the predicted class name by a multi-classification Model.
    ///
    /// This field is only populated iff the Model predicts display names as a
    /// separate field along with the explained output. The predicted display name
    /// must has the same shape of the explained output, and can be located using
    /// output_index.
    #[prost(string, tag = "5")]
    pub output_display_name: ::prost::alloc::string::String,
    /// Output only. Error of
    /// \[feature_attributions\]\[google.cloud.aiplatform.v1.Attribution.feature_attributions\]
    /// caused by approximation used in the explanation method. Lower value means
    /// more precise attributions.
    ///
    /// * For Sampled Shapley
    ///   \[attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.sampled_shapley_attribution\],
    ///   increasing
    ///   \[path_count\]\[google.cloud.aiplatform.v1.SampledShapleyAttribution.path_count\]
    ///   might reduce the error.
    /// * For Integrated Gradients
    ///   \[attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution\],
    ///   increasing
    ///   \[step_count\]\[google.cloud.aiplatform.v1.IntegratedGradientsAttribution.step_count\]
    ///   might reduce the error.
    /// * For \[XRAI
    ///   attribution\]\[google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution\],
    ///   increasing
    ///   \[step_count\]\[google.cloud.aiplatform.v1.XraiAttribution.step_count\] might
    ///   reduce the error.
    ///
    /// See [this introduction](/vertex-ai/docs/explainable-ai/overview)
    /// for more information.
    #[prost(double, tag = "6")]
    pub approximation_error: f64,
    /// Output only. Name of the explain output. Specified as the key in
    /// \[ExplanationMetadata.outputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.outputs\].
    #[prost(string, tag = "7")]
    pub output_name: ::prost::alloc::string::String,
}
/// Neighbors for example-based explanations.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Neighbor {
    /// Output only. The neighbor id.
    #[prost(string, tag = "1")]
    pub neighbor_id: ::prost::alloc::string::String,
    /// Output only. The neighbor distance.
    #[prost(double, tag = "2")]
    pub neighbor_distance: f64,
}
/// Specification of Model explanation.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationSpec {
    /// Required. Parameters that configure explaining of the Model's predictions.
    #[prost(message, optional, tag = "1")]
    pub parameters: ::core::option::Option<ExplanationParameters>,
    /// Optional. Metadata describing the Model's input and output for explanation.
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ExplanationMetadata>,
}
/// Parameters to configure explaining for Model's predictions.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationParameters {
    /// If populated, returns attributions for top K indices of outputs
    /// (defaults to 1). Only applies to Models that predicts more than one outputs
    /// (e,g, multi-class Models). When set to -1, returns explanations for all
    /// outputs.
    #[prost(int32, tag = "4")]
    pub top_k: i32,
    /// If populated, only returns attributions that have
    /// \[output_index\]\[google.cloud.aiplatform.v1.Attribution.output_index\]
    /// contained in output_indices. It must be an ndarray of integers, with the
    /// same shape of the output it's explaining.
    ///
    /// If not populated, returns attributions for
    /// \[top_k\]\[google.cloud.aiplatform.v1.ExplanationParameters.top_k\] indices of
    /// outputs. If neither top_k nor output_indices is populated, returns the
    /// argmax index of the outputs.
    ///
    /// Only applicable to Models that predict multiple outputs (e,g, multi-class
    /// Models that predict multiple classes).
    #[prost(message, optional, tag = "5")]
    pub output_indices: ::core::option::Option<super::super::super::protobuf::ListValue>,
    #[prost(oneof = "explanation_parameters::Method", tags = "1, 2, 3, 7")]
    pub method: ::core::option::Option<explanation_parameters::Method>,
}
/// Nested message and enum types in `ExplanationParameters`.
pub mod explanation_parameters {
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Method {
        /// An attribution method that approximates Shapley values for features that
        /// contribute to the label being predicted. A sampling strategy is used to
        /// approximate the value rather than considering all subsets of features.
        /// Refer to this paper for model details: <https://arxiv.org/abs/1306.4265.>
        #[prost(message, tag = "1")]
        SampledShapleyAttribution(super::SampledShapleyAttribution),
        /// An attribution method that computes Aumann-Shapley values taking
        /// advantage of the model's fully differentiable structure. Refer to this
        /// paper for more details: <https://arxiv.org/abs/1703.01365>
        #[prost(message, tag = "2")]
        IntegratedGradientsAttribution(super::IntegratedGradientsAttribution),
        /// An attribution method that redistributes Integrated Gradients
        /// attribution to segmented regions, taking advantage of the model's fully
        /// differentiable structure. Refer to this paper for
        /// more details: <https://arxiv.org/abs/1906.02825>
        ///
        /// XRAI currently performs better on natural images, like a picture of a
        /// house or an animal. If the images are taken in artificial environments,
        /// like a lab or manufacturing line, or from diagnostic equipment, like
        /// x-rays or quality-control cameras, use Integrated Gradients instead.
        #[prost(message, tag = "3")]
        XraiAttribution(super::XraiAttribution),
        /// Example-based explanations that returns the nearest neighbors from the
        /// provided dataset.
        #[prost(message, tag = "7")]
        Examples(super::Examples),
    }
}
/// An attribution method that approximates Shapley values for features that
/// contribute to the label being predicted. A sampling strategy is used to
/// approximate the value rather than considering all subsets of features.
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SampledShapleyAttribution {
    /// Required. The number of feature permutations to consider when approximating
    /// the Shapley values.
    ///
    /// Valid range of its value is \[1, 50\], inclusively.
    #[prost(int32, tag = "1")]
    pub path_count: i32,
}
/// An attribution method that computes the Aumann-Shapley value taking advantage
/// of the model's fully differentiable structure. Refer to this paper for
/// more details: <https://arxiv.org/abs/1703.01365>
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct IntegratedGradientsAttribution {
    /// Required. The number of steps for approximating the path integral.
    /// A good value to start is 50 and gradually increase until the
    /// sum to diff property is within the desired error range.
    ///
    /// Valid range of its value is \[1, 100\], inclusively.
    #[prost(int32, tag = "1")]
    pub step_count: i32,
    /// Config for SmoothGrad approximation of gradients.
    ///
    /// When enabled, the gradients are approximated by averaging the gradients
    /// from noisy samples in the vicinity of the inputs. Adding
    /// noise can help improve the computed gradients. Refer to this paper for more
    /// details: <https://arxiv.org/pdf/1706.03825.pdf>
    #[prost(message, optional, tag = "2")]
    pub smooth_grad_config: ::core::option::Option<SmoothGradConfig>,
    /// Config for IG with blur baseline.
    ///
    /// When enabled, a linear path from the maximally blurred image to the input
    /// image is created. Using a blurred baseline instead of zero (black image) is
    /// motivated by the BlurIG approach explained here:
    /// <https://arxiv.org/abs/2004.03383>
    #[prost(message, optional, tag = "3")]
    pub blur_baseline_config: ::core::option::Option<BlurBaselineConfig>,
}
/// An explanation method that redistributes Integrated Gradients
/// attributions to segmented regions, taking advantage of the model's fully
/// differentiable structure. Refer to this paper for more details:
/// <https://arxiv.org/abs/1906.02825>
///
/// Supported only by image Models.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct XraiAttribution {
    /// Required. The number of steps for approximating the path integral.
    /// A good value to start is 50 and gradually increase until the
    /// sum to diff property is met within the desired error range.
    ///
    /// Valid range of its value is \[1, 100\], inclusively.
    #[prost(int32, tag = "1")]
    pub step_count: i32,
    /// Config for SmoothGrad approximation of gradients.
    ///
    /// When enabled, the gradients are approximated by averaging the gradients
    /// from noisy samples in the vicinity of the inputs. Adding
    /// noise can help improve the computed gradients. Refer to this paper for more
    /// details: <https://arxiv.org/pdf/1706.03825.pdf>
    #[prost(message, optional, tag = "2")]
    pub smooth_grad_config: ::core::option::Option<SmoothGradConfig>,
    /// Config for XRAI with blur baseline.
    ///
    /// When enabled, a linear path from the maximally blurred image to the input
    /// image is created. Using a blurred baseline instead of zero (black image) is
    /// motivated by the BlurIG approach explained here:
    /// <https://arxiv.org/abs/2004.03383>
    #[prost(message, optional, tag = "3")]
    pub blur_baseline_config: ::core::option::Option<BlurBaselineConfig>,
}
/// Config for SmoothGrad approximation of gradients.
///
/// When enabled, the gradients are approximated by averaging the gradients from
/// noisy samples in the vicinity of the inputs. Adding noise can help improve
/// the computed gradients. Refer to this paper for more details:
/// <https://arxiv.org/pdf/1706.03825.pdf>
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SmoothGradConfig {
    /// The number of gradient samples to use for
    /// approximation. The higher this number, the more accurate the gradient
    /// is, but the runtime complexity increases by this factor as well.
    /// Valid range of its value is \[1, 50\]. Defaults to 3.
    #[prost(int32, tag = "3")]
    pub noisy_sample_count: i32,
    /// Represents the standard deviation of the gaussian kernel
    /// that will be used to add noise to the interpolated inputs
    /// prior to computing gradients.
    #[prost(oneof = "smooth_grad_config::GradientNoiseSigma", tags = "1, 2")]
    pub gradient_noise_sigma: ::core::option::Option<
        smooth_grad_config::GradientNoiseSigma,
    >,
}
/// Nested message and enum types in `SmoothGradConfig`.
pub mod smooth_grad_config {
    /// Represents the standard deviation of the gaussian kernel
    /// that will be used to add noise to the interpolated inputs
    /// prior to computing gradients.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum GradientNoiseSigma {
        /// This is a single float value and will be used to add noise to all the
        /// features. Use this field when all features are normalized to have the
        /// same distribution: scale to range \[0, 1\], \[-1, 1\] or z-scoring, where
        /// features are normalized to have 0-mean and 1-variance. Learn more about
        /// [normalization](<https://developers.google.com/machine-learning/data-prep/transform/normalization>).
        ///
        /// For best results the recommended value is about 10% - 20% of the standard
        /// deviation of the input feature. Refer to section 3.2 of the SmoothGrad
        /// paper: <https://arxiv.org/pdf/1706.03825.pdf.> Defaults to 0.1.
        ///
        /// If the distribution is different per feature, set
        /// \[feature_noise_sigma\]\[google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma\]
        /// instead for each feature.
        #[prost(float, tag = "1")]
        NoiseSigma(f32),
        /// This is similar to
        /// \[noise_sigma\]\[google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma\],
        /// but provides additional flexibility. A separate noise sigma can be
        /// provided for each feature, which is useful if their distributions are
        /// different. No noise is added to features that are not set. If this field
        /// is unset,
        /// \[noise_sigma\]\[google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma\]
        /// will be used for all features.
        #[prost(message, tag = "2")]
        FeatureNoiseSigma(super::FeatureNoiseSigma),
    }
}
/// Noise sigma by features. Noise sigma represents the standard deviation of the
/// gaussian kernel that will be used to add noise to interpolated inputs prior
/// to computing gradients.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FeatureNoiseSigma {
    /// Noise sigma per feature. No noise is added to features that are not set.
    #[prost(message, repeated, tag = "1")]
    pub noise_sigma: ::prost::alloc::vec::Vec<feature_noise_sigma::NoiseSigmaForFeature>,
}
/// Nested message and enum types in `FeatureNoiseSigma`.
pub mod feature_noise_sigma {
    /// Noise sigma for a single feature.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct NoiseSigmaForFeature {
        /// The name of the input feature for which noise sigma is provided. The
        /// features are defined in
        /// \[explanation metadata
        /// inputs\]\[google.cloud.aiplatform.v1.ExplanationMetadata.inputs\].
        #[prost(string, tag = "1")]
        pub name: ::prost::alloc::string::String,
        /// This represents the standard deviation of the Gaussian kernel that will
        /// be used to add noise to the feature prior to computing gradients. Similar
        /// to \[noise_sigma\]\[google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma\]
        /// but represents the noise added to the current feature. Defaults to 0.1.
        #[prost(float, tag = "2")]
        pub sigma: f32,
    }
}
/// Config for blur baseline.
///
/// When enabled, a linear path from the maximally blurred image to the input
/// image is created. Using a blurred baseline instead of zero (black image) is
/// motivated by the BlurIG approach explained here:
/// <https://arxiv.org/abs/2004.03383>
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct BlurBaselineConfig {
    /// The standard deviation of the blur kernel for the blurred baseline. The
    /// same blurring parameter is used for both the height and the width
    /// dimension. If not set, the method defaults to the zero (i.e. black for
    /// images) baseline.
    #[prost(float, tag = "1")]
    pub max_blur_sigma: f32,
}
/// Example-based explainability that returns the nearest neighbors from the
/// provided dataset.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Examples {
    /// The number of neighbors to return when querying for examples.
    #[prost(int32, tag = "3")]
    pub neighbor_count: i32,
    #[prost(oneof = "examples::Source", tags = "5")]
    pub source: ::core::option::Option<examples::Source>,
    #[prost(oneof = "examples::Config", tags = "2, 4")]
    pub config: ::core::option::Option<examples::Config>,
}
/// Nested message and enum types in `Examples`.
pub mod examples {
    /// The Cloud Storage input instances.
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
    pub struct ExampleGcsSource {
        /// The format in which instances are given, if not specified, assume it's
        /// JSONL format. Currently only JSONL format is supported.
        #[prost(enumeration = "example_gcs_source::DataFormat", tag = "1")]
        pub data_format: i32,
        /// The Cloud Storage location for the input instances.
        #[prost(message, optional, tag = "2")]
        pub gcs_source: ::core::option::Option<super::GcsSource>,
    }
    /// Nested message and enum types in `ExampleGcsSource`.
    pub mod example_gcs_source {
        /// The format of the input example instances.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum DataFormat {
            /// Format unspecified, used when unset.
            Unspecified = 0,
            /// Examples are stored in JSONL files.
            Jsonl = 1,
        }
        impl DataFormat {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "DATA_FORMAT_UNSPECIFIED",
                    Self::Jsonl => "JSONL",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "DATA_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
                    "JSONL" => Some(Self::Jsonl),
                    _ => None,
                }
            }
        }
    }
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Source {
        /// The Cloud Storage input instances.
        #[prost(message, tag = "5")]
        ExampleGcsSource(ExampleGcsSource),
    }
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Config {
        /// The full configuration for the generated index, the semantics are the
        /// same as \[metadata\]\[google.cloud.aiplatform.v1.Index.metadata\] and should
        /// match
        /// [NearestNeighborSearchConfig](<https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config>).
        #[prost(message, tag = "2")]
        NearestNeighborSearchConfig(super::super::super::super::protobuf::Value),
        /// Simplified preset configuration, which automatically sets configuration
        /// values based on the desired query speed-precision trade-off and modality.
        #[prost(message, tag = "4")]
        Presets(super::Presets),
    }
}
/// Preset configuration for example-based explanations
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Presets {
    /// Preset option controlling parameters for speed-precision trade-off when
    /// querying for examples. If omitted, defaults to `PRECISE`.
    #[prost(enumeration = "presets::Query", optional, tag = "1")]
    pub query: ::core::option::Option<i32>,
    /// The modality of the uploaded model, which automatically configures the
    /// distance measurement and feature normalization for the underlying example
    /// index and queries. If your model does not precisely fit one of these types,
    /// it is okay to choose the closest type.
    #[prost(enumeration = "presets::Modality", tag = "2")]
    pub modality: i32,
}
/// Nested message and enum types in `Presets`.
pub mod presets {
    /// Preset option controlling parameters for query speed-precision trade-off
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Query {
        /// More precise neighbors as a trade-off against slower response.
        Precise = 0,
        /// Faster response as a trade-off against less precise neighbors.
        Fast = 1,
    }
    impl Query {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Precise => "PRECISE",
                Self::Fast => "FAST",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PRECISE" => Some(Self::Precise),
                "FAST" => Some(Self::Fast),
                _ => None,
            }
        }
    }
    /// Preset option controlling parameters for different modalities
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Modality {
        /// Should not be set. Added as a recommended best practice for enums
        Unspecified = 0,
        /// IMAGE modality
        Image = 1,
        /// TEXT modality
        Text = 2,
        /// TABULAR modality
        Tabular = 3,
    }
    impl Modality {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODALITY_UNSPECIFIED",
                Self::Image => "IMAGE",
                Self::Text => "TEXT",
                Self::Tabular => "TABULAR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
                "IMAGE" => Some(Self::Image),
                "TEXT" => Some(Self::Text),
                "TABULAR" => Some(Self::Tabular),
                _ => None,
            }
        }
    }
}
/// The \[ExplanationSpec\]\[google.cloud.aiplatform.v1.ExplanationSpec\] entries
/// that can be overridden at \[online
/// explanation\]\[google.cloud.aiplatform.v1.PredictionService.Explain\] time.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationSpecOverride {
    /// The parameters to be overridden. Note that the
    /// attribution method cannot be changed. If not specified,
    /// no parameter is overridden.
    #[prost(message, optional, tag = "1")]
    pub parameters: ::core::option::Option<ExplanationParameters>,
    /// The metadata to be overridden. If not specified, no metadata is overridden.
    #[prost(message, optional, tag = "2")]
    pub metadata: ::core::option::Option<ExplanationMetadataOverride>,
    /// The example-based explanations parameter overrides.
    #[prost(message, optional, tag = "3")]
    pub examples_override: ::core::option::Option<ExamplesOverride>,
}
/// The \[ExplanationMetadata\]\[google.cloud.aiplatform.v1.ExplanationMetadata\]
/// entries that can be overridden at \[online
/// explanation\]\[google.cloud.aiplatform.v1.PredictionService.Explain\] time.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplanationMetadataOverride {
    /// Required. Overrides the \[input
    /// metadata\]\[google.cloud.aiplatform.v1.ExplanationMetadata.inputs\] of the
    /// features. The key is the name of the feature to be overridden. The keys
    /// specified here must exist in the input metadata to be overridden. If a
    /// feature is not specified here, the corresponding feature's input metadata
    /// is not overridden.
    #[prost(map = "string, message", tag = "1")]
    pub inputs: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        explanation_metadata_override::InputMetadataOverride,
    >,
}
/// Nested message and enum types in `ExplanationMetadataOverride`.
pub mod explanation_metadata_override {
    /// The \[input
    /// metadata\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata\]
    /// entries to be overridden.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct InputMetadataOverride {
        /// Baseline inputs for this feature.
        ///
        /// This overrides the `input_baseline` field of the
        /// \[ExplanationMetadata.InputMetadata\]\[google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata\]
        /// object of the corresponding feature's input metadata. If it's not
        /// specified, the original baselines are not overridden.
        #[prost(message, repeated, tag = "1")]
        pub input_baselines: ::prost::alloc::vec::Vec<
            super::super::super::super::protobuf::Value,
        >,
    }
}
/// Overrides for example-based explanations.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExamplesOverride {
    /// The number of neighbors to return.
    #[prost(int32, tag = "1")]
    pub neighbor_count: i32,
    /// The number of neighbors to return that have the same crowding tag.
    #[prost(int32, tag = "2")]
    pub crowding_count: i32,
    /// Restrict the resulting nearest neighbors to respect these constraints.
    #[prost(message, repeated, tag = "3")]
    pub restrictions: ::prost::alloc::vec::Vec<ExamplesRestrictionsNamespace>,
    /// If true, return the embeddings instead of neighbors.
    #[prost(bool, tag = "4")]
    pub return_embeddings: bool,
    /// The format of the data being provided with each call.
    #[prost(enumeration = "examples_override::DataFormat", tag = "5")]
    pub data_format: i32,
}
/// Nested message and enum types in `ExamplesOverride`.
pub mod examples_override {
    /// Data format enum.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum DataFormat {
        /// Unspecified format. Must not be used.
        Unspecified = 0,
        /// Provided data is a set of model inputs.
        Instances = 1,
        /// Provided data is a set of embeddings.
        Embeddings = 2,
    }
    impl DataFormat {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "DATA_FORMAT_UNSPECIFIED",
                Self::Instances => "INSTANCES",
                Self::Embeddings => "EMBEDDINGS",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "DATA_FORMAT_UNSPECIFIED" => Some(Self::Unspecified),
                "INSTANCES" => Some(Self::Instances),
                "EMBEDDINGS" => Some(Self::Embeddings),
                _ => None,
            }
        }
    }
}
/// Restrictions namespace for example-based explanations overrides.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ExamplesRestrictionsNamespace {
    /// The namespace name.
    #[prost(string, tag = "1")]
    pub namespace_name: ::prost::alloc::string::String,
    /// The list of allowed tags.
    #[prost(string, repeated, tag = "2")]
    pub allow: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The list of deny tags.
    #[prost(string, repeated, tag = "3")]
    pub deny: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A list of boolean values.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct BoolArray {
    /// A list of bool values.
    #[prost(bool, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<bool>,
}
/// A list of double values.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DoubleArray {
    /// A list of double values.
    #[prost(double, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<f64>,
}
/// A list of int64 values.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Int64Array {
    /// A list of int64 values.
    #[prost(int64, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<i64>,
}
/// A list of string values.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StringArray {
    /// A list of string values.
    #[prost(string, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A tensor value type.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tensor {
    /// The data type of tensor.
    #[prost(enumeration = "tensor::DataType", tag = "1")]
    pub dtype: i32,
    /// Shape of the tensor.
    #[prost(int64, repeated, tag = "2")]
    pub shape: ::prost::alloc::vec::Vec<i64>,
    /// Type specific representations that make it easy to create tensor protos in
    /// all languages.  Only the representation corresponding to "dtype" can
    /// be set.  The values hold the flattened representation of the tensor in
    /// row major order.
    ///
    /// \[BOOL\]\[google.cloud.aiplatform.v1.Tensor.DataType.BOOL\]
    #[prost(bool, repeated, tag = "3")]
    pub bool_val: ::prost::alloc::vec::Vec<bool>,
    /// \[STRING\]\[google.cloud.aiplatform.v1.Tensor.DataType.STRING\]
    #[prost(string, repeated, tag = "14")]
    pub string_val: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// \[STRING\]\[google.cloud.aiplatform.v1.Tensor.DataType.STRING\]
    #[prost(bytes = "vec", repeated, tag = "15")]
    pub bytes_val: ::prost::alloc::vec::Vec<::prost::alloc::vec::Vec<u8>>,
    /// \[FLOAT\]\[google.cloud.aiplatform.v1.Tensor.DataType.FLOAT\]
    #[prost(float, repeated, tag = "5")]
    pub float_val: ::prost::alloc::vec::Vec<f32>,
    /// \[DOUBLE\]\[google.cloud.aiplatform.v1.Tensor.DataType.DOUBLE\]
    #[prost(double, repeated, tag = "6")]
    pub double_val: ::prost::alloc::vec::Vec<f64>,
    /// \[INT_8\]\[google.cloud.aiplatform.v1.Tensor.DataType.INT8\]
    /// \[INT_16\]\[google.cloud.aiplatform.v1.Tensor.DataType.INT16\]
    /// \[INT_32\]\[google.cloud.aiplatform.v1.Tensor.DataType.INT32\]
    #[prost(int32, repeated, tag = "7")]
    pub int_val: ::prost::alloc::vec::Vec<i32>,
    /// \[INT64\]\[google.cloud.aiplatform.v1.Tensor.DataType.INT64\]
    #[prost(int64, repeated, tag = "8")]
    pub int64_val: ::prost::alloc::vec::Vec<i64>,
    /// \[UINT8\]\[google.cloud.aiplatform.v1.Tensor.DataType.UINT8\]
    /// \[UINT16\]\[google.cloud.aiplatform.v1.Tensor.DataType.UINT16\]
    /// \[UINT32\]\[google.cloud.aiplatform.v1.Tensor.DataType.UINT32\]
    #[prost(uint32, repeated, tag = "9")]
    pub uint_val: ::prost::alloc::vec::Vec<u32>,
    /// \[UINT64\]\[google.cloud.aiplatform.v1.Tensor.DataType.UINT64\]
    #[prost(uint64, repeated, tag = "10")]
    pub uint64_val: ::prost::alloc::vec::Vec<u64>,
    /// A list of tensor values.
    #[prost(message, repeated, tag = "11")]
    pub list_val: ::prost::alloc::vec::Vec<Tensor>,
    /// A map of string to tensor.
    #[prost(map = "string, message", tag = "12")]
    pub struct_val: ::std::collections::HashMap<::prost::alloc::string::String, Tensor>,
    /// Serialized raw tensor content.
    #[prost(bytes = "vec", tag = "13")]
    pub tensor_val: ::prost::alloc::vec::Vec<u8>,
}
/// Nested message and enum types in `Tensor`.
pub mod tensor {
    /// Data type of the tensor.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum DataType {
        /// Not a legal value for DataType. Used to indicate a DataType field has not
        /// been set.
        Unspecified = 0,
        /// Data types that all computation devices are expected to be
        /// capable to support.
        Bool = 1,
        String = 2,
        Float = 3,
        Double = 4,
        Int8 = 5,
        Int16 = 6,
        Int32 = 7,
        Int64 = 8,
        Uint8 = 9,
        Uint16 = 10,
        Uint32 = 11,
        Uint64 = 12,
    }
    impl DataType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "DATA_TYPE_UNSPECIFIED",
                Self::Bool => "BOOL",
                Self::String => "STRING",
                Self::Float => "FLOAT",
                Self::Double => "DOUBLE",
                Self::Int8 => "INT8",
                Self::Int16 => "INT16",
                Self::Int32 => "INT32",
                Self::Int64 => "INT64",
                Self::Uint8 => "UINT8",
                Self::Uint16 => "UINT16",
                Self::Uint32 => "UINT32",
                Self::Uint64 => "UINT64",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "DATA_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "BOOL" => Some(Self::Bool),
                "STRING" => Some(Self::String),
                "FLOAT" => Some(Self::Float),
                "DOUBLE" => Some(Self::Double),
                "INT8" => Some(Self::Int8),
                "INT16" => Some(Self::Int16),
                "INT32" => Some(Self::Int32),
                "INT64" => Some(Self::Int64),
                "UINT8" => Some(Self::Uint8),
                "UINT16" => Some(Self::Uint16),
                "UINT32" => Some(Self::Uint32),
                "UINT64" => Some(Self::Uint64),
                _ => None,
            }
        }
    }
}
/// Usage metadata about the content generation request and response.
/// This message provides a detailed breakdown of token usage and other
/// relevant metrics.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UsageMetadata {
    /// The total number of tokens in the prompt. This includes any text, images,
    /// or other media provided in the request. When `cached_content` is set,
    /// this also includes the number of tokens in the cached content.
    #[prost(int32, tag = "1")]
    pub prompt_token_count: i32,
    /// The total number of tokens in the generated candidates.
    #[prost(int32, tag = "2")]
    pub candidates_token_count: i32,
    /// The total number of tokens for the entire request. This is the sum of
    /// `prompt_token_count`, `candidates_token_count`,
    /// `tool_use_prompt_token_count`, and `thoughts_token_count`.
    #[prost(int32, tag = "3")]
    pub total_token_count: i32,
    /// Output only. The number of tokens in the results from tool executions,
    /// which are provided back to the model as input, if applicable.
    #[prost(int32, tag = "13")]
    pub tool_use_prompt_token_count: i32,
    /// Output only. The number of tokens that were part of the model's generated
    /// "thoughts" output, if applicable.
    #[prost(int32, tag = "14")]
    pub thoughts_token_count: i32,
    /// Output only. The number of tokens in the cached content that was used for
    /// this request.
    #[prost(int32, tag = "5")]
    pub cached_content_token_count: i32,
    /// Output only. A detailed breakdown of the token count for each modality in
    /// the prompt.
    #[prost(message, repeated, tag = "9")]
    pub prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. A detailed breakdown of the token count for each modality in
    /// the cached content.
    #[prost(message, repeated, tag = "10")]
    pub cache_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. A detailed breakdown of the token count for each modality in
    /// the generated candidates.
    #[prost(message, repeated, tag = "11")]
    pub candidates_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. A detailed breakdown by modality of the token counts from the
    /// results of tool executions, which are provided back to the model as input.
    #[prost(message, repeated, tag = "12")]
    pub tool_use_prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. The traffic type for this request.
    #[prost(enumeration = "usage_metadata::TrafficType", tag = "8")]
    pub traffic_type: i32,
}
/// Nested message and enum types in `UsageMetadata`.
pub mod usage_metadata {
    /// The type of traffic that this request was processed with, indicating which
    /// quota gets consumed.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum TrafficType {
        /// Unspecified request traffic type.
        Unspecified = 0,
        /// Type for Pay-As-You-Go traffic.
        OnDemand = 1,
        /// Type for Provisioned Throughput traffic.
        ProvisionedThroughput = 2,
    }
    impl TrafficType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "TRAFFIC_TYPE_UNSPECIFIED",
                Self::OnDemand => "ON_DEMAND",
                Self::ProvisionedThroughput => "PROVISIONED_THROUGHPUT",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "TRAFFIC_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "ON_DEMAND" => Some(Self::OnDemand),
                "PROVISIONED_THROUGHPUT" => Some(Self::ProvisionedThroughput),
                _ => None,
            }
        }
    }
}
/// Request message for
/// \[PredictionService.Predict\]\[google.cloud.aiplatform.v1.PredictionService.Predict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Required. The instances that are the input to the prediction call.
    /// A DeployedModel may have an upper limit on the number of instances it
    /// supports per request, and when it is exceeded the prediction call errors
    /// in case of AutoML Models, or, in case of customer created Models, the
    /// behaviour is as documented by that Model.
    /// The schema of any single instance may be specified via Endpoint's
    /// DeployedModels' \[Model's\]\[google.cloud.aiplatform.v1.DeployedModel.model\]
    /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
    /// \[instance_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri\].
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<super::super::super::protobuf::Value>,
    /// The parameters that govern the prediction. The schema of the parameters may
    /// be specified via Endpoint's DeployedModels' \[Model's
    /// \]\[google.cloud.aiplatform.v1.DeployedModel.model\]
    /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
    /// \[parameters_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.parameters_schema_uri\].
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<super::super::super::protobuf::Value>,
    /// Optional. The user labels for Imagen billing usage only. Only Imagen
    /// supports labels. For other use cases, it will be ignored.
    #[prost(map = "string, string", tag = "4")]
    pub labels: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
}
/// Response message for
/// \[PredictionService.Predict\]\[google.cloud.aiplatform.v1.PredictionService.Predict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PredictResponse {
    /// The predictions that are the output of the predictions call.
    /// The schema of any single prediction may be specified via Endpoint's
    /// DeployedModels' \[Model's \]\[google.cloud.aiplatform.v1.DeployedModel.model\]
    /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
    /// \[prediction_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.prediction_schema_uri\].
    #[prost(message, repeated, tag = "1")]
    pub predictions: ::prost::alloc::vec::Vec<super::super::super::protobuf::Value>,
    /// ID of the Endpoint's DeployedModel that served this prediction.
    #[prost(string, tag = "2")]
    pub deployed_model_id: ::prost::alloc::string::String,
    /// Output only. The resource name of the Model which is deployed as the
    /// DeployedModel that this prediction hits.
    #[prost(string, tag = "3")]
    pub model: ::prost::alloc::string::String,
    /// Output only. The version ID of the Model which is deployed as the
    /// DeployedModel that this prediction hits.
    #[prost(string, tag = "5")]
    pub model_version_id: ::prost::alloc::string::String,
    /// Output only. The \[display
    /// name\]\[google.cloud.aiplatform.v1.Model.display_name\] of the Model which is
    /// deployed as the DeployedModel that this prediction hits.
    #[prost(string, tag = "4")]
    pub model_display_name: ::prost::alloc::string::String,
    /// Output only. Request-level metadata returned by the model. The metadata
    /// type will be dependent upon the model implementation.
    #[prost(message, optional, tag = "6")]
    pub metadata: ::core::option::Option<super::super::super::protobuf::Value>,
}
/// Request message for
/// \[PredictionService.RawPredict\]\[google.cloud.aiplatform.v1.PredictionService.RawPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input. Supports HTTP headers and arbitrary data payload.
    ///
    /// A \[DeployedModel\]\[google.cloud.aiplatform.v1.DeployedModel\] may have an
    /// upper limit on the number of instances it supports per request. When this
    /// limit it is exceeded for an AutoML model, the
    /// \[RawPredict\]\[google.cloud.aiplatform.v1.PredictionService.RawPredict\]
    /// method returns an error. When this limit is exceeded for a custom-trained
    /// model, the behavior varies depending on the model.
    ///
    /// You can specify the schema for each instance in the
    /// \[predict_schemata.instance_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri\]
    /// field when you create a \[Model\]\[google.cloud.aiplatform.v1.Model\]. This
    /// schema applies when you deploy the `Model` as a `DeployedModel` to an
    /// \[Endpoint\]\[google.cloud.aiplatform.v1.Endpoint\] and use the `RawPredict`
    /// method.
    #[prost(message, optional, tag = "2")]
    pub http_body: ::core::option::Option<super::super::super::api::HttpBody>,
}
/// Request message for
/// \[PredictionService.StreamRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamRawPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input. Supports HTTP headers and arbitrary data payload.
    #[prost(message, optional, tag = "2")]
    pub http_body: ::core::option::Option<super::super::super::api::HttpBody>,
}
/// Request message for
/// \[PredictionService.DirectPredict\]\[google.cloud.aiplatform.v1.PredictionService.DirectPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// \[PredictionService.DirectPredict\]\[google.cloud.aiplatform.v1.PredictionService.DirectPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DirectPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// \[PredictionService.DirectRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.DirectRawPredict\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DirectRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// \[PredictionService.DirectRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.DirectRawPredict\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DirectRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// \[PredictionService.StreamDirectPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamDirectPredict\].
///
/// The first message must contain
/// \[endpoint\]\[google.cloud.aiplatform.v1.StreamDirectPredictRequest.endpoint\]
/// field and optionally \[input\]\[\]. The subsequent messages must contain
/// \[input\]\[\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Optional. The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// Optional. The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// \[PredictionService.StreamDirectPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamDirectPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamDirectPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// \[PredictionService.StreamDirectRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamDirectRawPredict\].
///
/// The first message must contain
/// \[endpoint\]\[google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.endpoint\]
/// and
/// \[method_name\]\[google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.method_name\]
/// fields and optionally
/// \[input\]\[google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.input\]. The
/// subsequent messages must contain
/// \[input\]\[google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.input\].
/// \[method_name\]\[google.cloud.aiplatform.v1.StreamDirectRawPredictRequest.method_name\]
/// in the subsequent messages have no effect.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamDirectRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Optional. Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// Optional. The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// \[PredictionService.StreamDirectRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamDirectRawPredict\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamDirectRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// \[PredictionService.StreamingPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamingPredict\].
///
/// The first message must contain
/// \[endpoint\]\[google.cloud.aiplatform.v1.StreamingPredictRequest.endpoint\] field
/// and optionally \[input\]\[\]. The subsequent messages must contain \[input\]\[\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(message, repeated, tag = "2")]
    pub inputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Response message for
/// \[PredictionService.StreamingPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamingPredict\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StreamingPredictResponse {
    /// The prediction output.
    #[prost(message, repeated, tag = "1")]
    pub outputs: ::prost::alloc::vec::Vec<Tensor>,
    /// The parameters that govern the prediction.
    #[prost(message, optional, tag = "2")]
    pub parameters: ::core::option::Option<Tensor>,
}
/// Request message for
/// \[PredictionService.StreamingRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamingRawPredict\].
///
/// The first message must contain
/// \[endpoint\]\[google.cloud.aiplatform.v1.StreamingRawPredictRequest.endpoint\]
/// and
/// \[method_name\]\[google.cloud.aiplatform.v1.StreamingRawPredictRequest.method_name\]
/// fields and optionally
/// \[input\]\[google.cloud.aiplatform.v1.StreamingRawPredictRequest.input\]. The
/// subsequent messages must contain
/// \[input\]\[google.cloud.aiplatform.v1.StreamingRawPredictRequest.input\].
/// \[method_name\]\[google.cloud.aiplatform.v1.StreamingRawPredictRequest.method_name\]
/// in the subsequent messages have no effect.
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamingRawPredictRequest {
    /// Required. The name of the Endpoint requested to serve the prediction.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Fully qualified name of the API method being invoked to perform
    /// predictions.
    ///
    /// Format:
    /// `/namespace.Service/Method/`
    /// Example:
    /// `/tensorflow.serving.PredictionService/Predict`
    #[prost(string, tag = "2")]
    pub method_name: ::prost::alloc::string::String,
    /// The prediction input.
    #[prost(bytes = "vec", tag = "3")]
    pub input: ::prost::alloc::vec::Vec<u8>,
}
/// Response message for
/// \[PredictionService.StreamingRawPredict\]\[google.cloud.aiplatform.v1.PredictionService.StreamingRawPredict\].
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StreamingRawPredictResponse {
    /// The prediction output.
    #[prost(bytes = "vec", tag = "1")]
    pub output: ::prost::alloc::vec::Vec<u8>,
}
/// Request message for
/// \[PredictionService.Explain\]\[google.cloud.aiplatform.v1.PredictionService.Explain\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplainRequest {
    /// Required. The name of the Endpoint requested to serve the explanation.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Required. The instances that are the input to the explanation call.
    /// A DeployedModel may have an upper limit on the number of instances it
    /// supports per request, and when it is exceeded the explanation call errors
    /// in case of AutoML Models, or, in case of customer created Models, the
    /// behaviour is as documented by that Model.
    /// The schema of any single instance may be specified via Endpoint's
    /// DeployedModels' \[Model's\]\[google.cloud.aiplatform.v1.DeployedModel.model\]
    /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
    /// \[instance_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri\].
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<super::super::super::protobuf::Value>,
    /// The parameters that govern the prediction. The schema of the parameters may
    /// be specified via Endpoint's DeployedModels' \[Model's
    /// \]\[google.cloud.aiplatform.v1.DeployedModel.model\]
    /// \[PredictSchemata's\]\[google.cloud.aiplatform.v1.Model.predict_schemata\]
    /// \[parameters_schema_uri\]\[google.cloud.aiplatform.v1.PredictSchemata.parameters_schema_uri\].
    #[prost(message, optional, tag = "4")]
    pub parameters: ::core::option::Option<super::super::super::protobuf::Value>,
    /// If specified, overrides the
    /// \[explanation_spec\]\[google.cloud.aiplatform.v1.DeployedModel.explanation_spec\]
    /// of the DeployedModel. Can be used for explaining prediction results with
    /// different configurations, such as:
    ///
    /// * Explaining top-5 predictions results as opposed to top-1;
    /// * Increasing path count or step count of the attribution methods to reduce
    ///   approximate errors;
    /// * Using different baselines for explaining the prediction results.
    #[prost(message, optional, tag = "5")]
    pub explanation_spec_override: ::core::option::Option<ExplanationSpecOverride>,
    /// If specified, this ExplainRequest will be served by the chosen
    /// DeployedModel, overriding
    /// \[Endpoint.traffic_split\]\[google.cloud.aiplatform.v1.Endpoint.traffic_split\].
    #[prost(string, tag = "3")]
    pub deployed_model_id: ::prost::alloc::string::String,
}
/// Response message for
/// \[PredictionService.Explain\]\[google.cloud.aiplatform.v1.PredictionService.Explain\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExplainResponse {
    /// The explanations of the Model's
    /// \[PredictResponse.predictions\]\[google.cloud.aiplatform.v1.PredictResponse.predictions\].
    ///
    /// It has the same number of elements as
    /// \[instances\]\[google.cloud.aiplatform.v1.ExplainRequest.instances\] to be
    /// explained.
    #[prost(message, repeated, tag = "1")]
    pub explanations: ::prost::alloc::vec::Vec<Explanation>,
    /// ID of the Endpoint's DeployedModel that served this explanation.
    #[prost(string, tag = "2")]
    pub deployed_model_id: ::prost::alloc::string::String,
    /// The predictions that are the output of the predictions call.
    /// Same as
    /// \[PredictResponse.predictions\]\[google.cloud.aiplatform.v1.PredictResponse.predictions\].
    #[prost(message, repeated, tag = "3")]
    pub predictions: ::prost::alloc::vec::Vec<super::super::super::protobuf::Value>,
}
/// Request message for \[PredictionService.CountTokens\]\[\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CountTokensRequest {
    /// Required. The name of the Endpoint requested to perform token counting.
    /// Format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "1")]
    pub endpoint: ::prost::alloc::string::String,
    /// Optional. The name of the publisher model requested to serve the
    /// prediction. Format:
    /// `projects/{project}/locations/{location}/publishers/*/models/*`
    #[prost(string, tag = "3")]
    pub model: ::prost::alloc::string::String,
    /// Optional. The instances that are the input to token counting call.
    /// Schema is identical to the prediction schema of the underlying model.
    #[prost(message, repeated, tag = "2")]
    pub instances: ::prost::alloc::vec::Vec<super::super::super::protobuf::Value>,
    /// Optional. Input content.
    #[prost(message, repeated, tag = "4")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Optional. The user provided system instructions for the model.
    /// Note: only text should be used in parts and content in each part will be in
    /// a separate paragraph.
    #[prost(message, optional, tag = "5")]
    pub system_instruction: ::core::option::Option<Content>,
    /// Optional. A list of `Tools` the model may use to generate the next
    /// response.
    ///
    /// A `Tool` is a piece of code that enables the system to interact with
    /// external systems to perform an action, or set of actions, outside of
    /// knowledge and scope of the model.
    #[prost(message, repeated, tag = "6")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Optional. Generation config that the model will use to generate the
    /// response.
    #[prost(message, optional, tag = "7")]
    pub generation_config: ::core::option::Option<GenerationConfig>,
}
/// Response message for \[PredictionService.CountTokens\]\[\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CountTokensResponse {
    /// The total number of tokens counted across all instances from the request.
    #[prost(int32, tag = "1")]
    pub total_tokens: i32,
    /// The total number of billable characters counted across all instances from
    /// the request.
    #[prost(int32, tag = "2")]
    pub total_billable_characters: i32,
    /// Output only. List of modalities that were processed in the request input.
    #[prost(message, repeated, tag = "3")]
    pub prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
}
/// Request message for \[PredictionService.GenerateContent\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentRequest {
    /// Required. The fully qualified name of the publisher model or tuned model
    /// endpoint to use.
    ///
    /// Publisher model format:
    /// `projects/{project}/locations/{location}/publishers/*/models/*`
    ///
    /// Tuned model endpoint format:
    /// `projects/{project}/locations/{location}/endpoints/{endpoint}`
    #[prost(string, tag = "5")]
    pub model: ::prost::alloc::string::String,
    /// Required. The content of the current conversation with the model.
    ///
    /// For single-turn queries, this is a single instance. For multi-turn queries,
    /// this is a repeated field that contains conversation history + latest
    /// request.
    #[prost(message, repeated, tag = "2")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Optional. The user provided system instructions for the model.
    /// Note: only text should be used in parts and content in each part will be in
    /// a separate paragraph.
    #[prost(message, optional, tag = "8")]
    pub system_instruction: ::core::option::Option<Content>,
    /// Optional. The name of the cached content used as context to serve the
    /// prediction. Note: only used in explicit caching, where users can have
    /// control over caching (e.g. what content to cache) and enjoy guaranteed cost
    /// savings. Format:
    /// `projects/{project}/locations/{location}/cachedContents/{cachedContent}`
    #[prost(string, tag = "9")]
    pub cached_content: ::prost::alloc::string::String,
    /// Optional. A list of `Tools` the model may use to generate the next
    /// response.
    ///
    /// A `Tool` is a piece of code that enables the system to interact with
    /// external systems to perform an action, or set of actions, outside of
    /// knowledge and scope of the model.
    #[prost(message, repeated, tag = "6")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Optional. Tool config. This config is shared for all tools provided in the
    /// request.
    #[prost(message, optional, tag = "7")]
    pub tool_config: ::core::option::Option<ToolConfig>,
    /// Optional. The labels with user-defined metadata for the request. It is used
    /// for billing and reporting only.
    ///
    /// Label keys and values can be no longer than 63 characters
    /// (Unicode codepoints) and can only contain lowercase letters, numeric
    /// characters, underscores, and dashes. International characters are allowed.
    /// Label values are optional. Label keys must start with a letter.
    #[prost(map = "string, string", tag = "10")]
    pub labels: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
    /// Optional. Per request settings for blocking unsafe content.
    /// Enforced on GenerateContentResponse.candidates.
    #[prost(message, repeated, tag = "3")]
    pub safety_settings: ::prost::alloc::vec::Vec<SafetySetting>,
    /// Optional. Settings for prompt and response sanitization using the Model
    /// Armor service. If supplied, safety_settings must not be supplied.
    #[prost(message, optional, tag = "11")]
    pub model_armor_config: ::core::option::Option<ModelArmorConfig>,
    /// Optional. Generation config.
    #[prost(message, optional, tag = "4")]
    pub generation_config: ::core::option::Option<GenerationConfig>,
}
/// Response message for \[PredictionService.GenerateContent\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentResponse {
    /// Output only. Generated candidates.
    #[prost(message, repeated, tag = "2")]
    pub candidates: ::prost::alloc::vec::Vec<Candidate>,
    /// Output only. The model version used to generate the response.
    #[prost(string, tag = "11")]
    pub model_version: ::prost::alloc::string::String,
    /// Output only. Timestamp when the request is made to the server.
    #[prost(message, optional, tag = "12")]
    pub create_time: ::core::option::Option<super::super::super::protobuf::Timestamp>,
    /// Output only. response_id is used to identify each response. It is the
    /// encoding of the event_id.
    #[prost(string, tag = "13")]
    pub response_id: ::prost::alloc::string::String,
    /// Output only. Content filter results for a prompt sent in the request.
    /// Note: Sent only in the first stream chunk.
    /// Only happens when no candidates were generated due to content violations.
    #[prost(message, optional, tag = "3")]
    pub prompt_feedback: ::core::option::Option<
        generate_content_response::PromptFeedback,
    >,
    /// Usage metadata about the response(s).
    #[prost(message, optional, tag = "4")]
    pub usage_metadata: ::core::option::Option<generate_content_response::UsageMetadata>,
}
/// Nested message and enum types in `GenerateContentResponse`.
pub mod generate_content_response {
    /// Content filter results for a prompt sent in the request.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PromptFeedback {
        /// Output only. Blocked reason.
        #[prost(enumeration = "prompt_feedback::BlockedReason", tag = "1")]
        pub block_reason: i32,
        /// Output only. Safety ratings.
        #[prost(message, repeated, tag = "2")]
        pub safety_ratings: ::prost::alloc::vec::Vec<super::SafetyRating>,
        /// Output only. A readable block reason message.
        #[prost(string, tag = "3")]
        pub block_reason_message: ::prost::alloc::string::String,
    }
    /// Nested message and enum types in `PromptFeedback`.
    pub mod prompt_feedback {
        /// Blocked reason enumeration.
        #[derive(
            Clone,
            Copy,
            Debug,
            PartialEq,
            Eq,
            Hash,
            PartialOrd,
            Ord,
            ::prost::Enumeration
        )]
        #[repr(i32)]
        pub enum BlockedReason {
            /// Unspecified blocked reason.
            Unspecified = 0,
            /// Candidates blocked due to safety.
            Safety = 1,
            /// Candidates blocked due to other reason.
            Other = 2,
            /// Candidates blocked due to the terms which are included from the
            /// terminology blocklist.
            Blocklist = 3,
            /// Candidates blocked due to prohibited content.
            ProhibitedContent = 4,
            /// The user prompt was blocked by Model Armor.
            ModelArmor = 5,
            /// The user prompt was blocked due to jailbreak.
            Jailbreak = 6,
        }
        impl BlockedReason {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "BLOCKED_REASON_UNSPECIFIED",
                    Self::Safety => "SAFETY",
                    Self::Other => "OTHER",
                    Self::Blocklist => "BLOCKLIST",
                    Self::ProhibitedContent => "PROHIBITED_CONTENT",
                    Self::ModelArmor => "MODEL_ARMOR",
                    Self::Jailbreak => "JAILBREAK",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "BLOCKED_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                    "SAFETY" => Some(Self::Safety),
                    "OTHER" => Some(Self::Other),
                    "BLOCKLIST" => Some(Self::Blocklist),
                    "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                    "MODEL_ARMOR" => Some(Self::ModelArmor),
                    "JAILBREAK" => Some(Self::Jailbreak),
                    _ => None,
                }
            }
        }
    }
    /// Usage metadata about response(s).
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct UsageMetadata {
        /// Number of tokens in the request. When `cached_content` is set, this is
        /// still the total effective prompt size meaning this includes the number of
        /// tokens in the cached content.
        #[prost(int32, tag = "1")]
        pub prompt_token_count: i32,
        /// Number of tokens in the response(s).
        #[prost(int32, tag = "2")]
        pub candidates_token_count: i32,
        /// Output only. Number of tokens present in thoughts output.
        #[prost(int32, tag = "14")]
        pub thoughts_token_count: i32,
        /// Total token count for prompt and response candidates.
        #[prost(int32, tag = "3")]
        pub total_token_count: i32,
        /// Output only. Number of tokens in the cached part in the input (the cached
        /// content).
        #[prost(int32, tag = "5")]
        pub cached_content_token_count: i32,
        /// Output only. List of modalities that were processed in the request input.
        #[prost(message, repeated, tag = "9")]
        pub prompt_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
        /// Output only. List of modalities of the cached content in the request
        /// input.
        #[prost(message, repeated, tag = "10")]
        pub cache_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
        /// Output only. List of modalities that were returned in the response.
        #[prost(message, repeated, tag = "11")]
        pub candidates_tokens_details: ::prost::alloc::vec::Vec<
            super::ModalityTokenCount,
        >,
    }
}
/// Request message for
/// \[PredictionService.EmbedContent\]\[google.cloud.aiplatform.v1.PredictionService.EmbedContent\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedContentRequest {
    /// Required. The name of the publisher model requested to serve the
    /// prediction. Format:
    /// `projects/{project}/locations/{location}/publishers/*/models/*`
    #[prost(string, optional, tag = "1")]
    pub model: ::core::option::Option<::prost::alloc::string::String>,
    /// Required. Input content to be embedded. Required.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
    /// Optional. An optional title for the text.
    #[prost(string, optional, tag = "4")]
    pub title: ::core::option::Option<::prost::alloc::string::String>,
    /// Optional. The task type of the embedding.
    #[prost(
        enumeration = "embed_content_request::EmbeddingTaskType",
        optional,
        tag = "5"
    )]
    pub task_type: ::core::option::Option<i32>,
    /// Optional. Optional reduced dimension for the output embedding. If set,
    /// excessive values in the output embedding are truncated from the end.
    #[prost(int32, optional, tag = "6")]
    pub output_dimensionality: ::core::option::Option<i32>,
    /// Optional. Whether to silently truncate the input content if it's longer
    /// than the maximum sequence length.
    #[prost(bool, optional, tag = "7")]
    pub auto_truncate: ::core::option::Option<bool>,
}
/// Nested message and enum types in `EmbedContentRequest`.
pub mod embed_content_request {
    /// Represents a downstream task the embeddings will be used for.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum EmbeddingTaskType {
        /// Unset value, which will default to one of the other enum values.
        Unspecified = 0,
        /// Specifies the given text is a query in a search/retrieval setting.
        RetrievalQuery = 2,
        /// Specifies the given text is a document from the corpus being searched.
        RetrievalDocument = 3,
        /// Specifies the given text will be used for STS.
        SemanticSimilarity = 4,
        /// Specifies that the given text will be classified.
        Classification = 5,
        /// Specifies that the embeddings will be used for clustering.
        Clustering = 6,
        /// Specifies that the embeddings will be used for question answering.
        QuestionAnswering = 7,
        /// Specifies that the embeddings will be used for fact verification.
        FactVerification = 8,
        /// Specifies that the embeddings will be used for code retrieval.
        CodeRetrievalQuery = 9,
    }
    impl EmbeddingTaskType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "UNSPECIFIED",
                Self::RetrievalQuery => "RETRIEVAL_QUERY",
                Self::RetrievalDocument => "RETRIEVAL_DOCUMENT",
                Self::SemanticSimilarity => "SEMANTIC_SIMILARITY",
                Self::Classification => "CLASSIFICATION",
                Self::Clustering => "CLUSTERING",
                Self::QuestionAnswering => "QUESTION_ANSWERING",
                Self::FactVerification => "FACT_VERIFICATION",
                Self::CodeRetrievalQuery => "CODE_RETRIEVAL_QUERY",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "UNSPECIFIED" => Some(Self::Unspecified),
                "RETRIEVAL_QUERY" => Some(Self::RetrievalQuery),
                "RETRIEVAL_DOCUMENT" => Some(Self::RetrievalDocument),
                "SEMANTIC_SIMILARITY" => Some(Self::SemanticSimilarity),
                "CLASSIFICATION" => Some(Self::Classification),
                "CLUSTERING" => Some(Self::Clustering),
                "QUESTION_ANSWERING" => Some(Self::QuestionAnswering),
                "FACT_VERIFICATION" => Some(Self::FactVerification),
                "CODE_RETRIEVAL_QUERY" => Some(Self::CodeRetrievalQuery),
                _ => None,
            }
        }
    }
}
/// Response message for
/// \[PredictionService.EmbedContent\]\[google.cloud.aiplatform.v1.PredictionService.EmbedContent\].
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedContentResponse {
    /// The embedding generated from the input content.
    #[prost(message, optional, tag = "1")]
    pub embedding: ::core::option::Option<embed_content_response::Embedding>,
    /// Metadata about the response(s).
    #[prost(message, optional, tag = "2")]
    pub usage_metadata: ::core::option::Option<UsageMetadata>,
    /// Whether the input content was truncated before generating the embedding.
    #[prost(bool, tag = "4")]
    pub truncated: bool,
}
/// Nested message and enum types in `EmbedContentResponse`.
pub mod embed_content_response {
    /// A list of floats representing an embedding.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Embedding {
        /// Embedding vector values.
        #[prost(float, repeated, tag = "1")]
        pub values: ::prost::alloc::vec::Vec<f32>,
    }
}
/// Generated client implementations.
pub mod prediction_service_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// A service for online predictions and explanations.
    #[derive(Debug, Clone)]
    pub struct PredictionServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl PredictionServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> PredictionServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> PredictionServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            PredictionServiceClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Perform an online prediction.
        pub async fn predict(
            &mut self,
            request: impl tonic::IntoRequest<super::PredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::PredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/Predict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "Predict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform an online prediction with an arbitrary HTTP payload.
        ///
        /// The response includes the following HTTP headers:
        ///
        /// * `X-Vertex-AI-Endpoint-Id`: ID of the
        ///  \[Endpoint\]\[google.cloud.aiplatform.v1.Endpoint\] that served this
        ///  prediction.
        ///
        /// * `X-Vertex-AI-Deployed-Model-Id`: ID of the Endpoint's
        ///  \[DeployedModel\]\[google.cloud.aiplatform.v1.DeployedModel\] that served this
        ///  prediction.
        pub async fn raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::RawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::super::super::super::api::HttpBody>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/RawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "RawPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform a streaming online prediction with an arbitrary HTTP payload.
        pub async fn stream_raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::StreamRawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<
                tonic::codec::Streaming<super::super::super::super::api::HttpBody>,
            >,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamRawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamRawPredict",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Perform an unary online prediction request to a gRPC model server for
        /// Vertex first-party products and frameworks.
        pub async fn direct_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::DirectPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::DirectPredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/DirectPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "DirectPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform an unary online prediction request to a gRPC model server for
        /// custom containers.
        pub async fn direct_raw_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::DirectRawPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<super::DirectRawPredictResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/DirectRawPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "DirectRawPredict",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Perform a streaming online prediction request to a gRPC model server for
        /// Vertex first-party products and frameworks.
        pub async fn stream_direct_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamDirectPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamDirectPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamDirectPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamDirectPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request to a gRPC model server for
        /// custom containers.
        pub async fn stream_direct_raw_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamDirectRawPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<
                tonic::codec::Streaming<super::StreamDirectRawPredictResponse>,
            >,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamDirectRawPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamDirectRawPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request for Vertex first-party
        /// products and frameworks.
        pub async fn streaming_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamingPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamingPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamingPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform a server-side streaming online prediction request for Vertex
        /// LLM streaming.
        pub async fn server_streaming_predict(
            &mut self,
            request: impl tonic::IntoRequest<super::StreamingPredictRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/ServerStreamingPredict",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "ServerStreamingPredict",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Perform a streaming online prediction request through gRPC.
        pub async fn streaming_raw_predict(
            &mut self,
            request: impl tonic::IntoStreamingRequest<
                Message = super::StreamingRawPredictRequest,
            >,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::StreamingRawPredictResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamingRawPredict",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamingRawPredict",
                    ),
                );
            self.inner.streaming(req, path, codec).await
        }
        /// Perform an online explanation.
        ///
        /// If
        /// \[deployed_model_id\]\[google.cloud.aiplatform.v1.ExplainRequest.deployed_model_id\]
        /// is specified, the corresponding DeployModel must have
        /// \[explanation_spec\]\[google.cloud.aiplatform.v1.DeployedModel.explanation_spec\]
        /// populated. If
        /// \[deployed_model_id\]\[google.cloud.aiplatform.v1.ExplainRequest.deployed_model_id\]
        /// is not specified, all DeployedModels must have
        /// \[explanation_spec\]\[google.cloud.aiplatform.v1.DeployedModel.explanation_spec\]
        /// populated.
        pub async fn explain(
            &mut self,
            request: impl tonic::IntoRequest<super::ExplainRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ExplainResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/Explain",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "Explain",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Generate content with multimodal inputs.
        pub async fn generate_content(
            &mut self,
            request: impl tonic::IntoRequest<super::GenerateContentRequest>,
        ) -> std::result::Result<
            tonic::Response<super::GenerateContentResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/GenerateContent",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "GenerateContent",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Generate content with multimodal inputs with streaming support.
        pub async fn stream_generate_content(
            &mut self,
            request: impl tonic::IntoRequest<super::GenerateContentRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::GenerateContentResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/StreamGenerateContent",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "StreamGenerateContent",
                    ),
                );
            self.inner.server_streaming(req, path, codec).await
        }
        /// Embed content with multimodal inputs.
        pub async fn embed_content(
            &mut self,
            request: impl tonic::IntoRequest<super::EmbedContentRequest>,
        ) -> std::result::Result<
            tonic::Response<super::EmbedContentResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.aiplatform.v1.PredictionService/EmbedContent",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.aiplatform.v1.PredictionService",
                        "EmbedContent",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
    }
}
